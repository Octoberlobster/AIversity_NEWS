"""
å›°é›£é—œéµå­—æå–å™¨ - å¯å­˜å…¥è³‡æ–™åº«ç‰ˆæœ¬
å¾ Supabase single_news è¡¨è®€å–è³‡æ–™ï¼Œæå–å›°é›£é—œéµå­—ä¸¦ç”Ÿæˆè§£é‡‹ï¼Œå¯å­˜å…¥è³‡æ–™åº«

ç”¨æ³•:
  ä¸€èˆ¬æ¨¡å¼ (è™•ç†æ‰€æœ‰è³‡æ–™): python difficult_keyword_extractor_final.py
  é™åˆ¶ç­†æ•¸æ¨¡å¼: python difficult_keyword_extractor_final.py [limit]
  æ¸¬è©¦æ¨¡å¼ (å–®ä¸€æ–°èé è¦½): python difficult_keyword_extractor_final.py test [story_id]
  æ¸¬è©¦æ¨¡å¼ (å–®ä¸€æ–°èå­˜å…¥è³‡æ–™åº«): python difficult_keyword_extractor_final.py test [story_id] --save

ç¯„ä¾‹:
  python difficult_keyword_extractor_final.py                    # è™•ç†æ‰€æœ‰è³‡æ–™
  python difficult_keyword_extractor_final.py 10                # è™•ç†å‰ 10 ç­†è³‡æ–™
  python difficult_keyword_extractor_final.py test abc123       # æ¸¬è©¦ story_id = abc123 çš„æ–°è (åƒ…é è¦½)
  python difficult_keyword_extractor_final.py test abc123 --save # æ¸¬è©¦ story_id = abc123 çš„æ–°è (å­˜å…¥è³‡æ–™åº«)

è«‹åœ¨ .env æª”æ¡ˆä¸­è¨­å®š GEMINI_API_KEYã€SUPABASE_URL èˆ‡ SUPABASE_KEY
"""

import os
import json
import time
import sys
from typing import List, Dict, Any, Set, Optional
from dotenv import load_dotenv
from tqdm import tqdm
import google.generativeai as genai


class DiffKeywordConfig:
    """å›°é›£é—œéµå­—è™•ç†å™¨è¨­å®š"""
    
    # API è¨­å®š
    API_CONFIG = {
        'model_name': 'gemini-2.5-flash-lite',
        'call_delay_seconds': 1,  # API å‘¼å«é–“éš”
        'max_retries': 3,
    }
    
    # è™•ç†è¨­å®š
    PROCESSING_CONFIG = {
        'explanation_word_limit': 50,  # è§£é‡‹å­—æ•¸é™åˆ¶
        'default_limit': None,  # é è¨­è®€å–ç­†æ•¸é™åˆ¶
    }
    
    # è³‡æ–™åº«è¨­å®š
    DB_CONFIG = {
        'table_name': 'single_news',
        'select_fields': ['story_id', 'news_title', 'ultra_short', 'short', 'long'],
        'primary_content_field': 'long',  # ä¸»è¦ç”¨æ–¼æå–é—œéµå­—çš„æ¬„ä½
        'title_field': 'news_title',
        'term_map_table': 'term_map',
        'term_map_fields': ['story_id', 'term'],
        'term_table': 'term',
        'term_fields': ['term', 'definition', 'example'],
    }
    
    # è¼¸å‡ºè¨­å®š
    OUTPUT_CONFIG = {
        'save_to_file': False,
        'output_filename': 'difficult_keywords_output.json',
        'terminal_width': 80,
    }


class DiffKeywordProcessor:
    """å›°é›£é—œéµå­—æå–èˆ‡è§£é‡‹çš„æ ¸å¿ƒé¡åˆ¥"""

    def __init__(self):
        """åˆå§‹åŒ–å›°é›£é—œéµå­—è™•ç†å™¨"""
        self.model = None
        self.supabase_client = None
        self.api_config = DiffKeywordConfig.API_CONFIG
        self.proc_config = DiffKeywordConfig.PROCESSING_CONFIG
        self.db_config = DiffKeywordConfig.DB_CONFIG
        self._setup_model()
        self._setup_supabase()

    def _setup_model(self):
        """è¼‰å…¥ç’°å¢ƒè®Šæ•¸ä¸¦åˆå§‹åŒ– Gemini æ¨¡å‹"""
        load_dotenv()
        api_key = os.getenv("GEMINI_API_KEY")
        if not api_key:
            raise EnvironmentError("éŒ¯èª¤ï¼šæ‰¾ä¸åˆ° GEMINI_API_KEYï¼Œè«‹åœ¨ .env æª”æ¡ˆä¸­è¨­å®š")
        
        try:
            genai.configure(api_key=api_key)
            self.model = genai.GenerativeModel(self.api_config['model_name'])
            print(f"âœ“ Gemini API ({self.api_config['model_name']}) åˆå§‹åŒ–æˆåŠŸ")
        except Exception as e:
            print(f"âœ— åˆå§‹åŒ– Gemini æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
            raise

    def _setup_supabase(self):
        """è¼‰å…¥ç’°å¢ƒè®Šæ•¸ä¸¦åˆå§‹åŒ– Supabase é€£ç·š"""
        load_dotenv()
        supabase_url = os.getenv("SUPABASE_URL")
        supabase_key = os.getenv("SUPABASE_KEY")
        
        if not supabase_url or not supabase_key:
            raise EnvironmentError("éŒ¯èª¤ï¼šæ‰¾ä¸åˆ° SUPABASE_URL æˆ– SUPABASE_KEYï¼Œè«‹åœ¨ .env æª”æ¡ˆä¸­è¨­å®š")
        
        try:
            from supabase import create_client
            self.supabase_client = create_client(supabase_url, supabase_key)
            print(f"âœ“ Supabase é€£ç·š ({supabase_url}) åˆå§‹åŒ–æˆåŠŸ")
        except Exception as e:
            print(f"âœ— åˆå§‹åŒ– Supabase æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
            print("è«‹ç¢ºèªå·²å®‰è£ supabase-pyï¼špip install supabase-py postgrest-py")
            raise

    def is_ready(self) -> bool:
        """æª¢æŸ¥æ¨¡å‹å’Œè³‡æ–™åº«é€£ç·šæ˜¯å¦å·²æˆåŠŸåˆå§‹åŒ–"""
        return self.model is not None and self.supabase_client is not None

    def _clean_response_text(self, text: str) -> str:
        """æ¸…ç† Gemini å›è¦†ä¸­çš„ markdown JSON æ¨™ç±¤"""
        cleaned_text = text.strip()
        # æª¢æŸ¥ä¸¦ç§»é™¤é–‹é ­çš„ markdown æ¨™ç±¤
        if cleaned_text.startswith("```json"):
            cleaned_text = cleaned_text[7:]
        elif cleaned_text.startswith("```"):
            cleaned_text = cleaned_text[3:]
        
        # æª¢æŸ¥ä¸¦ç§»é™¤çµå°¾çš„ markdown æ¨™ç±¤
        if cleaned_text.endswith("```json"):
            cleaned_text = cleaned_text[:-7]
        elif cleaned_text.endswith("```"):
            cleaned_text = cleaned_text[:-3]
            
        return cleaned_text.strip()

    def _call_gemini(self, prompt: str) -> Dict[str, Any]:
        """å‘¼å« Gemini API ä¸¦è™•ç†å›è¦†"""
        for attempt in range(self.api_config['max_retries']):
            try:
                response = self.model.generate_content(prompt)
                # ä½¿ç”¨ä¿®æ­£å¾Œçš„æ¸…ç†å‡½å¼
                cleaned_text = self._clean_response_text(response.text)
                return json.loads(cleaned_text)
            except json.JSONDecodeError as e:
                print(f"âœ— JSON è§£æéŒ¯èª¤ (å˜—è©¦ {attempt + 1}/{self.api_config['max_retries']}): {e}")
                if attempt == self.api_config['max_retries'] - 1:
                    print(f"åŸå§‹å›è¦†: {response.text}")
                    return {}
            except Exception as e:
                print(f"âœ— API å‘¼å«æ™‚ç™¼ç”ŸéŒ¯èª¤ (å˜—è©¦ {attempt + 1}/{self.api_config['max_retries']}): {e}")
                if attempt == self.api_config['max_retries'] - 1:
                    return {}
                time.sleep(2)  # é‡è©¦å‰ç­‰å¾…
        return {}

    def fetch_combined_data(self, limit: Optional[int] = None) -> List[Dict[str, Any]]:
        """è®€å–ä¸¦åˆä½µ single_news å’Œ term_map è³‡æ–™"""
        print("\n=== è®€å–åˆä½µè³‡æ–™ ===")
        
        # è®€å– single_news è³‡æ–™
        print("è®€å– single_news è³‡æ–™...")
        try:
            table_name = self.db_config['table_name']
            fields = ','.join(self.db_config['select_fields'])
            
            query = self.supabase_client.table(table_name).select(fields)
            
            if limit:
                query = query.limit(limit)
                print(f"é™åˆ¶è®€å–å‰ {limit} ç­†")
            else:
                print("è®€å–æ‰€æœ‰è³‡æ–™")
            
            resp = query.execute()
            
            if getattr(resp, 'error', None):
                print(f"è®€å– {table_name} å¤±æ•—: {resp.error}")
                return []
            
            news_data = resp.data or []
            print(f"æˆåŠŸè®€å– {len(news_data)} ç­†æ–°èè³‡æ–™")
            
        except Exception as e:
            print(f"è®€å–æ–°èè³‡æ–™æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
            return []
        
        # è®€å– term_map è³‡æ–™
        print("è®€å– term_map è³‡æ–™...")
        try:
            table_name = self.db_config['term_map_table']
            fields = ','.join(self.db_config['term_map_fields'])
            
            query = self.supabase_client.table(table_name).select(fields)
            resp = query.execute()
            
            if getattr(resp, 'error', None):
                print(f"è®€å– {table_name} å¤±æ•—: {resp.error}")
                term_map = {}
            else:
                rows = resp.data or []
                print(f"æˆåŠŸè®€å– {len(rows)} ç­† term_map è³‡æ–™")
                
                # çµ„ç¹”æˆ story_id -> terms çš„å­—å…¸
                term_map = {}
                for row in rows:
                    story_id = row.get('story_id')
                    term = row.get('term')
                    
                    if story_id and term:
                        if story_id not in term_map:
                            term_map[story_id] = []
                        term_map[story_id].append(term)
                
                print(f"çµ„ç¹” term_map: {len(term_map)} å€‹ä¸åŒçš„ story_id")
            
        except Exception as e:
            print(f"è®€å– term_map è³‡æ–™æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
            term_map = {}
        
        # åˆä½µè³‡æ–™
        combined_data = []
        for news in news_data:
            story_id = news.get('story_id')
            existing_terms = term_map.get(story_id, [])
            
            # å°‡ existing_terms æ·»åŠ åˆ°æ–°èè³‡æ–™ä¸­
            news_with_terms = news.copy()
            news_with_terms['existing_terms'] = existing_terms
            combined_data.append(news_with_terms)
        
        print(f"åˆä½µå®Œæˆ: {len(combined_data)} ç­†æ–°èè³‡æ–™")
        return combined_data

    def extract_keywords_from_text(self, text: str, title: str) -> List[str]:
        """å¾å–®ç¯‡æ–‡æœ¬ä¸­æå–å›°é›£é—œéµå­—"""
        prompt = f"""
        ä½ æ˜¯ä¸€ä½å°ˆæ¥­çš„çŸ¥è­˜ç·¨è¼¯ï¼Œæ“…é•·ç‚ºå¤§çœ¾è®€è€…è§£é‡‹è¤‡é›œæ¦‚å¿µã€‚
        è«‹å¾ä»¥ä¸‹æ–°èå…§å®¹ä¸­ï¼Œ**æ¥µåº¦åš´æ ¼ç¯©é¸**å‡ºå°ä¸€èˆ¬å¤§çœ¾è€Œè¨€æœ€è‰±æ·±ã€æœ€éœ€è¦è§£é‡‹çš„å°ˆæ¥­è¡“èªã€‚

        **æ¥µåš´æ ¼æ¨™æº–ï¼šå¯§å¯æ¼æ‰ï¼Œä¹Ÿä¸è¦é¸åˆ°ç°¡å–®è©å½™**
        **æ¯æ¬¡æœ€å¤šåªé¸ 3-5 å€‹æœ€å›°é›£çš„è©å½™ï¼Œå¦‚æœæ²’æœ‰çœŸæ­£å›°é›£çš„è©å½™ï¼Œè«‹å›å‚³ç©ºé™£åˆ—**
        
        å¿…é ˆç¬¦åˆä»¥ä¸‹æ¢ä»¶ä¹‹ä¸€ï¼Œä¸”æ˜¯çœŸæ­£éœ€è¦å°ˆæ¥­çŸ¥è­˜æ‰èƒ½ç†è§£çš„è©å½™ï¼š
        - é«˜åº¦å°ˆæ¥­è¡“èªï¼šé†«å­¸å°ˆæ¥­è¡“èªï¼ˆå¦‚ã€Œè¡€ç®¡å…§çš®ç´°èƒã€ã€ã€Œå…ç–«çƒè›‹ç™½ã€ï¼‰ã€æ³•å¾‹å°ˆæ¥­è¡“èªï¼ˆå¦‚ã€Œä¸ç•¶å¾—åˆ©ã€ã€ã€Œç‰©æ¬Šè¡Œç‚ºã€ï¼‰ã€å·¥ç¨‹æŠ€è¡“è¡“èªï¼ˆå¦‚ã€ŒåŠå°é«”è£½ç¨‹ã€ã€ã€Œé‡å­è¨ˆç®—ã€ï¼‰
        - å­¸è¡“æˆ–ç§‘å­¸æ¦‚å¿µï¼šéœ€è¦ç‰¹æ®Šæ•™è‚²èƒŒæ™¯æ‰èƒ½ç†è§£çš„æ¦‚å¿µï¼ˆå¦‚ã€ŒåŸºå› è¡¨é”ã€ã€ã€Œæ©Ÿå™¨å­¸ç¿’æ¼”ç®—æ³•ã€ã€ã€Œè²¡æ”¿ä¹˜æ•¸æ•ˆæ‡‰ã€ï¼‰
        - åœ‹éš›çµ„ç¹”æˆ–å°ˆæ¥­æ©Ÿæ§‹ç¸®å¯«ï¼šä¸€èˆ¬äººä¸ç†Ÿæ‚‰çš„ç¸®å¯«ï¼ˆå¦‚ã€ŒCPTPPã€ã€ã€ŒSWIFTã€ã€ã€ŒIMFã€ã€ã€ŒWHOã€ï¼‰
        - æ–°èˆˆæŠ€è¡“æˆ–å‰æ²¿ç§‘å­¸è¡“èªï¼šæœ€æ–°ç§‘æŠ€é ˜åŸŸçš„å°ˆæ¥­è©å½™ï¼ˆå¦‚ã€ŒNFTã€ã€ã€Œå€å¡Šéˆã€ã€ã€Œå…ƒå®‡å®™ã€ã€ã€ŒCRISPRã€ï¼‰
        - ç‰¹æ®Šé‡‘èæˆ–ç¶“æ¿Ÿè¡“èªï¼šéœ€è¦é‡‘èèƒŒæ™¯æ‰èƒ½ç†è§£ï¼ˆå¦‚ã€Œè¡ç”Ÿæ€§é‡‘èå•†å“ã€ã€ã€Œé€šè²¨ç·Šç¸®èºæ—‹ã€ã€ã€Œé‡åŒ–å¯¬é¬†ã€ï¼‰

        **çµ•å°ä¸è¦æå–çš„è©å½™ï¼š**
        - ä»»ä½•åœ°åã€äººåã€å…¬å¸åã€å“ç‰Œåï¼ˆå¦‚ã€Œå°ç©é›»ã€ã€ã€Œè˜‹æœå…¬å¸ã€ã€ã€Œå¼µä¸‰ã€ã€ã€Œå°åŒ—ã€ï¼‰
        - æ”¿æ²»äººç‰©å§“åæˆ–è·ç¨±ï¼ˆå¦‚ã€Œç¸½çµ±ã€ã€ã€Œç«‹å§”ã€ã€ã€Œå¸‚é•·ã€ï¼‰
        - ä¸€èˆ¬å½¢å®¹è©ã€å‹•è©ã€å‰¯è©ï¼ˆå¦‚ã€Œé‡è¦ã€ã€ã€Œæå‡ã€ã€ã€Œå¿«é€Ÿã€ï¼‰
        - æ—¥å¸¸è©å½™æˆ–å¸¸è­˜æ¦‚å¿µï¼ˆå¦‚ã€ŒæŠ•è³‡ã€ã€ã€Œç¶“æ¿Ÿã€ã€ã€Œç™¼å±•ã€ã€ã€Œæˆé•·ã€ï¼‰
        - ç°¡å–®çš„æ•¸å­—ã€æ™‚é–“ã€æ¯”ä¾‹ã€å–®ä½ï¼ˆå¦‚ã€Œç™¾åˆ†æ¯”ã€ã€ã€Œå„„å…ƒã€ã€ã€Œå¹´åº¦ã€ï¼‰
        - å¸¸è¦‹çš„è¡Œæ¥­æˆ–éƒ¨é–€åç¨±ï¼ˆå¦‚ã€Œç§‘æŠ€æ¥­ã€ã€ã€Œè£½é€ æ¥­ã€ã€ã€Œæœå‹™æ¥­ã€ï¼‰
        - æ™®é€šçš„å•†æ¥­æˆ–ç®¡ç†è©å½™ï¼ˆå¦‚ã€Œç‡Ÿæ”¶ã€ã€ã€Œç²åˆ©ã€ã€ã€Œå¸‚å ç‡ã€ï¼‰

        **åˆ¤æ–·åŸå‰‡ï¼š**
        - å¦‚æœä¸€å€‹é«˜ä¸­ç•¢æ¥­ç”Ÿä¸éœ€è¦æŸ¥å­—å…¸å°±èƒ½ç†è§£ï¼Œå°±ä¸è¦é¸
        - å¦‚æœæ˜¯æ–°èä¸­å¸¸è¦‹çš„è©å½™ï¼Œå°±ä¸è¦é¸
        - å¦‚æœæ˜¯æ—¥å¸¸å°è©±ä¸­æœƒå‡ºç¾çš„è©å½™ï¼Œå°±ä¸è¦é¸
        - å¯§å¯æ¼æ‰é‚Šç·£æ¡ˆä¾‹ï¼Œä¹Ÿä¸è¦é¸åˆ°ä¸å¤ å›°é›£çš„è©å½™

        æ¨™é¡Œï¼š{title}
        å…§å®¹ï¼š{text}

        è«‹æ¥µåº¦åš´æ ¼ç¯©é¸ï¼Œæœ€å¤šé¸å‡º 3-5 å€‹æœ€å›°é›£çš„å°ˆæ¥­è¡“èªã€‚å¦‚æœæ–‡ç« ä¸­æ²’æœ‰çœŸæ­£å›°é›£çš„è©å½™ï¼Œè«‹å›å‚³ç©ºé™£åˆ—ã€‚

        è«‹åš´æ ¼ä»¥ JSON æ ¼å¼å›å‚³ï¼Œæ ¼å¼å¦‚ä¸‹ï¼š
        {{"keywords": ["é—œéµå­—1", "é—œéµå­—2", "..."]}}
        """
        result = self._call_gemini(prompt)
        time.sleep(self.api_config['call_delay_seconds'])
        return result.get('keywords', [])

    def get_word_explanation(self, word: str) -> Dict[str, Any]:
        """ç‚ºå–®ä¸€è©å½™ç”¢ç”Ÿè§£é‡‹å’Œå¯¦éš›æ‡‰ç”¨å¯¦ä¾‹"""
        prompt = f"""
        ä½ æ˜¯ä¸€ä½çŸ¥è­˜æ·µåšçš„è©å…¸ç·¨çº‚å°ˆå®¶ï¼Œæ“…é•·ç”¨å…·é«”å¯¦ä¾‹èªªæ˜æ¦‚å¿µã€‚
        é‡å°ä»¥ä¸‹è©å½™ï¼Œè«‹æä¾›ç´„ {self.proc_config['explanation_word_limit']} å­—çš„ã€Œåè©è§£é‡‹ã€å’Œã€Œæ‡‰ç”¨å¯¦ä¾‹ã€ã€‚

        è¦è§£é‡‹çš„è©å½™æ˜¯ï¼šã€Œ{word}ã€

        ã€Œæ‡‰ç”¨å¯¦ä¾‹ã€éƒ¨åˆ†ï¼Œè«‹ä¸è¦ç”¨å®Œæ•´çš„å¥å­é€ å¥ã€‚è«‹ç›´æ¥åˆ—å‡ºè©²è©å½™æœƒè¢«ä½¿ç”¨åˆ°çš„å…·é«”å ´æ™¯ã€æŠ€è¡“æˆ–ç”¢å“ã€‚
        æ ¼å¼è«‹åƒé€™æ¨£ï¼Œåˆ—èˆ‰å¹¾å€‹å¯¦éš›ä¾‹å­ï¼š
        - **ç¯„ä¾‹è¼¸å…¥ï¼š** äººå·¥æ™ºæ…§
        - **æœŸæœ›çš„æ‡‰ç”¨å¯¦ä¾‹è¼¸å‡ºï¼š** èªéŸ³åŠ©æ‰‹ï¼ˆå¦‚ Siriã€Alexaï¼‰ã€æ¨è–¦ç³»çµ±ã€è‡ªå‹•é§•é§›æ±½è»Šã€é†«ç™‚å½±åƒåˆ†æã€‚

        è«‹åš´æ ¼ä¾ç…§ä»¥ä¸‹ JSON æ ¼å¼å›å‚³ï¼Œä¸è¦æœ‰ä»»ä½• markdown æ¨™ç±¤æˆ–èªªæ˜æ–‡å­—ï¼š
        {{
            "term": "{word}",
            "definition": "ï¼ˆåœ¨æ­¤å¡«å¯«ç°¡æ½”çš„åè©è§£é‡‹ï¼‰",
            "examples": [
                {{
                    "title": "æ‡‰ç”¨å¯¦ä¾‹",
                    "text": "ï¼ˆåœ¨æ­¤æ¢åˆ—å¼å¡«å¯«å…·é«”çš„æ‡‰ç”¨å ´æ™¯æˆ–ç”¢å“ï¼Œè€Œéé€ å¥ï¼‰"
                }}
            ]
        }}
        """
        result = self._call_gemini(prompt)
        time.sleep(self.api_config['call_delay_seconds'])
        return result

    def get_word_explanation_from_context(self, word: str, context: str, title: str = "") -> Dict[str, Any]:
        """æ ¹æ“šæ–‡ç« å…§å®¹ç‚ºè©å½™ç”¢ç”Ÿè§£é‡‹ï¼ˆæŒ‰ç…§æŒ‡å®šæ ¼å¼ï¼‰"""
        prompt = f"""
        ä½ æ˜¯ä¸€ä½å°ˆæ¥­çš„çŸ¥è­˜ç·¨è¼¯ï¼Œæ“…é•·æ ¹æ“šæ–‡ç« å…§å®¹ç‚ºè©å½™æä¾›æº–ç¢ºçš„è§£é‡‹ã€‚
        
        è«‹æ ¹æ“šä»¥ä¸‹æ–°èå…§å®¹ï¼Œç‚ºæŒ‡å®šçš„è©å½™ã€Œ{word}ã€æä¾›è©³ç´°çš„è§£é‡‹ã€‚
        
        æ–°èæ¨™é¡Œï¼š{title}
        æ–°èå…§å®¹ï¼š{context}
        
        è¦è§£é‡‹çš„è©å½™ï¼šã€Œ{word}ã€
        
        è«‹æä¾›ï¼š
        1. è©³ç´°è§£é‡‹ï¼ˆ100-150å­—ï¼‰ï¼šèªªæ˜è©²è©å½™çš„å«ç¾©ã€èƒŒæ™¯ã€é‡è¦æ€§ç­‰
        2. ç›¸é—œæ‡‰ç”¨ä¾‹å­ï¼ˆ3-5å€‹ï¼‰ï¼šåˆ—å‡ºè©²è©å½™çš„å…·é«”æ‡‰ç”¨å ´æ™¯ã€ç›¸é—œç”¢å“æˆ–å¯¦éš›ä¾‹å­
        
        è«‹åš´æ ¼ä¾ç…§ä»¥ä¸‹ JSON æ ¼å¼å›å‚³ï¼Œä¸è¦æœ‰ä»»ä½• markdown æ¨™ç±¤æˆ–èªªæ˜æ–‡å­—ï¼š
        {{
            "term": "{word}",
            "explanation": "è©³ç´°çš„è§£é‡‹èªªæ˜ï¼ˆ100-150å­—ï¼‰",
            "examples": [
                "å…·é«”æ‡‰ç”¨ä¾‹å­1",
                "å…·é«”æ‡‰ç”¨ä¾‹å­2", 
                "å…·é«”æ‡‰ç”¨ä¾‹å­3",
                "å…·é«”æ‡‰ç”¨ä¾‹å­4",
                "å…·é«”æ‡‰ç”¨ä¾‹å­5"
            ]
        }}
        
        æ‡‰ç”¨ä¾‹å­æ ¼å¼è¦æ±‚ï¼š
        - æ¯å€‹ä¾‹å­è¦å…·é«”æ˜ç¢ºï¼Œé¿å…éæ–¼æŠ½è±¡
        - å¯ä»¥åŒ…å«ç”¢å“åç¨±ã€æŠ€è¡“æ‡‰ç”¨ã€ä½¿ç”¨å ´æ™¯ç­‰
        - ä¾‹å­è¦èˆ‡è©²è©å½™ç›´æ¥ç›¸é—œ
        - æä¾›3-5å€‹ä¾‹å­ï¼ˆå¯ä»¥å°‘æ–¼5å€‹ï¼Œä½†è‡³å°‘3å€‹ï¼‰
        
        ç¯„ä¾‹æ ¼å¼ï¼š
        - term: "åŠå°é«”"
        - explanation: "ä¸€ç¨®å°é›»æ€§ä»‹æ–¼å°é«”å’Œçµ•ç·£é«”ä¹‹é–“çš„ææ–™ï¼Œæ˜¯ç¾ä»£é›»å­ç”¢å“çš„æ ¸å¿ƒçµ„ä»¶..."
        - examples: ["æ™ºæ…§å‹æ‰‹æ©Ÿè™•ç†å™¨", "é›»è…¦è¨˜æ†¶é«”æ™¶ç‰‡", "LEDç…§æ˜å…ƒä»¶", "å¤ªé™½èƒ½é›»æ± æ¿", "é›»å‹•è»Šé›»æ± ç®¡ç†ç³»çµ±"]
        """
        result = self._call_gemini(prompt)
        time.sleep(self.api_config['call_delay_seconds'])
        return result

    def test_word_explanation_by_story_id(self, story_id: str, save_to_db: bool = False):
        """æ¸¬è©¦åŠŸèƒ½ï¼šæ ¹æ“šæŒ‡å®šçš„ story_id ç”Ÿæˆè©å½™è§£é‡‹
        
        Args:
            story_id: è¦è™•ç†çš„æ–°è ID
            save_to_db: æ˜¯å¦å°‡çµæœå­˜å…¥è³‡æ–™åº«
        """
        print(f"\n=== æ¸¬è©¦è©å½™è§£é‡‹åŠŸèƒ½ (story_id: {story_id}) ===")
        if save_to_db:
            print("ğŸ”„ æ¨¡å¼ï¼šç”Ÿæˆè©å½™è§£é‡‹ä¸¦å­˜å…¥è³‡æ–™åº«")
        else:
            print("ğŸ“‹ æ¨¡å¼ï¼šåƒ…ç”Ÿæˆè©å½™è§£é‡‹é è¦½")
        
        # 1. å¾ single_news è¡¨è®€å–æŒ‡å®š story_id çš„è³‡æ–™
        try:
            table_name = self.db_config['table_name']
            fields = ','.join(self.db_config['select_fields'])
            
            resp = self.supabase_client.table(table_name).select(fields).eq('story_id', story_id).execute()
            
            if getattr(resp, 'error', None):
                print(f"âœ— è®€å–æ–°èå¤±æ•—: {resp.error}")
                return
            
            news_data = resp.data
            if not news_data:
                print(f"âœ— æ‰¾ä¸åˆ° story_id: {story_id}")
                return
            
            news = news_data[0]
            title = news.get(self.db_config['title_field'], 'æœªçŸ¥æ¨™é¡Œ')
            content = news.get(self.db_config['primary_content_field'], '')
            
            if not content:
                print(f"âœ— story_id {story_id} çš„å…§å®¹ç‚ºç©º")
                return
            
            print(f"âœ“ æˆåŠŸè®€å–æ–°è: {title[:50]}...")
            print(f"âœ“ å…§å®¹é•·åº¦: {len(content)} å­—")
            
        except Exception as e:
            print(f"âœ— è®€å–æ–°èè³‡æ–™æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
            return
        
        # 2. æå–å›°é›£é—œéµå­—
        print(f"\n--- æ­¥é©Ÿ 1: æå–å›°é›£é—œéµå­— ---")
        keywords = self.extract_keywords_from_text(content, title)
        
        if not keywords:
            print("âœ— æœªæ‰¾åˆ°å›°é›£é—œéµå­—")
            return
        
        print(f"âœ“ æ‰¾åˆ° {len(keywords)} å€‹å›°é›£é—œéµå­—:")
        for i, keyword in enumerate(keywords, 1):
            print(f"  {i}. {keyword}")
        
        # 3. ç‚ºæ¯å€‹é—œéµå­—ç”ŸæˆåŸºæ–¼æ–‡æ„çš„è§£é‡‹
        print(f"\n--- æ­¥é©Ÿ 2: ç”Ÿæˆè©å½™è§£é‡‹ ---")
        explanations = {}
        
        for keyword in keywords:
            print(f"\næ­£åœ¨ç‚ºã€Œ{keyword}ã€ç”Ÿæˆè§£é‡‹...")
            explanation = self.get_word_explanation_from_context(keyword, content, title)
            
            if explanation and explanation.get('term'):
                explanations[keyword] = explanation
                print(f"âœ“ æˆåŠŸç”Ÿæˆè§£é‡‹")
            else:
                print(f"âœ— æœªèƒ½ç”Ÿæˆè§£é‡‹")
        
        # 4. è¼¸å‡ºçµæœ
        print(f"\n" + "=" * 80)
        print(f"æ¸¬è©¦çµæœæ‘˜è¦")
        print("=" * 80)
        print(f"æ–°èæ¨™é¡Œ: {title}")
        print(f"story_id: {story_id}")
        print(f"æå–é—œéµå­—æ•¸: {len(keywords)}")
        print(f"æˆåŠŸè§£é‡‹æ•¸: {len(explanations)}")
        
        # è©³ç´°é¡¯ç¤ºæ¯å€‹è©å½™çš„è§£é‡‹
        print(f"\n" + "="*60)
        print("ç”Ÿæˆçš„è©å½™è§£é‡‹")
        print("="*60)
        
        for i, (word, explanation) in enumerate(explanations.items(), 1):
            term = explanation.get('term', word)
            explanation_text = explanation.get('explanation', 'ç„¡è§£é‡‹')
            examples = explanation.get('examples', [])
            
            print(f"\nã€è©å½™ {i}ã€‘")
            print(f"{term}")
            print(f"{explanation_text}")
            if examples:
                examples_text = "ã€".join(examples)
                print(f"{examples_text}")
            print("-" * 40)
        
        # 5. å¦‚æœé¸æ“‡å­˜å…¥è³‡æ–™åº«ï¼ŒåŸ·è¡Œè³‡æ–™åº«æ“ä½œ
        if save_to_db and explanations:
            print(f"\n--- æ­¥é©Ÿ 3: å­˜å…¥è³‡æ–™åº« ---")
            
            # æº–å‚™ term_map è³‡æ–™
            new_combinations = []
            for keyword in keywords:
                new_combinations.append({
                    'story_id': story_id,
                    'term': keyword
                })
            
            # æº–å‚™ term è³‡æ–™
            new_terms = []
            for word, explanation in explanations.items():
                explanation_text = explanation.get('explanation', '')
                examples = explanation.get('examples', [])
                examples_text = "ã€".join(examples) if examples else ""  # å°‡ä¾‹å­åˆ—è¡¨è½‰ç‚ºå­—ä¸²
                
                new_terms.append({
                    'term': word,
                    'definition': explanation_text,
                    'example': examples_text  # å°‡ä¾‹å­åˆ—è¡¨å­˜å…¥ example æ¬„ä½
                })
            
            # æª¢æŸ¥ç¾æœ‰è³‡æ–™ä¸¦åŸ·è¡Œæ’å…¥
            print("æª¢æŸ¥ç¾æœ‰è³‡æ–™...")
            
            # æª¢æŸ¥ term_map é‡è¤‡æ€§
            existing_term_map = self._check_existing_single_term_map(story_id, keywords)
            filtered_combinations = [combo for combo in new_combinations 
                                   if (combo['story_id'], combo['term']) not in existing_term_map]
            
            # æª¢æŸ¥ term é‡è¤‡æ€§
            existing_terms = self._check_existing_single_terms(list(explanations.keys()))
            filtered_terms = [term for term in new_terms 
                            if term['term'] not in existing_terms]
            
            print(f"æº–å‚™æ’å…¥ term_map: {len(filtered_combinations)} ç­†")
            print(f"æº–å‚™æ’å…¥ term: {len(filtered_terms)} ç­†")
            
            # åŸ·è¡Œæ’å…¥
            if filtered_terms:
                term_success = self.insert_term_data(filtered_terms)
            else:
                term_success = True
                print("æ‰€æœ‰è©å½™å·²å­˜åœ¨æ–¼ term è¡¨ä¸­")
            
            if filtered_combinations:
                term_map_success = self.insert_term_map_data(filtered_combinations)
            else:
                term_map_success = True
                print("æ‰€æœ‰çµ„åˆå·²å­˜åœ¨æ–¼ term_map è¡¨ä¸­")
            
            # é¡¯ç¤ºæœ€çµ‚çµæœ
            if term_success and term_map_success:
                print("âœ… è³‡æ–™åº«å„²å­˜å®Œæˆï¼")
            else:
                print("âŒ éƒ¨åˆ†è³‡æ–™å„²å­˜å¤±æ•—")
        
        return explanations

    def _check_existing_single_term_map(self, story_id: str, keywords: List[str]) -> Set:
        """æª¢æŸ¥å–®ä¸€ story_id çš„ç¾æœ‰ term_map çµ„åˆ"""
        try:
            table_name = self.db_config['term_map_table']
            resp = self.supabase_client.table(table_name).select('story_id,term').eq('story_id', story_id).execute()
            
            if getattr(resp, 'error', None):
                print(f"è®€å–ç¾æœ‰ term_map å¤±æ•—: {resp.error}")
                return set()
            
            existing_combinations = set()
            for row in resp.data or []:
                story_id_val = row.get('story_id')
                term = row.get('term')
                if story_id_val and term:
                    existing_combinations.add((story_id_val, term))
            
            return existing_combinations
            
        except Exception as e:
            print(f"æª¢æŸ¥ç¾æœ‰ term_map æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
            return set()

    def _check_existing_single_terms(self, keywords: List[str]) -> Set:
        """æª¢æŸ¥å–®ä¸€è©å½™åˆ—è¡¨çš„ç¾æœ‰ term"""
        try:
            table_name = self.db_config['term_table']
            
            # ä½¿ç”¨ in_ æŸ¥è©¢æª¢æŸ¥å¤šå€‹è©å½™
            resp = self.supabase_client.table(table_name).select('term').in_('term', keywords).execute()
            
            if getattr(resp, 'error', None):
                print(f"è®€å–ç¾æœ‰ term å¤±æ•—: {resp.error}")
                return set()
            
            existing_terms = set()
            for row in resp.data or []:
                term = row.get('term')
                if term:
                    existing_terms.add(term)
            
            return existing_terms
            
        except Exception as e:
            print(f"æª¢æŸ¥ç¾æœ‰ term æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
            return set()

    def insert_term_map_data(self, new_combinations: List[Dict[str, str]]) -> bool:
        """å°‡æ–°çš„ term_map çµ„åˆæ’å…¥è³‡æ–™åº«"""
        if not new_combinations:
            print("æ²’æœ‰ term_map è³‡æ–™éœ€è¦æ’å…¥")
            return True
        
        print("\n=== é–‹å§‹æ’å…¥ term_map è³‡æ–™ ===")
        print(f"æº–å‚™æ’å…¥ {len(new_combinations)} ç­†è³‡æ–™åˆ° {self.db_config['term_map_table']} è¡¨")
        
        success_count = 0
        error_count = 0
        
        try:
            table_name = self.db_config['term_map_table']
            
            # æ‰¹æ¬¡æ’å…¥
            batch_size = 100  # æ¯æ‰¹æ’å…¥100ç­†
            for i in range(0, len(new_combinations), batch_size):
                batch = new_combinations[i:i + batch_size]
                
                try:
                    resp = self.supabase_client.table(table_name).insert(batch).execute()
                    
                    if getattr(resp, 'error', None):
                        print(f"æ‰¹æ¬¡ {i//batch_size + 1} æ’å…¥å¤±æ•—: {resp.error}")
                        error_count += len(batch)
                    else:
                        batch_success = len(batch)
                        success_count += batch_success
                        print(f"âœ“ æ‰¹æ¬¡ {i//batch_size + 1}: æˆåŠŸæ’å…¥ {batch_success} ç­†")
                
                except Exception as e:
                    print(f"âœ— æ‰¹æ¬¡ {i//batch_size + 1} ç™¼ç”ŸéŒ¯èª¤: {e}")
                    error_count += len(batch)
        
        except Exception as e:
            print(f"âœ— æ’å…¥ term_map æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
            return False
        
        print("\nterm_map æ’å…¥çµæœ:")
        print(f"  æˆåŠŸ: {success_count} ç­†")
        print(f"  å¤±æ•—: {error_count} ç­†")
        
        return error_count == 0

    def insert_term_data(self, new_terms: List[Dict[str, str]]) -> bool:
        """å°‡æ–°çš„é—œéµå­—å®šç¾©æ’å…¥ term è¡¨"""
        if not new_terms:
            print("æ²’æœ‰ term è³‡æ–™éœ€è¦æ’å…¥")
            return True
        
        print("\n=== é–‹å§‹æ’å…¥ term è³‡æ–™ ===")
        print(f"æº–å‚™æ’å…¥ {len(new_terms)} ç­†è³‡æ–™åˆ° {self.db_config['term_table']} è¡¨")
        
        success_count = 0
        error_count = 0
        
        try:
            table_name = self.db_config['term_table']
            
            # æ‰¹æ¬¡æ’å…¥
            batch_size = 50  # term è¡¨è³‡æ–™è¼ƒå¤§ï¼Œæ¯æ‰¹æ’å…¥50ç­†
            for i in range(0, len(new_terms), batch_size):
                batch = new_terms[i:i + batch_size]
                
                try:
                    resp = self.supabase_client.table(table_name).insert(batch).execute()
                    
                    if getattr(resp, 'error', None):
                        print(f"æ‰¹æ¬¡ {i//batch_size + 1} æ’å…¥å¤±æ•—: {resp.error}")
                        error_count += len(batch)
                    else:
                        batch_success = len(batch)
                        success_count += batch_success
                        print(f"âœ“ æ‰¹æ¬¡ {i//batch_size + 1}: æˆåŠŸæ’å…¥ {batch_success} ç­†")
                
                except Exception as e:
                    print(f"âœ— æ‰¹æ¬¡ {i//batch_size + 1} ç™¼ç”ŸéŒ¯èª¤: {e}")
                    error_count += len(batch)
        
        except Exception as e:
            print(f"âœ— æ’å…¥ term æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
            return False
        
        print("\nterm æ’å…¥çµæœ:")
        print(f"  æˆåŠŸ: {success_count} ç­†")
        print(f"  å¤±æ•—: {error_count} ç­†")
        
        return error_count == 0

    def check_existing_term_combinations(self, story_keywords: Dict) -> List[Dict[str, str]]:
        """æª¢æŸ¥ä¸¦æº–å‚™éœ€è¦æ’å…¥åˆ° term_map çš„æ–°çµ„åˆ"""
        print("\n=== æª¢æŸ¥ term_map é‡è¤‡æ€§ ===")
        
        # å…ˆå–å¾—ç¾æœ‰çš„æ‰€æœ‰ term_map çµ„åˆ
        try:
            table_name = self.db_config['term_map_table']
            query = self.supabase_client.table(table_name).select('story_id,term')
            resp = query.execute()
            
            if getattr(resp, 'error', None):
                print(f"è®€å– {table_name} å¤±æ•—: {resp.error}")
                return []
            
            existing_combinations = set()
            for row in resp.data or []:
                story_id = row.get('story_id')
                term = row.get('term')
                if story_id and term:
                    existing_combinations.add((story_id, term))
            
            print(f"ç¾æœ‰ term_map çµ„åˆæ•¸é‡: {len(existing_combinations)}")
            
        except Exception as e:
            print(f"è®€å–ç¾æœ‰ term_map è³‡æ–™æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
            return []
        
        # æª¢æŸ¥å“ªäº›çµ„åˆæ˜¯æ–°çš„
        new_combinations = []
        
        for story_id, story_data in story_keywords.items():
            new_keywords = story_data.get("new_keywords", [])
            
            for keyword in new_keywords:
                combination = (story_id, keyword)
                if combination not in existing_combinations:
                    new_combinations.append({
                        'story_id': story_id,
                        'term': keyword
                    })
        
        print(f"æº–å‚™æ’å…¥çš„æ–°çµ„åˆæ•¸é‡: {len(new_combinations)}")
        return new_combinations

    def check_existing_terms(self, word_explanations: Dict) -> List[Dict[str, str]]:
        """æª¢æŸ¥ä¸¦æº–å‚™éœ€è¦æ’å…¥åˆ° term è¡¨çš„æ–°é—œéµå­—å®šç¾©"""
        print("\n=== æª¢æŸ¥ term è¡¨é‡è¤‡æ€§ ===")
        
        # å…ˆå–å¾—ç¾æœ‰çš„æ‰€æœ‰ term
        try:
            table_name = self.db_config['term_table']
            query = self.supabase_client.table(table_name).select('term')
            resp = query.execute()
            
            if getattr(resp, 'error', None):
                print(f"è®€å– {table_name} å¤±æ•—: {resp.error}")
                return []
            
            existing_terms = set()
            for row in resp.data or []:
                term = row.get('term')
                if term:
                    existing_terms.add(term)
            
            print(f"ç¾æœ‰ term è¡¨ä¸­çš„é—œéµå­—æ•¸é‡: {len(existing_terms)}")
            
        except Exception as e:
            print(f"è®€å–ç¾æœ‰ term è³‡æ–™æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
            return []
        
        # æª¢æŸ¥å“ªäº›é—œéµå­—æ˜¯æ–°çš„
        new_terms = []
        
        for word, explanation in word_explanations.items():
            if word not in existing_terms:
                # å¾è§£é‡‹ä¸­æå–å®šç¾©å’Œæ‡‰ç”¨
                definition = explanation.get('definition', '')
                examples = explanation.get('examples', [])
                example_text = examples[0].get('text', '') if examples else ''
                
                new_terms.append({
                    'term': word,
                    'definition': definition,
                    'example': example_text
                })
        
        print(f"æº–å‚™æ’å…¥çš„æ–°é—œéµå­—æ•¸é‡: {len(new_terms)}")
        return new_terms

    def run(self, limit: Optional[int] = None):
        """åŸ·è¡Œå®Œæ•´çš„å›°é›£é—œéµå­—æå–æµç¨‹"""
        if not self.is_ready():
            print("âœ— ç³»çµ±æœªå°±ç·’ï¼Œç„¡æ³•åŸ·è¡Œ")
            return

        print("\n" + "=" * 80)
        print("  å›°é›£é—œéµå­—æå–ç³»çµ± - å¯å­˜å…¥è³‡æ–™åº«ç‰ˆæœ¬")
        print("=" * 80)

        # 1. è®€å–ä¸¦åˆä½µ Supabase single_news å’Œ term_map è³‡æ–™
        news_data = self.fetch_combined_data(limit)
        if not news_data:
            print("æœªå–å¾—ä»»ä½•è³‡æ–™")
            return

        # 2. æå–æ‰€æœ‰é—œéµå­—ï¼Œä¸¦æ ¹æ“š story_id çµ„ç¹”
        print("\n=== éšæ®µä¸€ï¼šå¾æ–°èä¸­æå–å›°é›£é—œéµå­— ===")
        story_keywords = {}
        all_keywords: Set[str] = set()
        
        content_field = self.db_config['primary_content_field']
        title_field = self.db_config['title_field']
        
        for news in tqdm(news_data, desc="è™•ç†æ–°è"):
            story_id = news.get('story_id')
            if story_id is None:
                continue

            title = news.get(title_field, 'æœªçŸ¥æ¨™é¡Œ')
            content = news.get(content_field, '')
            existing_terms = news.get('existing_terms', [])
            
            if not content:
                print(f"âš  story_id {story_id} çš„ {content_field} æ¬„ä½ç‚ºç©ºï¼Œè·³é")
                continue
            
            # æå–é—œéµå­—
            keywords = self.extract_keywords_from_text(content, title)
            
            # åˆä½µæ–°æå–çš„é—œéµå­—å’Œç¾æœ‰çš„ terms
            all_story_keywords = list(set(keywords + existing_terms))
            
            # æ›´æ–°ç¸½é—œéµå­—é›†åˆ
            all_keywords.update(all_story_keywords)
            
            # å°‡é—œéµå­—åŠ å…¥å°æ‡‰çš„ story_id
            story_keywords[story_id] = {
                "title": title,
                "keywords": all_story_keywords,
                "new_keywords": keywords,
                "existing_terms": existing_terms
            }

        unique_keywords = sorted(list(all_keywords))
        print(f"âœ“ éšæ®µä¸€å®Œæˆï¼šå…±æå– {len(unique_keywords)} å€‹ä¸é‡è¤‡é—œéµå­—ã€‚")

        # 3. ç‚ºé—œéµå­—ç”Ÿæˆè§£é‡‹
        print("\n=== éšæ®µäºŒï¼šç‚ºé—œéµå­—ç”Ÿæˆè§£é‡‹èˆ‡ç¯„ä¾‹ ===")
        word_explanations = {}
        for word in tqdm(unique_keywords, desc="ç”Ÿæˆè©å½™è§£é‡‹"):
            explanation = self.get_word_explanation(word)
            if explanation and "term" in explanation:
                word_explanations[word] = explanation
            else:
                print(f"âš  æœªèƒ½æˆåŠŸè§£é‡‹è©å½™ï¼š'{word}'")
        
        print(f"âœ“ éšæ®µäºŒå®Œæˆï¼šå…±æˆåŠŸè§£é‡‹ {len(word_explanations)} å€‹è©å½™ã€‚")

        # 4. æª¢æŸ¥ä¸¦æº–å‚™æ’å…¥è³‡æ–™
        print("\n=== éšæ®µä¸‰ï¼šæª¢æŸ¥é‡è¤‡æ€§ä¸¦æº–å‚™æ’å…¥ ===")
        new_combinations = self.check_existing_term_combinations(story_keywords)
        new_terms = self.check_existing_terms(word_explanations)
        
        # 5. åŸ·è¡Œè³‡æ–™åº«æ’å…¥
        print("\n=== éšæ®µå››ï¼šåŸ·è¡Œè³‡æ–™åº«æ’å…¥ ===")
        
        # å…ˆæ’å…¥ term è¡¨ï¼ˆé—œéµå­—å®šç¾©ï¼‰
        term_success = self.insert_term_data(new_terms)
        
        # å†æ’å…¥ term_map è¡¨ï¼ˆstory_id å’Œ term çš„é—œè¯ï¼‰
        term_map_success = self.insert_term_map_data(new_combinations)

        # 6. é¡¯ç¤ºæœ€çµ‚çµæœ
        print("\n" + "=" * 80)
        print("  åŸ·è¡Œå®Œæˆæ‘˜è¦")
        print("=" * 80)
        print(f"âœ“ è™•ç†æ–°èæ•¸é‡: {len(story_keywords)}")
        print(f"âœ“ ä¸é‡è¤‡é—œéµå­—: {len(unique_keywords)}")
        print(f"âœ“ æˆåŠŸè§£é‡‹è©å½™: {len(word_explanations)}")
        
        if new_terms:
            status = "âœ“ æˆåŠŸ" if term_success else "âœ— å¤±æ•—"
            print(f"{status} æ’å…¥ term è¡¨: {len(new_terms)} å€‹æ–°é—œéµå­—")
        
        if new_combinations:
            status = "âœ“ æˆåŠŸ" if term_map_success else "âœ— å¤±æ•—"
            print(f"{status} æ’å…¥ term_map è¡¨: {len(new_combinations)} ç­†æ–°çµ„åˆ")
        
        print("=" * 80)


def main():
    """ä¸»ç¨‹å¼å…¥å£"""
    print("=" * 80)
    print("  å›°é›£é—œéµå­—æå–ç³»çµ± - å¯å­˜å…¥è³‡æ–™åº«ç‰ˆæœ¬")
    print("=" * 80)
    
    # è§£ææŒ‡ä»¤åˆ—åƒæ•¸
    if len(sys.argv) > 1:
        first_arg = sys.argv[1]
        
        # æª¢æŸ¥æ˜¯å¦ç‚ºæ¸¬è©¦æ¨¡å¼
        if first_arg == "test" and len(sys.argv) > 2:
            story_id = sys.argv[2]
            
            # æª¢æŸ¥æ˜¯å¦è¦å­˜å…¥è³‡æ–™åº«
            save_to_db = False
            if len(sys.argv) > 3 and sys.argv[3] == "--save":
                save_to_db = True
                print(f"âœ“ æ¸¬è©¦æ¨¡å¼: ä½¿ç”¨ story_id = {story_id} (å­˜å…¥è³‡æ–™åº«)")
            else:
                print(f"âœ“ æ¸¬è©¦æ¨¡å¼: ä½¿ç”¨ story_id = {story_id} (åƒ…é è¦½)")
            
            try:
                processor = DiffKeywordProcessor()
                if processor.is_ready():
                    processor.test_word_explanation_by_story_id(story_id, save_to_db)
                else:
                    print("âœ— ç³»çµ±æœªå°±ç·’ï¼Œç„¡æ³•åŸ·è¡Œæ¸¬è©¦")
            except EnvironmentError as e:
                print(f"âœ— ç’°å¢ƒéŒ¯èª¤ï¼š{e}")
                print("è«‹æª¢æŸ¥æ‚¨çš„ .env è¨­å®šæª”ã€‚")
            except Exception as e:
                print(f"âœ— ç™¼ç”Ÿæœªé æœŸçš„éŒ¯èª¤ï¼š{e}")
            
            return
        
        # ä¸€èˆ¬æ¨¡å¼ï¼šè§£æ limit åƒæ•¸
        try:
            limit = int(first_arg)
            print(f"âœ“ è¨­å®šè®€å–é™åˆ¶: {limit} ç­†")
        except ValueError:
            print("âš  ç„¡æ•ˆçš„ limit åƒæ•¸ï¼Œå°‡è®€å–æ‰€æœ‰è³‡æ–™")
            limit = None
    else:
        limit = None
        print("âœ“ ä¸€èˆ¬æ¨¡å¼: è™•ç†æ‰€æœ‰è³‡æ–™")
    
    try:
        # åˆå§‹åŒ–ä¸¦åŸ·è¡Œè™•ç†å™¨
        processor = DiffKeywordProcessor()
        if processor.is_ready():
            processor.run(limit)
        
    except EnvironmentError as e:
        print(f"âœ— ç’°å¢ƒéŒ¯èª¤ï¼š{e}")
        print("è«‹æª¢æŸ¥æ‚¨çš„ .env è¨­å®šæª”ã€‚")
        sys.exit(1)
    except Exception as e:
        print(f"âœ— ç™¼ç”Ÿæœªé æœŸçš„éŒ¯èª¤ï¼š{e}")
        sys.exit(1)
        
    print("\n" + "=" * 80)
    print("ç³»çµ±åŸ·è¡Œå®Œç•¢ã€‚")
    print("=" * 80)


if __name__ == "__main__":
    main()
