"""æ–°èäº‹ä»¶åˆ†çµ„å™¨ - å®Œæ•´ç‰ˆ
ä½¿ç”¨ google.genai é€²è¡Œæ™ºèƒ½åˆ†çµ„
"""

import os
import sys
import json
import time
import uuid
from datetime import datetime
from dotenv import load_dotenv

# è¼‰å…¥ç’°å¢ƒè®Šæ•¸

load_dotenv()

SUPABASE_URL = os.getenv('SUPABASE_URL')
SUPABASE_KEY = os.getenv('SUPABASE_KEY')
GEMINI_API_KEY = os.getenv('GEMINI_API_KEY')

if not SUPABASE_URL or not SUPABASE_KEY:
    print("è«‹åœ¨ Picture_generate_system/.env è¨­å®š SUPABASE_URL èˆ‡ SUPABASE_KEY")
    sys.exit(1)
if not GEMINI_API_KEY:
    print("è«‹åœ¨ Picture_generate_system/.env è¨­å®š GEMINI_API_KEY")
    sys.exit(1)

try:
    from supabase import create_client
    print("âœ“ Supabase å¥—ä»¶å·²è¼‰å…¥")
except ImportError:
    print("è«‹å…ˆå®‰è£ supabase-pyï¼špip install supabase-py postgrest-py")
    sys.exit(1)

try:
    import google.genai as genai
    print("âœ“ Google Genai å¥—ä»¶å·²è¼‰å…¥")
except ImportError:
    print("è«‹å…ˆå®‰è£ google genai SDKï¼špip install google-genai")
    sys.exit(1)

class NewsEventGrouper:
    """æ–°èäº‹ä»¶åˆ†çµ„å™¨"""
    
    def __init__(self):
        """åˆå§‹åŒ–å®¢æˆ¶ç«¯"""
        self.supabase = create_client(SUPABASE_URL, SUPABASE_KEY)
        try:
            self.genai_client = genai.Client(api_key=GEMINI_API_KEY)
            print("âœ“ Gemini Client åˆå§‹åŒ–æˆåŠŸ")
        except Exception as e:
            print(f"âœ— Gemini Client åˆå§‹åŒ–å¤±æ•—: {e}")
            # ä½¿ç”¨ fallback æ–¹æ³•
            print("åˆ‡æ›åˆ° fallback æ¨¡å¼...")
            self.genai_client = None
        
    def fetch_topic_news_map_from_supabase(self):
        """å¾ Supabase çš„ topic_news_map è¡¨ç²å–ä¸»é¡Œæ–°èæ˜ å°„"""
        try:
            print("é–‹å§‹å¾ topic_news_map è¡¨ç²å–è³‡æ–™...")
            response = self.supabase.table('topic_news_map').select(
                'topic_id, story_id'
            ).execute()
            
            if response.data:
                print(f"âœ“ æˆåŠŸç²å– {len(response.data)} ç­†ä¸»é¡Œæ–°èæ˜ å°„è³‡æ–™")
                return response.data
            else:
                print("âœ— topic_news_map è¡¨ç„¡è³‡æ–™")
                return []
                
        except Exception as e:
            print(f"âœ— ç²å– topic_news_map è³‡æ–™æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
            return []
    
    def group_by_topic_id(self, topic_news_map):
        """æ ¹æ“š topic_id å°‡æ–°èåˆ†çµ„"""
        topic_groups = {}
        
        for item in topic_news_map:
            topic_id = item.get('topic_id')
            story_id = item.get('story_id')
            
            if topic_id and story_id:
                if topic_id not in topic_groups:
                    topic_groups[topic_id] = []
                topic_groups[topic_id].append(story_id)
        
        print(f"âœ“ æ ¹æ“š topic_id åˆ†æˆ {len(topic_groups)} å€‹ä¸»é¡Œçµ„")
        for topic_id, story_ids in topic_groups.items():
            print(f"  ä¸»é¡Œ {topic_id}: {len(story_ids)} å‰‡æ–°è")
        
        return topic_groups
    
    def read_story_ids_from_json(self, json_file_path):
        """å¾ JSON æª”æ¡ˆè®€å– story_id åˆ—è¡¨"""
        try:
            with open(json_file_path, 'r', encoding='utf-8') as f:
                data = json.load(f)
            
            story_ids = []
            if isinstance(data, list):
                for item in data:
                    if isinstance(item, dict):
                        story_id = (item.get('story_id') or 
                                  item.get('id') or 
                                  item.get('storyId'))
                        if story_id:
                            story_ids.append(str(story_id))
            
            print(f"å¾ {json_file_path} è®€å–åˆ° {len(story_ids)} å€‹ story_id")
            return list(set(story_ids))  # å»é‡
            
        except Exception as e:
            print(f"è®€å– JSON æª”æ¡ˆæ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
            return []
    
    def fetch_news_from_supabase(self, story_ids):
        """å¾ Supabase ç²å–æ–°èå…§å®¹"""
        news_items = []
        
        print(f"é–‹å§‹å¾ Supabase ç²å– {len(story_ids)} å‰‡æ–°è...")
        
        for i, story_id in enumerate(story_ids, 1):
            try:
                response = self.supabase.table('single_news').select(
                    'story_id, news_title, long'
                ).eq('story_id', story_id).execute()
                
                if response.data and len(response.data) > 0:
                    news_data = response.data[0]
                    news_items.append({
                        'story_id': news_data.get('story_id'),
                        'news_title': news_data.get('news_title', ''),
                        'content': news_data.get('long', '')
                    })
                    print(f"âœ“ {i}/{len(story_ids)}: æˆåŠŸç²å– story_id {story_id}")
                else:
                    print(f"âœ— {i}/{len(story_ids)}: story_id {story_id} æœªæ‰¾åˆ°å°æ‡‰æ–°è")
                    
            except Exception as e:
                print(f"âœ— {i}/{len(story_ids)}: ç²å– story_id {story_id} æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
                
            # é¿å…è«‹æ±‚éæ–¼é »ç¹
            time.sleep(0.1)
        
        print(f"æˆåŠŸç²å– {len(news_items)} å‰‡æ–°èå…§å®¹")
        return news_items
    
    def group_news_by_events_ai(self, news_items):
        """ä½¿ç”¨ Gemini AI å°‡æ–°èåˆ†çµ„ç‚ºäº‹ä»¶åˆ†æ”¯"""
        if not self.genai_client or not news_items:
            return self.simple_group_news(news_items)
        
        print("é–‹å§‹ä½¿ç”¨ Gemini AI åˆ†ææ–°èäº‹ä»¶...")
        
        # æº–å‚™æ–°èæ‘˜è¦è³‡æ–™ä¾›æ¨¡å‹åˆ†æ
        news_summaries = []
        for i, news in enumerate(news_items):
            title = news['news_title'][:100]  # å¢åŠ æ¨™é¡Œé•·åº¦
            content = news['content'][:300]   # å¢åŠ å…§å®¹é•·åº¦ä»¥æä¾›æ›´å¤šç´°ç¯€
            summary = f"æ–°è{i+1}ï¼šæ¨™é¡Œï¼š{title}ï¼›å…§å®¹ï¼š{content}..."
            news_summaries.append(summary)
        
        # æ§‹å»ºæç¤ºèª
        prompt = f"""
# è§’è‰²
ä½ æ˜¯ä¸€ä½é ‚å°–çš„æ–°èåˆ†æå°ˆå®¶ï¼Œæ“æœ‰è¶…é20å¹´çš„ç”¢æ¥­ç¶“é©—ã€‚ä½ æ“…é•·è­˜åˆ¥çœŸæ­£ç›¸é—œçš„æ–°èäº‹ä»¶ï¼Œä¸¦ä»¥**åš´æ ¼çš„æ¨™æº–**é€²è¡Œåˆ†çµ„ã€‚

# æ ¸å¿ƒä»»å‹™
åˆ†æä¸‹æ–¹æä¾›çš„ {len(news_items)} å‰‡æ–°èï¼Œå°‡å®ƒå€‘ä¾æ“šã€Œæ ¸å¿ƒäº‹ä»¶ã€é€²è¡Œ**åš´æ ¼ä¸”ç²¾æº–çš„**åˆä½µåˆ†çµ„ã€‚

# ä¸‰å¤§çµ•å°åŸå‰‡ (å¿…é ˆåš´æ ¼éµå®ˆ)
1.  **æ¯å€‹åˆ†çµ„å¿…é ˆè‡³å°‘åŒ…å« 5 å‰‡æ–°è**ï¼šé€™æ˜¯ç¡¬æ€§è¦å®šã€‚å¦‚æœæŸå€‹äº‹ä»¶åˆ†çµ„ä¸è¶³ 5 å‰‡æ–°èï¼Œä¸è¦å–®ç¨æˆç«‹åˆ†çµ„ï¼Œæ‡‰å°‡é€™äº›æ–°èæš«æ™‚æ­¸é¡ç‚ºã€Œå…¶ä»–ã€ï¼Œæˆ–å¼·åˆ¶ä½µå…¥ç›¸é—œåº¦æœ€é«˜çš„å…¶ä»–åˆ†çµ„ä¸­ã€‚
2.  **æ¡ç”¨åš´æ ¼çš„åˆ†çµ„æ¨™æº–**ï¼šåªæœ‰æ ¸å¿ƒäº‹ä»¶ã€é—œéµäººç‰©ã€ä¸»è¦æ”¿ç­–æˆ–é‡å¤§è­°é¡Œå®Œå…¨ä¸€è‡´çš„æ–°èæ‰èƒ½æ­¸ç‚ºåŒä¸€çµ„ã€‚ä¸è¦å°‡æ³›æ³›ç›¸é—œçš„æ–°èç¡¬æ€§åˆä½µã€‚
3.  **å¯§å°‘å‹¿æ¿«**ï¼šå¦‚æœç„¡æ³•æ‰¾åˆ°è‡³å°‘ 5 å‰‡æ–°èçš„æ˜ç¢ºå…±åŒäº‹ä»¶ï¼Œé€™äº›æ–°èæ‡‰è©²æ­¸é¡ç‚ºã€Œå…¶ä»–ç›¸é—œæ–°èã€ï¼Œä¸è¦å¼·åˆ¶è£½é€ ä¸åˆç†çš„åˆ†çµ„ã€‚

# æ–°èè³‡æ–™
{chr(1000).join(news_summaries)}

# åŸ·è¡Œæ­¥é©Ÿ (è«‹åœ¨å…§éƒ¨ä¾åºæ€è€ƒï¼Œåƒ…æœ€çµ‚è¼¸å‡º JSON)

### æ­¥é©Ÿä¸€ï¼šè­˜åˆ¥æ ¸å¿ƒäº‹ä»¶
ä»”ç´°é–±è®€å…¨éƒ¨ {len(news_items)} å‰‡æ–°èï¼Œè­˜åˆ¥å‡ºçœŸæ­£æ˜ç¢ºçš„æ ¸å¿ƒäº‹ä»¶ã€‚æ ¸å¿ƒäº‹ä»¶å¿…é ˆå…·å‚™ï¼š
- æ˜ç¢ºçš„ä¸»é¡Œæˆ–è­°é¡Œï¼ˆä¾‹å¦‚ï¼šç‰¹å®šæ³•æ¡ˆã€ç‰¹å®šäººç‰©é†œèã€ç‰¹å®šç½å®³äº‹ä»¶ï¼‰
- è‡³å°‘ 5 å‰‡æ–°èç›´æ¥ç›¸é—œ
- æ–°èä¹‹é–“æœ‰æ˜ç¢ºçš„é—œè¯æ€§ï¼ˆåŒä¸€äº‹ä»¶çš„ä¸åŒé¢å‘ã€ç™¼å±•éšæ®µæˆ–å½±éŸ¿å±¤é¢ï¼‰

### æ­¥é©ŸäºŒï¼šå»ºç«‹åš´æ ¼çš„åˆ†çµ„
åªç‚ºç¬¦åˆä»¥ä¸‹æ¢ä»¶çš„äº‹ä»¶å»ºç«‹åˆ†çµ„ï¼š
- **è‡³å°‘ 5 å‰‡æ–°è**æ˜ç¢ºè¨è«–åŒä¸€æ ¸å¿ƒäº‹ä»¶
- æ–°èä¹‹é–“çš„é—œè¯æ€§å¼·ï¼ˆä¸æ˜¯æ³›æ³›ç›¸é—œï¼‰
- äº‹ä»¶æœ‰æ¸…æ™°çš„ä¸»é¡Œå®šç¾©

å¦‚æœæŸäº›æ–°èï¼š
- çœ‹ä¼¼ç›¸é—œä½†ä¸è¶³ 5 å‰‡
- ä¸»é¡Œè¼ƒç‚ºåˆ†æ•£
- ç„¡æ³•æ‰¾åˆ°æ˜ç¢ºçš„æ ¸å¿ƒäº‹ä»¶
â†’ å°‡é€™äº›æ–°èå…¨éƒ¨æ­¸é¡ç‚ºã€Œå…¶ä»–ç›¸é—œæ–°èã€

### æ­¥é©Ÿä¸‰ï¼šé©—è­‰åˆ†çµ„åš´æ ¼æ€§
æª¢æŸ¥æ¯å€‹åˆ†çµ„ï¼š
- âœ“ æ˜¯å¦è‡³å°‘åŒ…å« 5 å‰‡æ–°èï¼Ÿï¼ˆä¸è¶³ 5 å‰‡â†’ç§»åˆ°ã€Œå…¶ä»–ã€ï¼‰
- âœ“ æ–°èä¹‹é–“æ˜¯å¦æœ‰æ˜ç¢ºçš„æ ¸å¿ƒäº‹ä»¶é€£çµï¼Ÿï¼ˆé—œè¯å¤ªå¼±â†’ç§»åˆ°ã€Œå…¶ä»–ã€ï¼‰
- âœ“ äº‹ä»¶æ¨™é¡Œæ˜¯å¦ç²¾æº–æè¿°æ‰€æœ‰æ–°èçš„å…±åŒä¸»é¡Œï¼Ÿï¼ˆå¤ªæ¨¡ç³Šâ†’é‡æ–°è©•ä¼°ï¼‰

### æ­¥é©Ÿå››ï¼šç”Ÿæˆæœ€çµ‚è¼¸å‡º
åœ¨ä½ ç¢ºèªæ‰€æœ‰åŸå‰‡éƒ½å·²æ»¿è¶³å¾Œï¼Œæ‰å°‡æœ€çµ‚çµæœæ ¼å¼åŒ–ç‚º JSONã€‚

# æœ€çµ‚è¼¸å‡ºè¦æ±‚
**åƒ…å›å‚³æ¨™æº–çš„ JSON æ ¼å¼**ï¼Œä¸è¦åŒ…å«ä»»ä½•èª¬æ˜ã€è¨»è§£æˆ– ```json ... ``` æ¨™è¨˜ã€‚

{{
  "groups": [
    {{
      "event_title": "ç²¾ç…‰çš„æ ¸å¿ƒäº‹ä»¶æ¨™é¡Œ (10å­—å…§)",
      "event_summary": "å…¨é¢ä¸”å®¢è§€åœ°ç¸½çµè©²äº‹ä»¶çš„æ ¸å¿ƒå…§å®¹ (80å­—å…§)",
      "news_indices": [/* æ–°èç·¨è™Ÿé™£åˆ—ï¼Œå¾ 1 é–‹å§‹ï¼Œä¾‹å¦‚ [1, 5, 8] */]
    }},
    {{
      "event_title": "å¦ä¸€å€‹äº‹ä»¶çš„ç²¾ç…‰æ¨™é¡Œ (10å­—å…§)",
      "event_summary": "å¦ä¸€å€‹äº‹ä»¶çš„æ ¸å¿ƒå…§å®¹ç¸½çµ",
      "news_indices": [/* ... */]
    }}
  ]
}}

åš´æ ¼åˆ†çµ„åŸå‰‡ï¼š
1. **æ¯å€‹åˆ†çµ„è‡³å°‘ 5 å‰‡æ–°è** - é€™æ˜¯å¼·åˆ¶è¦æ±‚
2. åªæœ‰æ ¸å¿ƒäº‹ä»¶å®Œå…¨ä¸€è‡´çš„æ–°èæ‰èƒ½åˆ†åœ¨ä¸€çµ„
3. äº‹ä»¶æ¨™é¡Œå¿…é ˆç²¾æº–ï¼ˆ8-10å­—ï¼‰ï¼Œèƒ½æ¸…æ¥šæè¿°æ ¸å¿ƒäº‹ä»¶
4. ä¸è¶³ 5 å‰‡çš„ç›¸é—œæ–°èçµ±ä¸€æ”¾å…¥ã€Œå…¶ä»–ç›¸é—œæ–°èã€åˆ†çµ„
5. news_indices å°æ‡‰æ–°èçš„ç·¨è™Ÿï¼ˆå¾1é–‹å§‹ï¼‰
6. å¯§é¡˜æœ‰ä¸€å€‹å¤§çš„ã€Œå…¶ä»–ã€åˆ†çµ„ï¼Œä¹Ÿä¸è¦è£½é€ ä¸åˆç†çš„å°åˆ†çµ„
7. åªå›å‚³ JSONï¼Œä¸è¦å…¶ä»–èªªæ˜æ–‡å­—

æ³¨æ„ï¼šå¦‚æœæ‰€æœ‰æ–°èéƒ½ç„¡æ³•å½¢æˆè‡³å°‘ 5 å‰‡çš„æ˜ç¢ºäº‹ä»¶çµ„ï¼Œå‰‡å…¨éƒ¨æ­¸é¡ç‚ºã€Œå…¶ä»–ç›¸é—œæ–°èã€ã€‚

"""

        try:
            response = self.genai_client.models.generate_content(
                model='gemini-2.5-flash',
                contents=prompt
            )
            result_text = response.text.strip()
            
            # è§£æ JSON çµæœ
            if result_text.startswith('```json'):
                result_text = result_text[7:-3].strip()
            elif result_text.startswith('```'):
                result_text = result_text[3:-3].strip()
            
            result = json.loads(result_text)
            groups = result.get('groups', [])
            
            print(f"AI åˆ†æå®Œæˆï¼Œåˆæ­¥åˆ†ç‚º {len(groups)} å€‹äº‹ä»¶åˆ†æ”¯")
            
            # è½‰æ›ç‚ºæœ€çµ‚æ ¼å¼ï¼Œä¸¦åš´æ ¼éæ¿¾ä¸è¶³5ç¯‡çš„åˆ†æ”¯
            event_groups = []
            other_news_items = []  # æ”¶é›†ä¸è¶³5ç¯‡æˆ–æœªåˆ†é…çš„æ–°è
            used_news_indices = set()  # è¿½è¹¤å·²ä½¿ç”¨çš„æ–°èç´¢å¼•
            
            for group in groups:
                event_title = group.get('event_title', 'æœªå‘½åäº‹ä»¶')
                event_summary = group.get('event_summary', '')
                news_indices = group.get('news_indices', [])
                
                # ç²å–å°æ‡‰çš„æ–°èé …ç›®ï¼Œæ’é™¤å·²ä½¿ç”¨çš„æ–°è
                group_news = []
                for idx in news_indices:
                    if 1 <= idx <= len(news_items) and idx not in used_news_indices:
                        group_news.append(news_items[idx - 1])  # è½‰æ›ç‚º0-basedç´¢å¼•
                        used_news_indices.add(idx)  # æ¨™è¨˜ç‚ºå·²ä½¿ç”¨
                
                # æª¢æŸ¥æ˜¯å¦ç‚ºã€Œå…¶ä»–ã€é¡åˆ¥çš„åˆ†æ”¯ï¼ˆæ¨™é¡ŒåŒ…å«ã€Œå…¶ä»–ã€é—œéµå­—ï¼‰
                is_other_branch = 'å…¶ä»–' in event_title or 'other' in event_title.lower()
                
                # åš´æ ¼æª¢æŸ¥ï¼šåªä¿ç•™è‡³å°‘5ç¯‡æ–°èçš„åˆ†æ”¯ï¼Œä½†ã€Œå…¶ä»–ã€åˆ†æ”¯æœƒç‰¹åˆ¥è™•ç†
                if is_other_branch:
                    # AI æ¨™è¨˜ç‚ºã€Œå…¶ä»–ã€çš„æ–°èç›´æ¥åŠ å…¥ other_news_items
                    other_news_items.extend(group_news)
                    print(f"  âš™ï¸  AIåˆ†çµ„çš„ã€Œå…¶ä»–ã€: {event_title} ({len(group_news)} ç¯‡) â†’ ä½µå…¥çµ±ä¸€ã€Œå…¶ä»–ã€åˆ†æ”¯")
                elif len(group_news) >= 5:
                    event_groups.append({
                        'event_id': str(uuid.uuid4()),
                        'event_title': event_title,
                        'event_summary': event_summary,
                        'news_count': len(group_news),
                        'news_items': group_news
                    })
                    print(f"  âœ“ ä¿ç•™åˆ†æ”¯: {event_title} ({len(group_news)} ç¯‡)")
                elif len(group_news) > 0:
                    # ä¸è¶³5ç¯‡çš„æ–°èæ”¾å…¥ã€Œå…¶ä»–ã€
                    other_news_items.extend(group_news)
                    print(f"  âœ— åˆ†æ”¯ä¸è¶³5ç¯‡: {event_title} ({len(group_news)} ç¯‡) â†’ ç§»è‡³ã€Œå…¶ä»–ã€")
            
            # æª¢æŸ¥æ˜¯å¦æœ‰æœªåˆ†é…çš„æ–°è
            all_indices = set(range(1, len(news_items) + 1))
            unused_indices = all_indices - used_news_indices
            
            if unused_indices:
                unused_news = [news_items[idx - 1] for idx in unused_indices]
                other_news_items.extend(unused_news)
                print(f"  âš ï¸  ç™¼ç¾ {len(unused_indices)} å‰‡æœªåˆ†é…çš„æ–°è â†’ ç§»è‡³ã€Œå…¶ä»–ã€")
            
            # çµ±ä¸€å‰µå»ºä¸€å€‹ã€Œå…¶ä»–ç›¸é—œæ–°èã€åˆ†æ”¯ï¼ˆåˆä½µæ‰€æœ‰ä¾†æºï¼‰
            if other_news_items:
                event_groups.append({
                    'event_id': str(uuid.uuid4()),
                    'event_title': 'å…¶ä»–ç›¸é—œæ–°è',
                    'event_summary': f'åŒ…å« {len(other_news_items)} å‰‡æœªé”åˆ†æ”¯é–€æª»æˆ–ç„¡æ˜ç¢ºä¸»é¡Œçš„ç›¸é—œæ–°è',
                    'news_count': len(other_news_items),
                    'news_items': other_news_items
                })
                print(f"  â†’ å»ºç«‹çµ±ä¸€ã€Œå…¶ä»–ç›¸é—œæ–°èã€åˆ†æ”¯ ({len(other_news_items)} ç¯‡)")
            
            print(f"\næœ€çµ‚çµæœï¼š{len(event_groups)} å€‹åˆ†æ”¯")
            
            return event_groups
            
        except Exception as e:
            print(f"AI åˆ†ææ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
            print("åˆ‡æ›åˆ°ç°¡å–®åˆ†çµ„æ¨¡å¼...")
            return self.simple_group_news(news_items)
    
    def simple_group_news(self, news_items):
        """ç°¡å–®çš„æ–°èåˆ†çµ„ï¼ˆä¸ä½¿ç”¨ AIï¼‰"""
        return [{
            'event_id': str(uuid.uuid4()),
            'event_title': 'ç¶œåˆæ–°èäº‹ä»¶',
            'event_summary': f'åŒ…å« {len(news_items)} å‰‡ç›¸é—œæ–°èçš„ç¶œåˆäº‹ä»¶',
            'news_count': len(news_items),
            'news_items': news_items
        }]
    
    def save_to_database(self, event_groups, save_mode="both"):
        """å°‡äº‹ä»¶åˆ†æ”¯å’Œæ–°èæ˜ å°„å­˜å…¥è³‡æ–™åº«
        
        Args:
            event_groups: è™•ç†å¥½çš„äº‹ä»¶åˆ†çµ„è³‡æ–™
            save_mode: å„²å­˜æ¨¡å¼ - "preview"(åƒ…é è¦½), "database"(åƒ…è³‡æ–™åº«), "both"(é è¦½+è³‡æ–™åº«)
        """
        try:
            print(f"\né–‹å§‹è³‡æ–™åº«å„²å­˜æµç¨‹ (æ¨¡å¼: {save_mode})...")
            
            # æº–å‚™å…©å€‹è³‡æ–™è¡¨çš„è³‡æ–™
            topic_branch_news_map_data = []
            topic_branch_data = []
            
            for topic_group in event_groups:
                topic_id = topic_group.get('topic_id')
                sub_events = topic_group.get('sub_events', [])
                
                for sub_event in sub_events:
                    topic_branch_id = sub_event.get('event_id')
                    topic_branch_title = sub_event.get('event_title')
                    topic_branch_content = sub_event.get('event_summary')
                    news_items = sub_event.get('news_items', [])
                    
                    # 1. æº–å‚™ topic_branch è³‡æ–™
                    if topic_id and topic_branch_id and topic_branch_title:
                        topic_branch_data.append({
                            'topic_id': topic_id,
                            'topic_branch_id': topic_branch_id,
                            'topic_branch_title': topic_branch_title,
                            'topic_branch_content': topic_branch_content or ''
                        })
                    
                    # 2. æº–å‚™ topic_branch_news_map è³‡æ–™
                    for news_item in news_items:
                        story_id = news_item.get('story_id')
                        if topic_branch_id and story_id:
                            topic_branch_news_map_data.append({
                                'topic_branch_id': topic_branch_id,
                                'story_id': story_id
                            })
            
            print(f"æº–å‚™è³‡æ–™: {len(topic_branch_data)} å€‹åˆ†æ”¯, {len(topic_branch_news_map_data)} ç­†æ–°èå°æ‡‰")
            
            # æ ¹æ“šæ¨¡å¼åŸ·è¡Œç›¸æ‡‰æ“ä½œ
            if save_mode in ["preview", "both"]:
                self._save_database_preview(topic_branch_data, topic_branch_news_map_data)
            
            if save_mode in ["database", "both"]:
                self._save_to_actual_database(topic_branch_data, topic_branch_news_map_data)
                
        except Exception as e:
            print(f"âœ— è³‡æ–™åº«å„²å­˜æµç¨‹ç™¼ç”ŸéŒ¯èª¤: {e}")
    
    def _save_database_preview(self, topic_branch_data, topic_branch_news_map_data):
        """å„²å­˜è³‡æ–™åº«é è¦½æª”æ¡ˆ"""
        try:
            print("\n--- ç”Ÿæˆè³‡æ–™åº«é è¦½æª”æ¡ˆ ---")
            
            # å„²å­˜ topic_branch é è¦½
            topic_branch_file = "database_preview_topic_branch.json"
            with open(topic_branch_file, 'w', encoding='utf-8') as f:
                json.dump(topic_branch_data, f, ensure_ascii=False, indent=2)
            print(f"âœ“ topic_branch é è¦½å·²å„²å­˜: {topic_branch_file}")
            print(f"  å…± {len(topic_branch_data)} å€‹ä¸»é¡Œåˆ†æ”¯")
            
            # å„²å­˜ topic_branch_news_map é è¦½
            topic_branch_news_map_file = "database_preview_topic_branch_news_map.json"
            with open(topic_branch_news_map_file, 'w', encoding='utf-8') as f:
                json.dump(topic_branch_news_map_data, f, ensure_ascii=False, indent=2)
            print(f"âœ“ topic_branch_news_map é è¦½å·²å„²å­˜: {topic_branch_news_map_file}")
            print(f"  å…± {len(topic_branch_news_map_data)} ç­†å°æ‡‰é—œä¿‚")
            
            # é¡¯ç¤ºç¯„ä¾‹
            print("\nã€topic_branch ç¯„ä¾‹ã€‘")
            for i, item in enumerate(topic_branch_data[:3], 1):
                print(f"{i}. topic_id: {item['topic_id']}")
                print(f"   topic_branch_id: {item['topic_branch_id']}")
                print(f"   topic_branch_title: {item['topic_branch_title']}")
                print(f"   topic_branch_content: {item['topic_branch_content'][:50]}...")
                print()
            
            print("ã€topic_branch_news_map ç¯„ä¾‹ã€‘")
            for i, item in enumerate(topic_branch_news_map_data[:5], 1):
                print(f"{i}. {item['topic_branch_id']} <-> {item['story_id']}")
            
            if len(topic_branch_news_map_data) > 5:
                print(f"... é‚„æœ‰ {len(topic_branch_news_map_data) - 5} ç­†è³‡æ–™")
            
        except Exception as e:
            print(f"âœ— ç”Ÿæˆé è¦½æª”æ¡ˆæ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
    
    def _save_to_actual_database(self, topic_branch_data, topic_branch_news_map_data):
        """å„²å­˜åˆ°å¯¦éš›è³‡æ–™åº«"""
        try:
            print("\n--- é–‹å§‹å„²å­˜åˆ°å¯¦éš›è³‡æ–™åº« ---")
            
            # å„²å­˜ topic_branch è³‡æ–™
            print("1. å„²å­˜ topic_branch è³‡æ–™...")
            if topic_branch_data:
                # æ¸…é™¤ç¾æœ‰è³‡æ–™ï¼ˆå¯é¸ - æ ¹æ“šéœ€æ±‚æ±ºå®šï¼‰
                # self.supabase.table('topic_branch').delete().neq('topic_id', '').execute()
                
                batch_size = 50
                success_count = 0
                
                for i in range(0, len(topic_branch_data), batch_size):
                    batch = topic_branch_data[i:i + batch_size]
                    try:
                        response = self.supabase.table('topic_branch').upsert(batch).execute()
                        if response.data:
                            success_count += len(batch)
                            print(f"   âœ“ topic_branch ç¬¬ {i//batch_size + 1} æ‰¹ ({len(batch)} ç­†)")
                        else:
                            print(f"   âœ— topic_branch ç¬¬ {i//batch_size + 1} æ‰¹æ’å…¥å¤±æ•—")
                    except Exception as e:
                        print(f"   âœ— topic_branch ç¬¬ {i//batch_size + 1} æ‰¹ç™¼ç”ŸéŒ¯èª¤: {e}")
                
                print(f"   â†’ topic_branch æˆåŠŸå„²å­˜: {success_count}/{len(topic_branch_data)} ç­†")
            
            # å„²å­˜ topic_branch_news_map è³‡æ–™
            print("2. å„²å­˜ topic_branch_news_map è³‡æ–™...")
            if topic_branch_news_map_data:
                # æ¸…é™¤ç¾æœ‰è³‡æ–™ï¼ˆå¯é¸ï¼‰
                # self.supabase.table('topic_branch_news_map').delete().neq('topic_branch_id', '').execute()
                
                batch_size = 100
                success_count = 0
                
                for i in range(0, len(topic_branch_news_map_data), batch_size):
                    batch = topic_branch_news_map_data[i:i + batch_size]
                    try:
                        response = self.supabase.table('topic_branch_news_map').upsert(batch).execute()
                        if response.data:
                            success_count += len(batch)
                            print(f"   âœ“ topic_branch_news_map ç¬¬ {i//batch_size + 1} æ‰¹ ({len(batch)} ç­†)")
                        else:
                            print(f"   âœ— topic_branch_news_map ç¬¬ {i//batch_size + 1} æ‰¹æ’å…¥å¤±æ•—")
                    except Exception as e:
                        print(f"   âœ— topic_branch_news_map ç¬¬ {i//batch_size + 1} æ‰¹ç™¼ç”ŸéŒ¯èª¤: {e}")
                
                print(f"   â†’ topic_branch_news_map æˆåŠŸå„²å­˜: {success_count}/{len(topic_branch_news_map_data)} ç­†")
            
            print("\nâœ… è³‡æ–™åº«å„²å­˜å®Œæˆï¼")
            
        except Exception as e:
            print(f"âœ— å„²å­˜åˆ°å¯¦éš›è³‡æ–™åº«æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
    
    def save_to_json(self, event_groups, output_path):
        """å„²å­˜çµæœåˆ° JSON æª”æ¡ˆ"""
        try:
            with open(output_path, 'w', encoding='utf-8') as f:
                json.dump(event_groups, f, ensure_ascii=False, indent=2)
            print(f"çµæœå·²å„²å­˜è‡³: {output_path}")
        except Exception as e:
            print(f"å„²å­˜æª”æ¡ˆæ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
    
    def process_from_topic_map(self, output_path, save_to_db=True):
        """ä½¿ç”¨ topic_news_map çš„è™•ç†æµç¨‹
        
        Args:
            output_path: JSON è¼¸å‡ºæª”æ¡ˆè·¯å¾‘
            save_to_db: æ˜¯å¦å„²å­˜åˆ°è³‡æ–™åº« (True=å„²å­˜, False=åƒ…é è¦½)
        """
        print("=" * 60)
        print("æ–°èäº‹ä»¶åˆ†çµ„å™¨ - å¾ topic_news_map é–‹å§‹è™•ç†")
        print("=" * 60)
        
        # 1. å¾ topic_news_map ç²å–è³‡æ–™
        topic_news_map = self.fetch_topic_news_map_from_supabase()
        if not topic_news_map:
            print("æœªç²å–åˆ° topic_news_map è³‡æ–™ï¼Œç¨‹å¼çµæŸ")
            return
        
        # 2. æ ¹æ“š topic_id åˆ†çµ„
        topic_groups = self.group_by_topic_id(topic_news_map)
        if not topic_groups:
            print("æœªæ‰¾åˆ°æœ‰æ•ˆçš„ä¸»é¡Œåˆ†çµ„ï¼Œç¨‹å¼çµæŸ")
            return
        
        # 3. ç‚ºæ¯å€‹ä¸»é¡Œçµ„ç²å–æ–°èå…§å®¹ï¼Œç„¶å¾Œå†ç”¨ AI åšç´°åˆ†
        all_topic_events = []
        
        for topic_id, story_ids in topic_groups.items():
            print(f"\nè™•ç†ä¸»é¡Œ {topic_id} ({len(story_ids)} å‰‡æ–°è)...")
            
            # ç²å–è©²ä¸»é¡Œçš„æ–°èå…§å®¹
            news_items = self.fetch_news_from_supabase(story_ids)
            
            if not news_items:
                print(f"âœ— ä¸»é¡Œ {topic_id}: æœªç²å–åˆ°æœ‰æ•ˆæ–°èå…§å®¹")
                continue
            
            # ç‚ºè©²ä¸»é¡Œç”Ÿæˆç¸½é«”æ¨™é¡Œ
            topic_title = self.generate_topic_title(news_items)
            print(f"âœ“ ä¸»é¡Œ {topic_id}: {topic_title}")
            
            # å¦‚æœæ–°èæ•¸é‡è¼ƒå°‘ï¼ˆ<=3å‰‡ï¼‰ï¼Œç›´æ¥ä½œç‚ºä¸€å€‹åˆ†æ”¯
            if len(news_items) <= 3:
                topic_summary = self.generate_topic_summary(news_items)
                topic_event = {
                    'topic_id': topic_id,
                    'topic_title': topic_title,
                    'sub_events': [
                        {
                            'event_id': str(uuid.uuid4()),
                            'event_title': topic_title,
                            'event_summary': topic_summary,
                            'news_count': len(news_items),
                            'news_items': news_items
                        }
                    ]
                }
                all_topic_events.append(topic_event)
                print(f"  â†’ å–®ä¸€åˆ†æ”¯: {topic_title} ({len(news_items)} å‰‡æ–°è)")
            
            else:
                # æ–°èæ•¸é‡è¼ƒå¤šï¼Œä½¿ç”¨ AI é€²è¡Œç´°åˆ†
                print(f"  æ­£åœ¨å° {len(news_items)} å‰‡æ–°èé€²è¡Œ AI ç´°åˆ†...")
                sub_events = self.group_news_by_events_ai(news_items)
                
                # ç‚ºæ¯å€‹å­äº‹ä»¶æ·»åŠ  topic ç›¸é—œè³‡è¨Š
                for sub_event in sub_events:
                    sub_event['topic_id'] = topic_id
                
                topic_event = {
                    'topic_id': topic_id,
                    'topic_title': topic_title,
                    'sub_events': sub_events
                }
                all_topic_events.append(topic_event)
                
                print(f"  â†’ ç´°åˆ†ç‚º {len(sub_events)} å€‹åˆ†æ”¯:")
                for i, sub_event in enumerate(sub_events, 1):
                    print(f"    åˆ†æ”¯ {i}: {sub_event['event_title']} ({sub_event['news_count']} å‰‡æ–°è)")
        
        # 4. å„²å­˜çµæœåˆ° JSON
        self.save_to_json(all_topic_events, output_path)
        
        # 5. å„²å­˜åˆ°è³‡æ–™åº«æˆ–ç”Ÿæˆé è¦½
        if save_to_db:
            save_mode = "both"  # åŒæ™‚ç”Ÿæˆé è¦½å’Œå„²å­˜åˆ°è³‡æ–™åº«
            print("\nå°‡åŒæ™‚ç”Ÿæˆé è¦½æª”æ¡ˆä¸¦å„²å­˜åˆ°è³‡æ–™åº«...")
        else:
            save_mode = "preview"  # åƒ…ç”Ÿæˆé è¦½
            print("\nåƒ…ç”Ÿæˆè³‡æ–™åº«é è¦½æª”æ¡ˆ...")
        
        self.save_to_database(all_topic_events, save_mode)
        
        # 6. è¼¸å‡ºçµ±è¨ˆè³‡è¨Š
        print("\n" + "=" * 60)
        print("è™•ç†å®Œæˆ - çµ±è¨ˆè³‡è¨Š")
        print("=" * 60)
        print(f"ä¸»é¡Œæ•¸é‡: {len(topic_groups)}")
        print(f"æˆåŠŸè™•ç†çš„ä¸»é¡Œ: {len(all_topic_events)}")
        
        total_sub_events = sum(len(topic['sub_events']) for topic in all_topic_events)
        total_news = sum(
            sum(sub_event['news_count'] for sub_event in topic['sub_events'])
            for topic in all_topic_events
        )
        print(f"ç¸½åˆ†æ”¯æ•¸é‡: {total_sub_events}")
        print(f"ç¸½æ–°èæ•¸é‡: {total_news}")
        
        for i, topic in enumerate(all_topic_events, 1):
            print(f"\nä¸»é¡Œ {i}: {topic['topic_title']} (ID: {topic['topic_id']})")
            for j, sub_event in enumerate(topic['sub_events'], 1):
                print(f"  åˆ†æ”¯ {j}: {sub_event['event_title']} ({sub_event['news_count']} å‰‡æ–°è)")
        
        return all_topic_events
    
    def generate_topic_title(self, news_items):
        """ç‚ºæ•´å€‹ä¸»é¡Œç”Ÿæˆæ¨™é¡Œ"""
        if not self.genai_client or not news_items:
            return f"ä¸»é¡Œäº‹ä»¶ ({len(news_items)} å‰‡æ–°è)"
        
        # å–å‰3å‰‡æ–°èçš„æ¨™é¡Œå’Œå…§å®¹ç‰‡æ®µ
        sample_news = []
        for i, news in enumerate(news_items[:3], 1):
            title = news['news_title'][:50]
            content = news['content'][:80]
            sample_news.append(f"æ–°è{i}: {title} - {content}...")
        
        prompt = f"""
åŸºæ–¼ä»¥ä¸‹ {len(news_items)} å‰‡æ–°èï¼Œç”Ÿæˆä¸€å€‹ç°¡æ½”çš„ä¸»é¡Œæ¨™é¡Œã€‚

ç¯„ä¾‹æ–°èï¼š
{chr(1000).join(sample_news)}

è«‹ç”Ÿæˆä¸€å€‹8å­—ä»¥å…§çš„ä¸»é¡Œæ¨™é¡Œï¼Œåªå›å‚³æ¨™é¡Œæ–‡å­—ï¼Œä¸è¦å…¶ä»–å…§å®¹ã€‚
"""
        
        try:
            response = self.genai_client.models.generate_content(
                model='gemini-2.5-flash',
                contents=prompt
            )
            title = response.text.strip().replace('"', '').replace("'", '')
            return title if len(title) <= 20 else title[:17] + "..."
            
        except Exception as e:
            print(f"  âœ— AI ç”Ÿæˆä¸»é¡Œæ¨™é¡Œæ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
            return f"ä¸»é¡Œäº‹ä»¶ ({len(news_items)} å‰‡æ–°è)"
    
    def generate_topic_summary(self, news_items):
        """ç‚ºä¸»é¡Œç”Ÿæˆæ¦‚è¦"""
        if not self.genai_client or not news_items:
            return f"åŒ…å« {len(news_items)} å‰‡ç›¸é—œæ–°èçš„ä¸»é¡Œäº‹ä»¶"
        
        # å–å‰3å‰‡æ–°èçš„å…§å®¹
        sample_news = []
        for i, news in enumerate(news_items[:3], 1):
            content = news['content'][:100]
            sample_news.append(f"æ–°è{i}: {content}...")
        
        prompt = f"""
åŸºæ–¼ä»¥ä¸‹æ–°èå…§å®¹ï¼Œç”Ÿæˆä¸€å€‹80å­—ä»¥å…§çš„äº‹ä»¶æ¦‚è¦ã€‚

æ–°èå…§å®¹ï¼š
{chr(1000).join(sample_news)}

è«‹ç”Ÿæˆç°¡æ½”çš„æ¦‚è¦èªªæ˜ï¼Œåªå›å‚³æ¦‚è¦æ–‡å­—ï¼Œä¸è¦å…¶ä»–å…§å®¹ã€‚
"""
        
        try:
            response = self.genai_client.models.generate_content(
                model='gemini-1.5-flash',
                contents=prompt
            )
            summary = response.text.strip()
            return summary if len(summary) <= 100 else summary[:97] + "..."
            
        except Exception as e:
            print(f"  âœ— AI ç”Ÿæˆæ¦‚è¦æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
            return f"åŒ…å« {len(news_items)} å‰‡ç›¸é—œæ–°èçš„ä¸»é¡Œäº‹ä»¶"
    
    def generate_topic_title_and_summary(self, news_items):
        """ä½¿ç”¨ AI ç‚ºä¸»é¡Œç”Ÿæˆæ¨™é¡Œå’Œæ¦‚è¦"""
        if not self.genai_client or not news_items:
            return f"ä¸»é¡Œäº‹ä»¶ ({len(news_items)} å‰‡æ–°è)", f"åŒ…å« {len(news_items)} å‰‡ç›¸é—œæ–°èçš„ä¸»é¡Œäº‹ä»¶"
        
        # æº–å‚™æ–°èæ‘˜è¦
        news_summaries = []
        for i, news in enumerate(news_items[:5], 1):  # æœ€å¤šå–å‰5å‰‡æ–°èåˆ†æ
            title = news['news_title'][:60]
            content = news['content'][:100]
            news_summaries.append(f"æ–°è{i}: {title} - {content}...")
        
        prompt = f"""
åŸºæ–¼ä»¥ä¸‹ {len(news_items)} å‰‡æ–°èï¼Œç”Ÿæˆä¸€å€‹ç°¡æ½”çš„äº‹ä»¶æ¨™é¡Œå’Œæ¦‚è¦ã€‚

æ–°èå…§å®¹ï¼š
{chr(1000).join(news_summaries)}

è«‹ä»¥ JSON æ ¼å¼å›å‚³ï¼š
{{
  "title": "ç°¡æ½”çš„äº‹ä»¶æ¨™é¡Œï¼ˆ8å­—ä»¥å…§ï¼‰",
  "summary": "äº‹ä»¶æ¦‚è¦èªªæ˜ï¼ˆ80å­—ä»¥å…§ï¼‰"
}}

åªå›å‚³ JSONï¼Œä¸è¦å…¶ä»–æ–‡å­—ã€‚
"""
        
        try:
            response = self.genai_client.models.generate_content(
                model='gemini-2.5-flash',
                contents=prompt
            )
            result_text = response.text.strip()
            
            # æ¸…ç† JSON æ ¼å¼
            if result_text.startswith('```json'):
                result_text = result_text[7:-3].strip()
            elif result_text.startswith('```'):
                result_text = result_text[3:-3].strip()
            
            result = json.loads(result_text)
            return result.get('title', 'ä¸»é¡Œäº‹ä»¶'), result.get('summary', f'åŒ…å« {len(news_items)} å‰‡ç›¸é—œæ–°è')
            
        except Exception as e:
            print(f"âœ— AI ç”Ÿæˆæ¨™é¡Œå’Œæ¦‚è¦æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
            return f"ä¸»é¡Œäº‹ä»¶ ({len(news_items)} å‰‡æ–°è)", f"åŒ…å« {len(news_items)} å‰‡ç›¸é—œæ–°èçš„ä¸»é¡Œäº‹ä»¶"
    
    def redistribute_small_branches(self, all_topic_events, min_news_count=5):
        """å°‡ä¸è¶³æŒ‡å®šæ•¸é‡çš„åˆ†æ”¯æ‹†æ‰é‡æ–°åˆ†é…
        
        Args:
            all_topic_events: æ‰€æœ‰ä¸»é¡Œäº‹ä»¶è³‡æ–™
            min_news_count: æœ€å°æ–°èæ•¸é‡é–€æª»ï¼ˆé è¨­ç‚º5ï¼‰
        
        Returns:
            é‡æ–°åˆ†é…å¾Œçš„ä¸»é¡Œäº‹ä»¶è³‡æ–™
        """
        print("\n" + "=" * 60)
        print(f"é–‹å§‹è™•ç†ä¸è¶³ {min_news_count} ç¯‡çš„åˆ†æ”¯")
        print("=" * 60)
        
        redistributed_events = []
        other_news_items = []  # æ”¶é›†ä¸è¶³é–€æª»çš„æ–°è
        
        for topic in all_topic_events:
            topic_id = topic.get('topic_id')
            topic_title = topic.get('topic_title')
            sub_events = topic.get('sub_events', [])
            
            valid_sub_events = []
            small_branches_news = []
            
            print(f"\næª¢æŸ¥ä¸»é¡Œ: {topic_title} (ID: {topic_id})")
            
            for sub_event in sub_events:
                news_count = sub_event.get('news_count', 0)
                event_title = sub_event.get('event_title', '')
                
                if news_count < min_news_count:
                    print(f"  âœ— åˆ†æ”¯ä¸è¶³ {min_news_count} ç¯‡: {event_title} ({news_count} ç¯‡) - å°‡é‡æ–°åˆ†é…")
                    # æ”¶é›†é€™å€‹åˆ†æ”¯çš„æ‰€æœ‰æ–°è
                    small_branches_news.extend(sub_event.get('news_items', []))
                else:
                    print(f"  âœ“ åˆ†æ”¯ä¿ç•™: {event_title} ({news_count} ç¯‡)")
                    valid_sub_events.append(sub_event)
            
            # å¦‚æœè©²ä¸»é¡Œé‚„æœ‰ä¿ç•™çš„åˆ†æ”¯ï¼Œå‰‡ç¹¼çºŒä¿ç•™è©²ä¸»é¡Œ
            if valid_sub_events:
                redistributed_events.append({
                    'topic_id': topic_id,
                    'topic_title': topic_title,
                    'sub_events': valid_sub_events
                })
            
            # å°‡å°åˆ†æ”¯çš„æ–°èåŠ å…¥å¾…åˆ†é…æ¸…å–®
            if small_branches_news:
                other_news_items.extend(small_branches_news)
        
        # å¦‚æœæœ‰éœ€è¦é‡æ–°åˆ†é…çš„æ–°èï¼Œå‰µå»ºã€Œå…¶ä»–ã€åˆ†æ”¯
        if other_news_items:
            print(f"\næ‰¾åˆ° {len(other_news_items)} å‰‡éœ€è¦é‡æ–°åˆ†é…çš„æ–°è")
            print("å»ºç«‹ã€Œå…¶ä»–ç›¸é—œæ–°èã€åˆ†æ”¯...")
            
            # å‰µå»ºä¸€å€‹ç‰¹æ®Šçš„ topic_id ç”¨æ–¼ã€Œå…¶ä»–ã€é¡åˆ¥
            other_topic_id = "other_news_" + str(uuid.uuid4())[:8]
            
            other_topic = {
                'topic_id': other_topic_id,
                'topic_title': 'å…¶ä»–ç›¸é—œæ–°è',
                'sub_events': [
                    {
                        'event_id': str(uuid.uuid4()),
                        'event_title': 'å…¶ä»–ç›¸é—œæ–°è',
                        'event_summary': f'åŒ…å« {len(other_news_items)} å‰‡ä¾†è‡ªä¸åŒåˆ†æ”¯çš„æ–°è',
                        'news_count': len(other_news_items),
                        'news_items': other_news_items
                    }
                ]
            }
            redistributed_events.append(other_topic)
            print(f"  â†’ ã€Œå…¶ä»–ã€åˆ†æ”¯åŒ…å« {len(other_news_items)} å‰‡æ–°è")
        
        # é¡¯ç¤ºé‡æ–°åˆ†é…çµæœçµ±è¨ˆ
        print("\n" + "=" * 60)
        print("é‡æ–°åˆ†é…çµæœçµ±è¨ˆ")
        print("=" * 60)
        print(f"åŸå§‹ä¸»é¡Œæ•¸: {len(all_topic_events)}")
        print(f"é‡æ–°åˆ†é…å¾Œä¸»é¡Œæ•¸: {len(redistributed_events)}")
        
        original_branch_count = sum(len(t.get('sub_events', [])) for t in all_topic_events)
        new_branch_count = sum(len(t.get('sub_events', [])) for t in redistributed_events)
        print(f"åŸå§‹åˆ†æ”¯æ•¸: {original_branch_count}")
        print(f"é‡æ–°åˆ†é…å¾Œåˆ†æ”¯æ•¸: {new_branch_count}")
        
        original_news_count = sum(
            sum(sub.get('news_count', 0) for sub in t.get('sub_events', []))
            for t in all_topic_events
        )
        new_news_count = sum(
            sum(sub.get('news_count', 0) for sub in t.get('sub_events', []))
            for t in redistributed_events
        )
        print(f"ç¸½æ–°èæ•¸: {original_news_count} (ä¸è®Š)")
        print(f"ç§»åˆ°ã€Œå…¶ä»–ã€çš„æ–°èæ•¸: {len(other_news_items)}")
        
        return redistributed_events
    
    def display_redistribution_preview(self, original_events, redistributed_events):
        """é¡¯ç¤ºé‡æ–°åˆ†é…çš„è©³ç´°é è¦½"""
        print("\n" + "=" * 60)
        print("è©³ç´°é è¦½ - é‡æ–°åˆ†é…çµæœ")
        print("=" * 60)
        
        for i, topic in enumerate(redistributed_events, 1):
            topic_id = topic.get('topic_id')
            topic_title = topic.get('topic_title')
            sub_events = topic.get('sub_events', [])
            
            print(f"\nã€ä¸»é¡Œ {i}ã€‘{topic_title} (ID: {topic_id})")
            print(f"åˆ†æ”¯æ•¸é‡: {len(sub_events)}")
            
            for j, sub_event in enumerate(sub_events, 1):
                event_title = sub_event.get('event_title')
                event_summary = sub_event.get('event_summary', '')
                news_count = sub_event.get('news_count')
                news_items = sub_event.get('news_items', [])
                
                print(f"\n  åˆ†æ”¯ {j}: {event_title}")
                print(f"  æ–°èæ•¸é‡: {news_count}")
                print(f"  æ¦‚è¦: {event_summary[:100]}...")
                
                # é¡¯ç¤ºå‰3å‰‡æ–°èæ¨™é¡Œ
                print(f"  åŒ…å«æ–°è:")
                for k, news in enumerate(news_items[:3], 1):
                    news_title = news.get('news_title', '')[:60]
                    story_id = news.get('story_id')
                    print(f"    {k}. [{story_id}] {news_title}")
                
                if len(news_items) > 3:
                    print(f"    ... é‚„æœ‰ {len(news_items) - 3} å‰‡æ–°è")
        
        print("\n" + "=" * 60)
    
    def process(self, json_file_path, output_path):
        """å®Œæ•´è™•ç†æµç¨‹ï¼ˆåŸç‰ˆ - å¾JSONæª”æ¡ˆé–‹å§‹ï¼‰"""
        print("=" * 60)
        print("æ–°èäº‹ä»¶åˆ†çµ„å™¨ - é–‹å§‹è™•ç†")
        print("=" * 60)
        
        # 1. è®€å– story_id
        story_ids = self.read_story_ids_from_json(json_file_path)
        if not story_ids:
            print("æœªæ‰¾åˆ°æœ‰æ•ˆçš„ story_idï¼Œç¨‹å¼çµæŸ")
            return
        
        # 2. å¾ Supabase ç²å–æ–°è
        news_items = self.fetch_news_from_supabase(story_ids)
        if not news_items:
            print("æœªç²å–åˆ°ä»»ä½•æ–°èå…§å®¹ï¼Œç¨‹å¼çµæŸ")
            return
        
        # 3. ä½¿ç”¨ AI åˆ†çµ„
        event_groups = self.group_news_by_events_ai(news_items)
        
        # 4. å„²å­˜çµæœåˆ° JSON æª”æ¡ˆ
        self.save_to_json(event_groups, output_path)
        
        # 5. å„²å­˜çµæœåˆ°è³‡æ–™åº«
        self.save_to_database(event_groups)
        
        # 5. è¼¸å‡ºçµ±è¨ˆè³‡è¨Š
        print("\n" + "=" * 60)
        print("è™•ç†å®Œæˆ - çµ±è¨ˆè³‡è¨Š")
        print("=" * 60)
        print(f"åŸå§‹ story_id æ•¸é‡: {len(story_ids)}")
        print(f"æˆåŠŸç²å–æ–°èæ•¸é‡: {len(news_items)}")
        print(f"åˆ†çµ„å¾Œäº‹ä»¶åˆ†æ”¯æ•¸é‡: {len(event_groups)}")
        
        for i, group in enumerate(event_groups, 1):
            print(f"  åˆ†æ”¯ {i}: {group['event_title']} ({group['news_count']} å‰‡æ–°è)")


def main():
    """ä¸»ç¨‹å¼å…¥å£ - æ¸¬è©¦æ¨¡å¼ï¼ˆä¸å¯«å…¥è³‡æ–™åº«ï¼‰"""
    print("ğŸš€ æ–°èäº‹ä»¶åˆ†çµ„å™¨ - å•Ÿå‹•ä¸­...")
    print("ğŸ”’ åš´æ ¼æ¨¡å¼ï¼šæ¯å€‹åˆ†æ”¯è‡³å°‘éœ€è¦ 5 ç¯‡æ–°è")
    print("ğŸ§ª æ¸¬è©¦æ¨¡å¼ï¼šåƒ…é¡¯ç¤ºçµæœï¼Œä¸å¯«å…¥è³‡æ–™åº«")
    print("=" * 60)
    
    # å‰µå»ºè™•ç†å™¨
    try:
        grouper = NewsEventGrouper()
    except Exception as e:
        print(f"âŒ åˆå§‹åŒ–å¤±æ•—: {e}")
        print("è«‹æª¢æŸ¥ç’°å¢ƒè¨­å®šå’Œç¶²è·¯é€£ç·š")
        return
    
    # è¨­å®šè¼¸å‡ºæª”æ¡ˆåç¨±ï¼ˆåŒ…å«æ™‚é–“æˆ³è¨˜ï¼‰
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    output_path = f"topic_grouped_news_strict_{timestamp}.json"
    
    # æ¸¬è©¦æ¨¡å¼ï¼šä¸å„²å­˜åˆ°è³‡æ–™åº«
    save_to_db = False
    
    print(f"ğŸ“„ çµæœå°‡å„²å­˜åˆ°: {output_path}")
    print("âš ï¸  æ¸¬è©¦æ¨¡å¼ï¼šä¸æœƒå¯«å…¥è³‡æ–™åº«")
    print()
    
    try:
        # åŸ·è¡Œä¸»è¦è™•ç†æµç¨‹ï¼ˆå·²å…§å»ºåš´æ ¼çš„5ç¯‡é–€æª»ï¼‰
        print("é–‹å§‹å¾ topic_news_map ç²å–è³‡æ–™ä¸¦é€²è¡Œåš´æ ¼åˆ†çµ„...")
        print("åˆ†çµ„æ¨™æº–ï¼š")
        print("  â€¢ æ¯å€‹åˆ†æ”¯è‡³å°‘ 5 ç¯‡æ–°è")
        print("  â€¢ æ ¸å¿ƒäº‹ä»¶å¿…é ˆæ˜ç¢ºä¸€è‡´")
        print("  â€¢ ä¸è¶³é–€æª»çš„æ–°èè‡ªå‹•æ­¸å…¥ã€Œå…¶ä»–ã€")
        print()
        
        result = grouper.process_from_topic_map(output_path, save_to_db)
        
        if not result:
            print("\nâš ï¸ è™•ç†éç¨‹ä¸­é‡åˆ°å•é¡Œï¼Œè«‹æª¢æŸ¥è¼¸å‡ºè¨Šæ¯")
            return
        
        # é¡¯ç¤ºè©³ç´°çµ±è¨ˆ
        print("\n" + "=" * 60)
        print("ğŸ“Š æœ€çµ‚çµ±è¨ˆçµæœ")
        print("=" * 60)
        
        total_branches = 0
        total_news = 0
        other_branches = 0
        valid_branches = 0
        
        for topic in result:
            topic_title = topic.get('topic_title')
            sub_events = topic.get('sub_events', [])
            
            print(f"\nã€{topic_title}ã€‘")
            for sub_event in sub_events:
                event_title = sub_event.get('event_title')
                news_count = sub_event.get('news_count')
                total_branches += 1
                total_news += news_count
                
                if 'å…¶ä»–' in event_title:
                    other_branches += 1
                    print(f"  â€¢ {event_title}: {news_count} ç¯‡ âš ï¸")
                else:
                    valid_branches += 1
                    print(f"  â€¢ {event_title}: {news_count} ç¯‡ âœ“")
        
        print("\n" + "=" * 60)
        print("ç¸½è¦½ï¼š")
        print(f"  â€¢ ç¸½ä¸»é¡Œæ•¸: {len(result)}")
        print(f"  â€¢ ç¸½åˆ†æ”¯æ•¸: {total_branches}")
        print(f"  â€¢ æœ‰æ•ˆåˆ†æ”¯æ•¸: {valid_branches} (â‰¥5ç¯‡)")
        print(f"  â€¢ ã€Œå…¶ä»–ã€åˆ†æ”¯æ•¸: {other_branches}")
        print(f"  â€¢ ç¸½æ–°èæ•¸: {total_news}")
        print("=" * 60)
        
        print("\nâœ… æ¸¬è©¦å®Œæˆï¼")
        print(f"ğŸ“„ çµæœå·²å„²å­˜åˆ°: {output_path}")
        print("âš ï¸  é€™æ˜¯æ¸¬è©¦æ¨¡å¼ï¼Œæœªå¯«å…¥è³‡æ–™åº«")
        print("\nğŸ’¡ æç¤ºï¼šå¦‚æœçµæœç¬¦åˆé æœŸï¼Œå¯ä¿®æ”¹ save_to_db = True ä¾†å¯«å…¥è³‡æ–™åº«")
        
    except KeyboardInterrupt:
        print("\n\nâ¹ï¸ ä½¿ç”¨è€…ä¸­æ–·ç¨‹å¼åŸ·è¡Œ")
    except Exception as e:
        print(f"\nâŒ åŸ·è¡Œéç¨‹ä¸­ç™¼ç”ŸéŒ¯èª¤: {e}")
        print("è«‹æª¢æŸ¥ç¶²è·¯é€£ç·šå’Œè³‡æ–™åº«è¨­å®š")
        import traceback
        traceback.print_exc()
    
    print("\nç¨‹å¼çµæŸ")


if __name__ == "__main__":
    main()