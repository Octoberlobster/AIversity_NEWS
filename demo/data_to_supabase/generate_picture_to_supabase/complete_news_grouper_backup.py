"""æ–°èäº‹ä»¶åˆ†çµ„å™¨ - å®Œæ•´ç‰ˆ
ä½¿ç”¨ google.genai é€²è¡Œæ™ºèƒ½åˆ†çµ„
"""

import os
import sys
import json
import time
import uuid
from datetime import datetime
from dotenv import load_dotenv

# è¼‰å…¥ç’°å¢ƒè®Šæ•¸

load_dotenv()

SUPABASE_URL = os.getenv('SUPABASE_URL')
SUPABASE_KEY = os.getenv('SUPABASE_KEY')
GEMINI_API_KEY = os.getenv('GEMINI_API_KEY')

if not SUPABASE_URL or not SUPABASE_KEY:
    print("è«‹åœ¨ Picture_generate_system/.env è¨­å®š SUPABASE_URL èˆ‡ SUPABASE_KEY")
    sys.exit(1)
if not GEMINI_API_KEY:
    print("è«‹åœ¨ Picture_generate_system/.env è¨­å®š GEMINI_API_KEY")
    sys.exit(1)

try:
    from supabase import create_client
    print("âœ“ Supabase å¥—ä»¶å·²è¼‰å…¥")
except ImportError:
    print("è«‹å…ˆå®‰è£ supabase-pyï¼špip install supabase-py postgrest-py")
    sys.exit(1)

try:
    import google.genai as genai
    print("âœ“ Google Genai å¥—ä»¶å·²è¼‰å…¥")
except ImportError:
    print("è«‹å…ˆå®‰è£ google genai SDKï¼špip install google-genai")
    sys.exit(1)

class NewsEventGrouper:
    """æ–°èäº‹ä»¶åˆ†çµ„å™¨"""
    
    # å¸¸æ•¸è¨­å®š
    MIN_BRANCH_SIZE = 5  # æ¯å€‹åˆ†æ”¯æœ€å°‘éœ€è¦çš„æ–°èæ•¸é‡
    OTHER_BRANCH_TITLE = "å…¶ä»–å¾…åˆ†é¡æ–°è"  # æš«å­˜å€åˆ†æ”¯åç¨±
    
    def __init__(self):
        """åˆå§‹åŒ–å®¢æˆ¶ç«¯"""
        self.supabase = create_client(SUPABASE_URL, SUPABASE_KEY)
        try:
            self.genai_client = genai.Client(api_key=GEMINI_API_KEY)
            print("âœ“ Gemini Client åˆå§‹åŒ–æˆåŠŸ")
        except Exception as e:
            print(f"âœ— Gemini Client åˆå§‹åŒ–å¤±æ•—: {e}")
            # ä½¿ç”¨ fallback æ–¹æ³•
            print("åˆ‡æ›åˆ° fallback æ¨¡å¼...")
            self.genai_client = None
        
    def fetch_existing_branches_for_topic(self, topic_id):
        """ç²å–æŸä¸»é¡Œç¾æœ‰çš„æ‰€æœ‰åˆ†æ”¯è³‡æ–™"""
        try:
            print(f"  æª¢æŸ¥ä¸»é¡Œ {topic_id} çš„ç¾æœ‰åˆ†æ”¯...")
            
            # ç²å–è©²ä¸»é¡Œçš„æ‰€æœ‰åˆ†æ”¯
            branch_response = self.supabase.table('topic_branch').select(
                'topic_branch_id, topic_branch_title, topic_branch_content'
            ).eq('topic_id', topic_id).execute()
            
            if not branch_response.data:
                print(f"  â†’ è©²ä¸»é¡Œå°šç„¡åˆ†æ”¯")
                return []
            
            branches = []
            for branch in branch_response.data:
                branch_id = branch.get('topic_branch_id')
                
                # ç²å–è©²åˆ†æ”¯åŒ…å«çš„æ–°è
                news_map_response = self.supabase.table('topic_branch_news_map').select(
                    'story_id'
                ).eq('topic_branch_id', branch_id).execute()
                
                story_ids = [item['story_id'] for item in news_map_response.data] if news_map_response.data else []
                
                branches.append({
                    'branch_id': branch_id,
                    'title': branch.get('topic_branch_title'),
                    'content': branch.get('topic_branch_content'),
                    'story_ids': story_ids,
                    'news_count': len(story_ids)
                })
            
            print(f"  â†’ æ‰¾åˆ° {len(branches)} å€‹ç¾æœ‰åˆ†æ”¯")
            for i, branch in enumerate(branches, 1):
                print(f"    åˆ†æ”¯ {i}: {branch['title']} ({branch['news_count']} å‰‡æ–°è)")
            
            return branches
            
        except Exception as e:
            print(f"  âœ— ç²å–ç¾æœ‰åˆ†æ”¯æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
            return []
    
    def fetch_topic_news_map_from_supabase(self):
        """å¾ Supabase çš„ topic_news_map è¡¨ç²å–ä¸»é¡Œæ–°èæ˜ å°„"""
        try:
            print("é–‹å§‹å¾ topic_news_map è¡¨ç²å–è³‡æ–™...")
            response = self.supabase.table('topic_news_map').select(
                'topic_id, story_id'
            ).execute()
            
            if response.data:
                print(f"âœ“ æˆåŠŸç²å– {len(response.data)} ç­†ä¸»é¡Œæ–°èæ˜ å°„è³‡æ–™")
                return response.data
            else:
                print("âœ— topic_news_map è¡¨ç„¡è³‡æ–™")
                return []
                
        except Exception as e:
            print(f"âœ— ç²å– topic_news_map è³‡æ–™æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
            return []
    
    def group_by_topic_id(self, topic_news_map):
        """æ ¹æ“š topic_id å°‡æ–°èåˆ†çµ„"""
        topic_groups = {}
        
        for item in topic_news_map:
            topic_id = item.get('topic_id')
            story_id = item.get('story_id')
            
            if topic_id and story_id:
                if topic_id not in topic_groups:
                    topic_groups[topic_id] = []
                topic_groups[topic_id].append(story_id)
        
        print(f"âœ“ æ ¹æ“š topic_id åˆ†æˆ {len(topic_groups)} å€‹ä¸»é¡Œçµ„")
        for topic_id, story_ids in topic_groups.items():
            print(f"  ä¸»é¡Œ {topic_id}: {len(story_ids)} å‰‡æ–°è")
        
        return topic_groups
    
    def read_story_ids_from_json(self, json_file_path):
        """å¾ JSON æª”æ¡ˆè®€å– story_id åˆ—è¡¨"""
        try:
            with open(json_file_path, 'r', encoding='utf-8') as f:
                data = json.load(f)
            
            story_ids = []
            if isinstance(data, list):
                for item in data:
                    if isinstance(item, dict):
                        story_id = (item.get('story_id') or 
                                  item.get('id') or 
                                  item.get('storyId'))
                        if story_id:
                            story_ids.append(str(story_id))
            
            print(f"å¾ {json_file_path} è®€å–åˆ° {len(story_ids)} å€‹ story_id")
            return list(set(story_ids))  # å»é‡
            
        except Exception as e:
            print(f"è®€å– JSON æª”æ¡ˆæ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
            return []
    
    def fetch_news_from_supabase(self, story_ids):
        """å¾ Supabase ç²å–æ–°èå…§å®¹"""
        news_items = []
        
        print(f"é–‹å§‹å¾ Supabase ç²å– {len(story_ids)} å‰‡æ–°è...")
        
        for i, story_id in enumerate(story_ids, 1):
            try:
                response = self.supabase.table('single_news').select(
                    'story_id, news_title, long'
                ).eq('story_id', story_id).execute()
                
                if response.data and len(response.data) > 0:
                    news_data = response.data[0]
                    news_items.append({
                        'story_id': news_data.get('story_id'),
                        'news_title': news_data.get('news_title', ''),
                        'content': news_data.get('long', '')
                    })
                    print(f"âœ“ {i}/{len(story_ids)}: æˆåŠŸç²å– story_id {story_id}")
                else:
                    print(f"âœ— {i}/{len(story_ids)}: story_id {story_id} æœªæ‰¾åˆ°å°æ‡‰æ–°è")
                    
            except Exception as e:
                print(f"âœ— {i}/{len(story_ids)}: ç²å– story_id {story_id} æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
                
            # é¿å…è«‹æ±‚éæ–¼é »ç¹
            time.sleep(0.1)
        
        print(f"æˆåŠŸç²å– {len(news_items)} å‰‡æ–°èå…§å®¹")
        return news_items
    
    def check_if_news_fits_branch(self, news_item, branch_news_items):
        """ä½¿ç”¨ AI æª¢æŸ¥æ–°æ–°èæ˜¯å¦é©åˆåŠ å…¥ç¾æœ‰åˆ†æ”¯"""
        if not self.genai_client:
            return False
        
        # æº–å‚™ç¾æœ‰åˆ†æ”¯çš„æ–°èæ‘˜è¦
        branch_summaries = []
        for i, news in enumerate(branch_news_items[:3], 1):
            title = news['news_title'][:50]
            content = news['content'][:100]
            branch_summaries.append(f"æ–°è{i}: {title} - {content}...")
        
        # æ–°æ–°èæ‘˜è¦
        new_title = news_item['news_title'][:50]
        new_content = news_item['content'][:100]
        
        prompt = f"""
åˆ¤æ–·ä»¥ä¸‹ã€Œæ–°æ–°èã€æ˜¯å¦èˆ‡ã€Œç¾æœ‰åˆ†æ”¯æ–°èã€å±¬æ–¼åŒä¸€äº‹ä»¶æˆ–é«˜åº¦ç›¸é—œã€‚

ã€ç¾æœ‰åˆ†æ”¯æ–°èã€‘
{chr(10).join(branch_summaries)}

ã€æ–°æ–°èã€‘
æ¨™é¡Œ: {new_title}
å…§å®¹: {new_content}...

è«‹å›ç­” YES æˆ– NOï¼š
- YES: æ–°æ–°èèˆ‡ç¾æœ‰åˆ†æ”¯é«˜åº¦ç›¸é—œï¼Œå¯ä»¥åŠ å…¥
- NO: æ–°æ–°èèˆ‡ç¾æœ‰åˆ†æ”¯ä¸ç›¸é—œï¼Œä¸æ‡‰åŠ å…¥

åªå›å‚³ YES æˆ– NOï¼Œä¸è¦å…¶ä»–æ–‡å­—ã€‚
"""
        
        try:
            response = self.genai_client.models.generate_content(
                model='gemini-2.5-flash',
                contents=prompt
            )
            answer = response.text.strip().upper()
            return 'YES' in answer
        except Exception as e:
            print(f"    âœ— AI åˆ¤æ–·æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
            return False
    
    def group_news_by_events_ai_with_min_size(self, news_items, min_size=5):
        """ä½¿ç”¨ Gemini AI å°‡æ–°èåˆ†çµ„ï¼Œç¢ºä¿æ¯çµ„è‡³å°‘æœ‰ min_size å‰‡æ–°è
        
        Args:
            news_items: æ–°èåˆ—è¡¨
            min_size: æ¯çµ„æœ€å°‘æ–°èæ•¸é‡ï¼ˆé è¨­5å‰‡ï¼‰
        
        Returns:
            ç¬¦åˆæœ€å°è¦æ¨¡çš„åˆ†çµ„ + "å…¶ä»–"æš«å­˜åˆ†çµ„
        """
        if not self.genai_client or not news_items:
            return self.simple_group_news(news_items)
        
        print(f"  ä½¿ç”¨ AI åˆ†çµ„ï¼ˆæœ€å°è¦æ¨¡: {min_size} å‰‡æ–°èï¼‰...")
        
        # å…ˆç”¨åŸæœ‰é‚è¼¯åˆ†çµ„
        raw_groups = self.group_news_by_events_ai(news_items)
        
        # ç¯©é¸å‡ºç¬¦åˆæœ€å°è¦æ¨¡çš„åˆ†çµ„
        valid_groups = []
        small_groups_news = []  # æ”¶é›†ä¸è¶³æœ€å°è¦æ¨¡çš„æ–°è
        
        for group in raw_groups:
            if group['news_count'] >= min_size:
                valid_groups.append(group)
                print(f"    âœ“ åˆ†æ”¯ã€Œ{group['event_title']}ã€ç¬¦åˆè¦æ¨¡ ({group['news_count']} å‰‡)")
            else:
                print(f"    âœ— åˆ†æ”¯ã€Œ{group['event_title']}ã€ä¸è¶³è¦æ¨¡ ({group['news_count']} å‰‡)ï¼Œæ–°èå°‡æ”¾å…¥æš«å­˜å€")
                small_groups_news.extend(group['news_items'])
        
        # å°‡ä¸è¶³è¦æ¨¡çš„æ–°èæ”¾å…¥"å…¶ä»–"æš«å­˜å€
        if small_groups_news:
            other_branch = {
                'event_id': str(uuid.uuid4()),
                'event_title': self.OTHER_BRANCH_TITLE,
                'event_summary': f'åŒ…å« {len(small_groups_news)} å‰‡å¾…é‡æ–°åˆ†é¡çš„æ–°èï¼ˆä¸è¶³ {min_size} å‰‡ç„¡æ³•æˆç‚ºç¨ç«‹åˆ†æ”¯ï¼‰',
                'news_count': len(small_groups_news),
                'news_items': small_groups_news,
                'is_other': True  # æ¨™è¨˜ç‚ºæš«å­˜å€
            }
            valid_groups.append(other_branch)
            print(f"    â†’ å‰µå»ºæš«å­˜å€ã€Œ{self.OTHER_BRANCH_TITLE}ã€({len(small_groups_news)} å‰‡æ–°è)")
        
        return valid_groups
    
    def group_news_by_events_ai(self, news_items):
        """ä½¿ç”¨ Gemini AI å°‡æ–°èåˆ†çµ„ç‚ºäº‹ä»¶åˆ†æ”¯ï¼ˆåŸå§‹æ–¹æ³•ï¼Œä¸è€ƒæ…®æœ€å°è¦æ¨¡ï¼‰"""
        if not self.genai_client or not news_items:
            return self.simple_group_news(news_items)
        
        print("é–‹å§‹ä½¿ç”¨ Gemini AI åˆ†ææ–°èäº‹ä»¶...")
        
        # æº–å‚™æ–°èæ‘˜è¦è³‡æ–™ä¾›æ¨¡å‹åˆ†æ
        news_summaries = []
        for i, news in enumerate(news_items):
            title = news['news_title'][:100]  # å¢åŠ æ¨™é¡Œé•·åº¦
            content = news['content'][:300]   # å¢åŠ å…§å®¹é•·åº¦ä»¥æä¾›æ›´å¤šç´°ç¯€
            summary = f"æ–°è{i+1}ï¼šæ¨™é¡Œï¼š{title}ï¼›å…§å®¹ï¼š{content}..."
            news_summaries.append(summary)
        
        # æ§‹å»ºæç¤ºèª
        prompt = f"""
# è§’è‰²
ä½ æ˜¯ä¸€ä½é ‚å°–çš„æ–°èåˆ†æå°ˆå®¶ï¼Œæ“æœ‰è¶…é20å¹´çš„ç”¢æ¥­ç¶“é©—ã€‚ä½ çš„æ ¸å¿ƒèƒ½åŠ›æ˜¯å¿«é€Ÿæ´å¯Ÿå¤§é‡å¿«è¨ŠèƒŒå¾Œçš„æ ¸å¿ƒäº‹ä»¶è„ˆçµ¡ï¼Œå°‡çœ‹ä¼¼ç¨ç«‹çš„å ±å°æ•´åˆæˆæ¸…æ™°ã€æœ‰é‚è¼¯çš„äº‹ä»¶ç¾¤çµ„ï¼Œä¸¦ç‚ºå…¶å‘½åç²¾æº–çš„æ¨™é¡Œã€‚

# æ ¸å¿ƒä»»å‹™
åˆ†æä¸‹æ–¹æä¾›çš„ {len(news_items)} å‰‡æ–°èï¼Œå°‡å®ƒå€‘ä¾æ“šã€Œæ ¸å¿ƒäº‹ä»¶ã€é€²è¡Œåˆä½µåˆ†çµ„ã€‚

# å…©å¤§çµ•å°åŸå‰‡ (å¿…é ˆåš´æ ¼éµå®ˆ)
1.  **ç¦æ­¢ä»»ä½•å½¢å¼çš„ã€Œå…¶ä»–ã€æˆ–ã€Œæœªåˆ†é¡ã€åˆ†çµ„**ï¼šæ‰€æœ‰æ–°èéƒ½å¿…é ˆè¢«æ­¸å…¥ä¸€å€‹æœ‰å…·é«”äº‹ä»¶æ„ç¾©çš„åˆ†çµ„ã€‚é€™æ¢åŸå‰‡æ²’æœ‰ä¾‹å¤–ã€‚
2.  **æœçµ•å–®ä¸€æ–°èåˆ†çµ„**ï¼šæ¯å€‹åˆ†çµ„å¿…é ˆåŒ…å«è‡³å°‘ 2 å‰‡æ–°èã€‚å¦‚æœæŸå‰‡æ–°èçœ‹ä¼¼ç¨ç«‹ï¼Œä½ å¿…é ˆé‡æ–°å¯©è¦–æ‰€æœ‰æ–°èï¼Œæ‰¾å‡ºèˆ‡å®ƒæœ€ç›¸é—œçš„äº‹ä»¶ä¸¦å°‡å…¶ä½µå…¥ã€‚ä½ çš„è·è²¬æ˜¯æ‰¾å‡ºé—œè¯ï¼Œè€Œéè£½é€ å­¤å³¶ã€‚

# æ–°èè³‡æ–™
{chr(1000).join(news_summaries)}

# åŸ·è¡Œæ­¥é©Ÿ (è«‹åœ¨å…§éƒ¨ä¾åºæ€è€ƒï¼Œåƒ…æœ€çµ‚è¼¸å‡º JSON)

### æ­¥é©Ÿä¸€ï¼šåˆæ­¥æƒæèˆ‡ä¸»é¡Œè­˜åˆ¥
å¿«é€Ÿé–±è®€å…¨éƒ¨ {len(news_items)} å‰‡æ–°èï¼Œç‚ºæ¯ä¸€å‰‡æ–°èæ¨™è¨˜å‡º 2-3 å€‹æ ¸å¿ƒé—œéµè©ï¼ˆä¾‹å¦‚ï¼šäººç‰©ã€åœ°é»ã€äº‹ä»¶é¡å‹ï¼‰ã€‚

### æ­¥é©ŸäºŒï¼šå¼·åˆ¶é—œè¯èˆ‡åˆä½µ
é€™æ˜¯æœ€é‡è¦çš„æ­¥é©Ÿã€‚æª¢è¦–æ‰€æœ‰æ–°èçš„é—œéµè©ï¼Œé–‹å§‹å¼·åˆ¶å°‹æ‰¾é—œè¯æ€§ä¸¦é€²è¡Œåˆä½µï¼š
- **å› æœé—œè¯**ï¼šäº‹ä»¶Aæ˜¯å¦å°è‡´äº†äº‹ä»¶Bï¼Ÿå®ƒå€‘æ‡‰å±¬åŒä¸€çµ„ã€‚
- **äººç‰©/åœ°é»é—œè¯**ï¼šä¸åŒæ–°èæ˜¯å¦æ¶‰åŠç›¸åŒçš„é—œéµäººç‰©ã€å…¬å¸æˆ–åœ°é»ï¼Ÿå®ƒå€‘æ‡‰å±¬åŒä¸€çµ„ã€‚
- **ä¸»é¡Œå»¶ä¼¸**ï¼šå ±å°Aæ˜¯å¦æ˜¯äº‹ä»¶Bçš„å¾ŒçºŒç™¼å±•æˆ–ä¸åŒé¢å‘çš„æ¢è¨ï¼Ÿå®ƒå€‘æ‡‰å±¬åŒä¸€çµ„ã€‚
- **å»ºç«‹è‰ç¨¿åˆ†çµ„**ï¼šåŸºæ–¼ä»¥ä¸Šé—œè¯ï¼Œå»ºç«‹ 3-5 å€‹è‰ç¨¿åˆ†çµ„ã€‚**ä½ çš„é è¨­è¡Œç‚ºæ‡‰è©²æ˜¯åˆä½µï¼Œè€Œä¸æ˜¯æ‹†åˆ†**ã€‚

### æ­¥é©Ÿä¸‰ï¼šå¯©æ ¸èˆ‡èª¿æ•´
æª¢æŸ¥ä½ çš„è‰ç¨¿åˆ†çµ„æ˜¯å¦é•åäº†ã€Œå…©å¤§çµ•å°åŸå‰‡ã€ï¼š
- æ˜¯å¦å­˜åœ¨åªæœ‰ä¸€å‰‡æ–°èçš„åˆ†çµ„ï¼Ÿè‹¥æœ‰ï¼Œç«‹åˆ»å°‡è©²æ–°èä½µå…¥æœ€ç›¸é—œçš„ç¾æœ‰åˆ†çµ„ä¸­ï¼Œä¸¦èª¿æ•´è©²çµ„çš„æ¨™é¡Œèˆ‡æ‘˜è¦ä»¥æ¶µè“‹æ–°å…§å®¹ã€‚
- æ˜¯å¦æ‰€æœ‰æ–°èéƒ½å·²åˆ†é…å®Œç•¢ï¼Ÿç¢ºä¿ç·¨è™Ÿ 1 åˆ° {len(news_items)} éƒ½è¢«åˆ†é…ã€‚
- åˆ†çµ„æ•¸é‡æ˜¯å¦åœ¨ 3-5 å€‹ä¹‹é–“ï¼Ÿé€™æ˜¯æœ€ä½³å¯¦è¸ï¼Œé™¤éæ–°èå…§å®¹æ¥µåº¦å–®ä¸€æˆ–åˆ†æ•£ã€‚

### æ­¥é©Ÿå››ï¼šç”Ÿæˆæœ€çµ‚è¼¸å‡º
åœ¨ä½ ç¢ºèªæ‰€æœ‰åŸå‰‡éƒ½å·²æ»¿è¶³å¾Œï¼Œæ‰å°‡æœ€çµ‚çµæœæ ¼å¼åŒ–ç‚º JSONã€‚

# æœ€çµ‚è¼¸å‡ºè¦æ±‚
**åƒ…å›å‚³æ¨™æº–çš„ JSON æ ¼å¼**ï¼Œä¸è¦åŒ…å«ä»»ä½•èª¬æ˜ã€è¨»è§£æˆ– ```json ... ``` æ¨™è¨˜ã€‚

{{
  "groups": [
    {{
      "event_title": "ç²¾ç…‰çš„æ ¸å¿ƒäº‹ä»¶æ¨™é¡Œ (10å­—å…§)",
      "event_summary": "å…¨é¢ä¸”å®¢è§€åœ°ç¸½çµè©²äº‹ä»¶çš„æ ¸å¿ƒå…§å®¹ (80å­—å…§)",
      "news_indices": [/* æ–°èç·¨è™Ÿé™£åˆ—ï¼Œå¾ 1 é–‹å§‹ï¼Œä¾‹å¦‚ [1, 5, 8] */]
    }},
    {{
      "event_title": "å¦ä¸€å€‹äº‹ä»¶çš„ç²¾ç…‰æ¨™é¡Œ (10å­—å…§)",
      "event_summary": "å¦ä¸€å€‹äº‹ä»¶çš„æ ¸å¿ƒå…§å®¹ç¸½çµ",
      "news_indices": [/* ... */]
    }}
  ]
}}

åˆ†çµ„åŸå‰‡ï¼š
1. ä»¥ä¸»è¦äº‹ä»¶æˆ–æ”¿ç­–ç‚ºæ ¸å¿ƒåˆ†çµ„
2. åŒä¸€äº‹ä»¶çš„ä¸åŒç™¼å±•éšæ®µå¯ä»¥æ”¾åœ¨åŒä¸€çµ„

4. äº‹ä»¶æ¨™é¡Œè¦èƒ½æ¶µè“‹çµ„å…§æ‰€æœ‰æ–°èçš„å…±åŒä¸»é¡Œ
5. news_indices å°æ‡‰æ–°èçš„ç·¨è™Ÿï¼ˆå¾1é–‹å§‹ï¼‰
6. ç¢ºä¿æ‰€æœ‰æ–°èéƒ½è¢«åˆ†é…åˆ°æŸå€‹åˆ†çµ„
7. åªå›å‚³ JSONï¼Œä¸è¦å…¶ä»–èªªæ˜æ–‡å­—

"""

        try:
            response = self.genai_client.models.generate_content(
                model='gemini-2.5-flash',
                contents=prompt
            )
            result_text = response.text.strip()
            
            # è§£æ JSON çµæœ
            if result_text.startswith('```json'):
                result_text = result_text[7:-3].strip()
            elif result_text.startswith('```'):
                result_text = result_text[3:-3].strip()
            
            result = json.loads(result_text)
            groups = result.get('groups', [])
            
            print(f"AI åˆ†æå®Œæˆï¼Œå…±åˆ†ç‚º {len(groups)} å€‹äº‹ä»¶åˆ†æ”¯")
            
            # è½‰æ›ç‚ºæœ€çµ‚æ ¼å¼ï¼Œä¸¦ç¢ºä¿æ¯å‰‡æ–°èåªå‡ºç¾åœ¨ä¸€å€‹åˆ†æ”¯
            event_groups = []
            used_news_indices = set()  # è¿½è¹¤å·²ä½¿ç”¨çš„æ–°èç´¢å¼•
            
            for group in groups:
                event_title = group.get('event_title', 'æœªå‘½åäº‹ä»¶')
                event_summary = group.get('event_summary', '')
                news_indices = group.get('news_indices', [])
                
                # ç²å–å°æ‡‰çš„æ–°èé …ç›®ï¼Œæ’é™¤å·²ä½¿ç”¨çš„æ–°è
                group_news = []
                for idx in news_indices:
                    if 1 <= idx <= len(news_items) and idx not in used_news_indices:
                        group_news.append(news_items[idx - 1])  # è½‰æ›ç‚º0-basedç´¢å¼•
                        used_news_indices.add(idx)  # æ¨™è¨˜ç‚ºå·²ä½¿ç”¨
                
                if group_news:  # åªæ·»åŠ æœ‰æ–°èçš„åˆ†çµ„
                    event_groups.append({
                        'event_id': str(uuid.uuid4()),
                        'event_title': event_title,
                        'event_summary': event_summary,
                        'news_count': len(group_news),
                        'news_items': group_news
                    })
            
            # æª¢æŸ¥æ˜¯å¦æœ‰æœªåˆ†é…çš„æ–°è
            all_indices = set(range(1, len(news_items) + 1))
            unused_indices = all_indices - used_news_indices
            
            if unused_indices:
                # å°‡æœªåˆ†é…çš„æ–°èå‰µå»ºç‚ºä¸€å€‹é¡å¤–çš„åˆ†çµ„
                unused_news = [news_items[idx - 1] for idx in unused_indices]
                event_groups.append({
                    'event_id': str(uuid.uuid4()),
                    'event_title': 'å…¶ä»–ç›¸é—œæ–°è',
                    'event_summary': f'åŒ…å« {len(unused_news)} å‰‡æœªè¢«å…¶ä»–åˆ†æ”¯åŒ…å«çš„ç›¸é—œæ–°è',
                    'news_count': len(unused_news),
                    'news_items': unused_news
                })
                print(f"æ³¨æ„ï¼šæœ‰ {len(unused_indices)} å‰‡æ–°èæœªè¢« AI åˆ†çµ„ï¼Œå·²è‡ªå‹•å‰µå»ºã€Œå…¶ä»–ç›¸é—œæ–°èã€åˆ†æ”¯")
            
            return event_groups
            
        except Exception as e:
            print(f"AI åˆ†ææ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
            print("åˆ‡æ›åˆ°ç°¡å–®åˆ†çµ„æ¨¡å¼...")
            return self.simple_group_news(news_items)
    
    def simple_group_news(self, news_items):
        """ç°¡å–®çš„æ–°èåˆ†çµ„ï¼ˆä¸ä½¿ç”¨ AIï¼‰"""
        return [{
            'event_id': str(uuid.uuid4()),
            'event_title': 'ç¶œåˆæ–°èäº‹ä»¶',
            'event_summary': f'åŒ…å« {len(news_items)} å‰‡ç›¸é—œæ–°èçš„ç¶œåˆäº‹ä»¶',
            'news_count': len(news_items),
            'news_items': news_items
        }]
    
    def save_to_database(self, event_groups, save_mode="both"):
        """å°‡äº‹ä»¶åˆ†æ”¯å’Œæ–°èæ˜ å°„å­˜å…¥è³‡æ–™åº«
        
        Args:
            event_groups: è™•ç†å¥½çš„äº‹ä»¶åˆ†çµ„è³‡æ–™
            save_mode: å„²å­˜æ¨¡å¼ - "preview"(åƒ…é è¦½), "database"(åƒ…è³‡æ–™åº«), "both"(é è¦½+è³‡æ–™åº«)
        """
        try:
            print(f"\né–‹å§‹è³‡æ–™åº«å„²å­˜æµç¨‹ (æ¨¡å¼: {save_mode})...")
            
            # æº–å‚™å…©å€‹è³‡æ–™è¡¨çš„è³‡æ–™
            topic_branch_news_map_data = []
            topic_branch_data = []
            
            for topic_group in event_groups:
                topic_id = topic_group.get('topic_id')
                sub_events = topic_group.get('sub_events', [])
                
                for sub_event in sub_events:
                    topic_branch_id = sub_event.get('event_id')
                    topic_branch_title = sub_event.get('event_title')
                    topic_branch_content = sub_event.get('event_summary')
                    news_items = sub_event.get('news_items', [])
                    
                    # 1. æº–å‚™ topic_branch è³‡æ–™
                    if topic_id and topic_branch_id and topic_branch_title:
                        topic_branch_data.append({
                            'topic_id': topic_id,
                            'topic_branch_id': topic_branch_id,
                            'topic_branch_title': topic_branch_title,
                            'topic_branch_content': topic_branch_content or ''
                        })
                    
                    # 2. æº–å‚™ topic_branch_news_map è³‡æ–™
                    for news_item in news_items:
                        story_id = news_item.get('story_id')
                        if topic_branch_id and story_id:
                            topic_branch_news_map_data.append({
                                'topic_branch_id': topic_branch_id,
                                'story_id': story_id
                            })
            
            print(f"æº–å‚™è³‡æ–™: {len(topic_branch_data)} å€‹åˆ†æ”¯, {len(topic_branch_news_map_data)} ç­†æ–°èå°æ‡‰")
            
            # æ ¹æ“šæ¨¡å¼åŸ·è¡Œç›¸æ‡‰æ“ä½œ
            if save_mode in ["preview", "both"]:
                self._save_database_preview(topic_branch_data, topic_branch_news_map_data)
            
            if save_mode in ["database", "both"]:
                self._save_to_actual_database(topic_branch_data, topic_branch_news_map_data)
                
        except Exception as e:
            print(f"âœ— è³‡æ–™åº«å„²å­˜æµç¨‹ç™¼ç”ŸéŒ¯èª¤: {e}")
    
    def _save_database_preview(self, topic_branch_data, topic_branch_news_map_data):
        """å„²å­˜è³‡æ–™åº«é è¦½æª”æ¡ˆ"""
        try:
            print("\n--- ç”Ÿæˆè³‡æ–™åº«é è¦½æª”æ¡ˆ ---")
            
            # å„²å­˜ topic_branch é è¦½
            topic_branch_file = "database_preview_topic_branch.json"
            with open(topic_branch_file, 'w', encoding='utf-8') as f:
                json.dump(topic_branch_data, f, ensure_ascii=False, indent=2)
            print(f"âœ“ topic_branch é è¦½å·²å„²å­˜: {topic_branch_file}")
            print(f"  å…± {len(topic_branch_data)} å€‹ä¸»é¡Œåˆ†æ”¯")
            
            # å„²å­˜ topic_branch_news_map é è¦½
            topic_branch_news_map_file = "database_preview_topic_branch_news_map.json"
            with open(topic_branch_news_map_file, 'w', encoding='utf-8') as f:
                json.dump(topic_branch_news_map_data, f, ensure_ascii=False, indent=2)
            print(f"âœ“ topic_branch_news_map é è¦½å·²å„²å­˜: {topic_branch_news_map_file}")
            print(f"  å…± {len(topic_branch_news_map_data)} ç­†å°æ‡‰é—œä¿‚")
            
            # é¡¯ç¤ºç¯„ä¾‹
            print("\nã€topic_branch ç¯„ä¾‹ã€‘")
            for i, item in enumerate(topic_branch_data[:3], 1):
                print(f"{i}. topic_id: {item['topic_id']}")
                print(f"   topic_branch_id: {item['topic_branch_id']}")
                print(f"   topic_branch_title: {item['topic_branch_title']}")
                print(f"   topic_branch_content: {item['topic_branch_content'][:50]}...")
                print()
            
            print("ã€topic_branch_news_map ç¯„ä¾‹ã€‘")
            for i, item in enumerate(topic_branch_news_map_data[:5], 1):
                print(f"{i}. {item['topic_branch_id']} <-> {item['story_id']}")
            
            if len(topic_branch_news_map_data) > 5:
                print(f"... é‚„æœ‰ {len(topic_branch_news_map_data) - 5} ç­†è³‡æ–™")
            
        except Exception as e:
            print(f"âœ— ç”Ÿæˆé è¦½æª”æ¡ˆæ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
    
    def _save_to_actual_database(self, topic_branch_data, topic_branch_news_map_data):
        """å„²å­˜åˆ°å¯¦éš›è³‡æ–™åº«"""
        try:
            print("\n--- é–‹å§‹å„²å­˜åˆ°å¯¦éš›è³‡æ–™åº« ---")
            
            # å„²å­˜ topic_branch è³‡æ–™
            print("1. å„²å­˜ topic_branch è³‡æ–™...")
            if topic_branch_data:
                # æ¸…é™¤ç¾æœ‰è³‡æ–™ï¼ˆå¯é¸ - æ ¹æ“šéœ€æ±‚æ±ºå®šï¼‰
                # self.supabase.table('topic_branch').delete().neq('topic_id', '').execute()
                
                batch_size = 50
                success_count = 0
                
                for i in range(0, len(topic_branch_data), batch_size):
                    batch = topic_branch_data[i:i + batch_size]
                    try:
                        response = self.supabase.table('topic_branch').upsert(batch).execute()
                        if response.data:
                            success_count += len(batch)
                            print(f"   âœ“ topic_branch ç¬¬ {i//batch_size + 1} æ‰¹ ({len(batch)} ç­†)")
                        else:
                            print(f"   âœ— topic_branch ç¬¬ {i//batch_size + 1} æ‰¹æ’å…¥å¤±æ•—")
                    except Exception as e:
                        print(f"   âœ— topic_branch ç¬¬ {i//batch_size + 1} æ‰¹ç™¼ç”ŸéŒ¯èª¤: {e}")
                
                print(f"   â†’ topic_branch æˆåŠŸå„²å­˜: {success_count}/{len(topic_branch_data)} ç­†")
            
            # å„²å­˜ topic_branch_news_map è³‡æ–™
            print("2. å„²å­˜ topic_branch_news_map è³‡æ–™...")
            if topic_branch_news_map_data:
                # æ¸…é™¤ç¾æœ‰è³‡æ–™ï¼ˆå¯é¸ï¼‰
                # self.supabase.table('topic_branch_news_map').delete().neq('topic_branch_id', '').execute()
                
                batch_size = 100
                success_count = 0
                
                for i in range(0, len(topic_branch_news_map_data), batch_size):
                    batch = topic_branch_news_map_data[i:i + batch_size]
                    try:
                        response = self.supabase.table('topic_branch_news_map').upsert(batch).execute()
                        if response.data:
                            success_count += len(batch)
                            print(f"   âœ“ topic_branch_news_map ç¬¬ {i//batch_size + 1} æ‰¹ ({len(batch)} ç­†)")
                        else:
                            print(f"   âœ— topic_branch_news_map ç¬¬ {i//batch_size + 1} æ‰¹æ’å…¥å¤±æ•—")
                    except Exception as e:
                        print(f"   âœ— topic_branch_news_map ç¬¬ {i//batch_size + 1} æ‰¹ç™¼ç”ŸéŒ¯èª¤: {e}")
                
                print(f"   â†’ topic_branch_news_map æˆåŠŸå„²å­˜: {success_count}/{len(topic_branch_news_map_data)} ç­†")
            
            print("\nâœ… è³‡æ–™åº«å„²å­˜å®Œæˆï¼")
            
        except Exception as e:
            print(f"âœ— å„²å­˜åˆ°å¯¦éš›è³‡æ–™åº«æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
    
    def save_to_json(self, event_groups, output_path):
        """å„²å­˜çµæœåˆ° JSON æª”æ¡ˆ"""
        try:
            with open(output_path, 'w', encoding='utf-8') as f:
                json.dump(event_groups, f, ensure_ascii=False, indent=2)
            print(f"çµæœå·²å„²å­˜è‡³: {output_path}")
        except Exception as e:
            print(f"å„²å­˜æª”æ¡ˆæ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
    
    def process_topic_with_incremental_update(self, topic_id, new_story_ids, existing_branches):
        """å¢é‡æ›´æ–°ï¼šè™•ç†æ–°æ–°èèˆ‡ç¾æœ‰åˆ†æ”¯çš„æ•´åˆ
        
        Args:
            topic_id: ä¸»é¡Œ ID
            new_story_ids: æ–°åŠ å…¥çš„ story_id åˆ—è¡¨
            existing_branches: ç¾æœ‰çš„åˆ†æ”¯è³‡æ–™
        
        Returns:
            æ›´æ–°å¾Œçš„åˆ†æ”¯çµæ§‹ + éœ€è¦åˆªé™¤çš„èˆŠåˆ†æ”¯ ID
        """
        print(f"\n  ã€å¢é‡æ›´æ–°æ¨¡å¼ã€‘è™•ç† {len(new_story_ids)} å‰‡æ–°æ–°è")
        
        # 1. ç²å–æ–°æ–°èå…§å®¹
        new_news_items = self.fetch_news_from_supabase(new_story_ids)
        if not new_news_items:
            print("  âœ— æœªç²å–åˆ°æ–°æ–°èå…§å®¹")
            return None, []
        
        # 2. æå–"å…¶ä»–"æš«å­˜å€ï¼ˆå¦‚æœå­˜åœ¨ï¼‰
        other_branch = None
        normal_branches = []
        
        for branch in existing_branches:
            if self.OTHER_BRANCH_TITLE in branch['title']:
                other_branch = branch
                print(f"  â†’ æ‰¾åˆ°æš«å­˜å€åˆ†æ”¯: {branch['news_count']} å‰‡æ–°è")
            else:
                normal_branches.append(branch)
        
        # 3. å˜—è©¦å°‡æ–°æ–°èåŠ å…¥ç¾æœ‰åˆ†æ”¯
        unmatched_new_news = []
        branch_additions = {}  # {branch_id: [news_items to add]}
        
        print(f"\n  æª¢æŸ¥æ–°æ–°èæ˜¯å¦å¯åŠ å…¥ç¾æœ‰ {len(normal_branches)} å€‹åˆ†æ”¯...")
        for new_news in new_news_items:
            matched = False
            
            for branch in normal_branches:
                # ç²å–è©²åˆ†æ”¯çš„æ–°èå…§å®¹ç”¨æ–¼åˆ¤æ–·
                branch_news = self.fetch_news_from_supabase(branch['story_ids'][:5])  # å–å‰5å‰‡ä»£è¡¨
                
                if self.check_if_news_fits_branch(new_news, branch_news):
                    print(f"    âœ“ æ–°èã€Œ{new_news['news_title'][:30]}ã€å¯åŠ å…¥åˆ†æ”¯ã€Œ{branch['title']}ã€")
                    if branch['branch_id'] not in branch_additions:
                        branch_additions[branch['branch_id']] = []
                    branch_additions[branch['branch_id']].append(new_news)
                    matched = True
                    break
            
            if not matched:
                print(f"    â—‹ æ–°èã€Œ{new_news['news_title'][:30]}ã€æœªåŒ¹é…ç¾æœ‰åˆ†æ”¯")
                unmatched_new_news.append(new_news)
        
        # 4. åˆä½µæš«å­˜å€æ–°è + æœªåŒ¹é…çš„æ–°æ–°è
        candidate_for_regroup = unmatched_new_news.copy()
        if other_branch:
            other_news = self.fetch_news_from_supabase(other_branch['story_ids'])
            candidate_for_regroup.extend(other_news)
            print(f"\n  åˆä½µæš«å­˜å€ {len(other_news)} å‰‡ + æ–°æœªåŒ¹é… {len(unmatched_new_news)} å‰‡ = {len(candidate_for_regroup)} å‰‡")
        
        # 5. åˆ¤æ–·æ˜¯å¦éœ€è¦é‡æ–°åˆ†çµ„
        need_regroup = False
        branches_to_delete = []
        new_branches = []
        
        if len(candidate_for_regroup) >= self.MIN_BRANCH_SIZE:
            print(f"\n  â˜… æš«å­˜å€+æ–°æ–°èå…± {len(candidate_for_regroup)} å‰‡ï¼Œé”åˆ°æœ€å°è¦æ¨¡ï¼Œå˜—è©¦é‡æ–°åˆ†çµ„...")
            need_regroup = True
            
            # é‡æ–°åˆ†çµ„é€™äº›æ–°è
            regrouped = self.group_news_by_events_ai_with_min_size(
                candidate_for_regroup, 
                min_size=self.MIN_BRANCH_SIZE
            )
            
            # æ¨™è¨˜èˆŠçš„"å…¶ä»–"åˆ†æ”¯éœ€è¦åˆªé™¤
            if other_branch:
                branches_to_delete.append(other_branch['branch_id'])
            
            new_branches = regrouped
        
        elif candidate_for_regroup:
            # æ•¸é‡ä¸è¶³ï¼Œæ”¾å›æš«å­˜å€
            print(f"\n  â†’ æš«å­˜å€+æ–°æ–°èå…± {len(candidate_for_regroup)} å‰‡ï¼Œä¸è¶³æœ€å°è¦æ¨¡ï¼Œç¹¼çºŒæ”¾å…¥æš«å­˜å€")
            other_branch_new = {
                'event_id': other_branch['branch_id'] if other_branch else str(uuid.uuid4()),
                'event_title': self.OTHER_BRANCH_TITLE,
                'event_summary': f'åŒ…å« {len(candidate_for_regroup)} å‰‡å¾…é‡æ–°åˆ†é¡çš„æ–°è',
                'news_count': len(candidate_for_regroup),
                'news_items': candidate_for_regroup,
                'is_other': True
            }
            new_branches = [other_branch_new]
        
        # 6. çµ„åˆæœ€çµ‚çµæœ
        result_branches = []
        
        # åŠ å…¥æ›´æ–°å¾Œçš„ç¾æœ‰åˆ†æ”¯
        for branch in normal_branches:
            branch_dict = {
                'event_id': branch['branch_id'],
                'event_title': branch['title'],
                'event_summary': branch['content'],
                'news_count': branch['news_count'],
                'news_items': []  # å¯¦éš›å¯«å…¥æ™‚æœƒè£œé½Š
            }
            
            # å¦‚æœè©²åˆ†æ”¯æœ‰æ–°å¢æ–°è
            if branch['branch_id'] in branch_additions:
                added_count = len(branch_additions[branch['branch_id']])
                branch_dict['news_count'] += added_count
                branch_dict['news_items'] = branch_additions[branch['branch_id']]
                print(f"    â†’ åˆ†æ”¯ã€Œ{branch['title']}ã€å°‡æ–°å¢ {added_count} å‰‡æ–°è")
            
            result_branches.append(branch_dict)
        
        # åŠ å…¥æ–°åˆ†çµ„çš„åˆ†æ”¯
        result_branches.extend(new_branches)
        
        return result_branches, branches_to_delete
    
    def process_from_topic_map(self, output_path, save_to_db=True, incremental_mode=False):
        """ä½¿ç”¨ topic_news_map çš„è™•ç†æµç¨‹
        
        Args:
            output_path: JSON è¼¸å‡ºæª”æ¡ˆè·¯å¾‘
            save_to_db: æ˜¯å¦å„²å­˜åˆ°è³‡æ–™åº« (True=å„²å­˜, False=åƒ…é è¦½)
            incremental_mode: æ˜¯å¦ä½¿ç”¨å¢é‡æ›´æ–°æ¨¡å¼ï¼ˆæª¢æŸ¥ç¾æœ‰åˆ†æ”¯ä¸¦æ™ºèƒ½æ•´åˆæ–°æ–°èï¼‰
        """
        print("=" * 60)
        if incremental_mode:
            print("æ–°èäº‹ä»¶åˆ†çµ„å™¨ - å¢é‡æ›´æ–°æ¨¡å¼ï¼ˆæœ€å°åˆ†æ”¯è¦æ¨¡: 5 å‰‡ï¼‰")
        else:
            print("æ–°èäº‹ä»¶åˆ†çµ„å™¨ - å¾ topic_news_map é–‹å§‹è™•ç†")
        print("=" * 60)
        
        # 1. å¾ topic_news_map ç²å–è³‡æ–™
        topic_news_map = self.fetch_topic_news_map_from_supabase()
        if not topic_news_map:
            print("æœªç²å–åˆ° topic_news_map è³‡æ–™ï¼Œç¨‹å¼çµæŸ")
            return
        
        # 2. æ ¹æ“š topic_id åˆ†çµ„
        topic_groups = self.group_by_topic_id(topic_news_map)
        if not topic_groups:
            print("æœªæ‰¾åˆ°æœ‰æ•ˆçš„ä¸»é¡Œåˆ†çµ„ï¼Œç¨‹å¼çµæŸ")
            return
        
        # 3. ç‚ºæ¯å€‹ä¸»é¡Œçµ„ç²å–æ–°èå…§å®¹ï¼Œç„¶å¾Œå†ç”¨ AI åšç´°åˆ†
        all_topic_events = []
        all_branches_to_delete = []  # æ”¶é›†éœ€è¦åˆªé™¤çš„èˆŠåˆ†æ”¯ ID
        
        for topic_id, story_ids in topic_groups.items():
            print(f"\n{'='*60}")
            print(f"è™•ç†ä¸»é¡Œ {topic_id} ({len(story_ids)} å‰‡æ–°è)")
            print(f"{'='*60}")
            
            # ã€å¢é‡æ¨¡å¼ã€‘æª¢æŸ¥ç¾æœ‰åˆ†æ”¯
            if incremental_mode:
                existing_branches = self.fetch_existing_branches_for_topic(topic_id)
                
                if existing_branches:
                    # æ‰¾å‡ºæ–°å¢çš„æ–°èï¼ˆä¸åœ¨ç¾æœ‰åˆ†æ”¯ä¸­çš„ï¼‰
                    existing_story_ids = set()
                    for branch in existing_branches:
                        existing_story_ids.update(branch['story_ids'])
                    
                    new_story_ids = [sid for sid in story_ids if sid not in existing_story_ids]
                    
                    if new_story_ids:
                        print(f"  ç™¼ç¾ {len(new_story_ids)} å‰‡æ–°æ–°èï¼ˆç¾æœ‰ {len(existing_story_ids)} å‰‡ï¼‰")
                        
                        # ä½¿ç”¨å¢é‡æ›´æ–°é‚è¼¯
                        updated_branches, branches_to_delete = self.process_topic_with_incremental_update(
                            topic_id, new_story_ids, existing_branches
                        )
                        
                        if branches_to_delete:
                            all_branches_to_delete.extend(branches_to_delete)
                            print(f"\n  âš ï¸ éœ€è¦åˆªé™¤ {len(branches_to_delete)} å€‹èˆŠåˆ†æ”¯ï¼ˆå°‡é‡æ–°åˆ†çµ„ï¼‰")
                        
                        if updated_branches:
                            # ç”Ÿæˆä¸»é¡Œæ¨™é¡Œ
                            all_news_items = self.fetch_news_from_supabase(story_ids)
                            topic_title = self.generate_topic_title(all_news_items)
                            
                            topic_event = {
                                'topic_id': topic_id,
                                'topic_title': topic_title,
                                'sub_events': updated_branches
                            }
                            all_topic_events.append(topic_event)
                            continue
                    else:
                        print("  â†’ ç„¡æ–°æ–°èï¼Œä¿æŒç¾æœ‰åˆ†æ”¯çµæ§‹")
                        
                        # ä¿ç•™ç¾æœ‰åˆ†æ”¯çµæ§‹åˆ°çµæœä¸­
                        all_news_items = self.fetch_news_from_supabase(story_ids)
                        topic_title = self.generate_topic_title(all_news_items)
                        
                        # å°‡ç¾æœ‰åˆ†æ”¯è½‰æ›ç‚ºæ¨™æº–æ ¼å¼
                        sub_events = []
                        for branch in existing_branches:
                            branch_news = self.fetch_news_from_supabase(branch['story_ids'])
                            sub_events.append({
                                'event_id': branch['branch_id'],
                                'event_title': branch['title'],
                                'event_summary': branch['content'],
                                'news_count': len(branch_news),
                                'news_items': branch_news,
                                'is_other': self.OTHER_BRANCH_TITLE in branch['title']
                            })
                        
                        topic_event = {
                            'topic_id': topic_id,
                            'topic_title': topic_title,
                            'sub_events': sub_events,
                            'status': 'unchanged'  # æ¨™è¨˜ç‚ºæœªè®Šæ›´
                        }
                        all_topic_events.append(topic_event)
                        continue
            
            # ã€æ¨™æº–æ¨¡å¼æˆ–é¦–æ¬¡è™•ç†ã€‘
            # ç²å–è©²ä¸»é¡Œçš„æ–°èå…§å®¹
            news_items = self.fetch_news_from_supabase(story_ids)
            
            if not news_items:
                print(f"âœ— ä¸»é¡Œ {topic_id}: æœªç²å–åˆ°æœ‰æ•ˆæ–°èå…§å®¹")
                continue
            
            # ç‚ºè©²ä¸»é¡Œç”Ÿæˆç¸½é«”æ¨™é¡Œ
            topic_title = self.generate_topic_title(news_items)
            print(f"âœ“ ä¸»é¡Œæ¨™é¡Œ: {topic_title}")
            
            # æ ¹æ“šæ–°èæ•¸é‡æ±ºå®šè™•ç†æ–¹å¼
            if len(news_items) < self.MIN_BRANCH_SIZE:
                # æ•¸é‡ä¸è¶³æœ€å°è¦æ¨¡ï¼Œç›´æ¥æ”¾å…¥æš«å­˜å€
                print(f"  â†’ æ–°èæ•¸é‡ {len(news_items)} ä¸è¶³æœ€å°è¦æ¨¡ {self.MIN_BRANCH_SIZE}ï¼Œæ”¾å…¥æš«å­˜å€")
                topic_summary = self.generate_topic_summary(news_items)
                topic_event = {
                    'topic_id': topic_id,
                    'topic_title': topic_title,
                    'sub_events': [
                        {
                            'event_id': str(uuid.uuid4()),
                            'event_title': self.OTHER_BRANCH_TITLE,
                            'event_summary': f'åŒ…å« {len(news_items)} å‰‡å¾…é‡æ–°åˆ†é¡çš„æ–°è',
                            'news_count': len(news_items),
                            'news_items': news_items,
                            'is_other': True
                        }
                    ]
                }
                all_topic_events.append(topic_event)
            
            else:
                # æ–°èæ•¸é‡è¶³å¤ ï¼Œä½¿ç”¨ AI é€²è¡Œç´°åˆ†ï¼ˆè€ƒæ…®æœ€å°è¦æ¨¡ï¼‰
                print(f"  æ­£åœ¨å° {len(news_items)} å‰‡æ–°èé€²è¡Œ AI ç´°åˆ†ï¼ˆæœ€å°è¦æ¨¡: {self.MIN_BRANCH_SIZE}ï¼‰...")
                sub_events = self.group_news_by_events_ai_with_min_size(
                    news_items, 
                    min_size=self.MIN_BRANCH_SIZE
                )
                
                # ç‚ºæ¯å€‹å­äº‹ä»¶æ·»åŠ  topic ç›¸é—œè³‡è¨Š
                for sub_event in sub_events:
                    sub_event['topic_id'] = topic_id
                
                topic_event = {
                    'topic_id': topic_id,
                    'topic_title': topic_title,
                    'sub_events': sub_events
                }
                all_topic_events.append(topic_event)
                
                print(f"\n  âœ“ ç´°åˆ†çµæœ:")
                for i, sub_event in enumerate(sub_events, 1):
                    is_other = sub_event.get('is_other', False)
                    marker = "ğŸ“¦" if is_other else "ğŸ“Œ"
                    print(f"    {marker} åˆ†æ”¯ {i}: {sub_event['event_title']} ({sub_event['news_count']} å‰‡æ–°è)")
        
        # 4. å„²å­˜çµæœåˆ° JSON
        self.save_to_json(all_topic_events, output_path)
        
        # 5. è¼¸å‡ºè©³ç´°é è¦½åˆ°çµ‚ç«¯
        print("\n" + "=" * 80)
        print("ğŸ“Š åˆ†çµ„çµæœé è¦½ï¼ˆè¼¸å‡ºåˆ°çµ‚ç«¯ï¼‰")
        print("=" * 80)
        
        for i, topic in enumerate(all_topic_events, 1):
            print(f"\nã€ä¸»é¡Œ {i}ã€‘{topic['topic_title']}")
            print(f"  ä¸»é¡Œ ID: {topic['topic_id']}")
            print(f"  åˆ†æ”¯æ•¸é‡: {len(topic['sub_events'])}")
            
            for j, sub_event in enumerate(topic['sub_events'], 1):
                is_other = sub_event.get('is_other', False)
                marker = "ğŸ“¦ [æš«å­˜å€]" if is_other else "ğŸ“Œ"
                
                print(f"\n  {marker} åˆ†æ”¯ {j}: {sub_event['event_title']}")
                print(f"     åˆ†æ”¯ ID: {sub_event['event_id']}")
                print(f"     æ–°èæ•¸é‡: {sub_event['news_count']} å‰‡")
                print(f"     æ‘˜è¦: {sub_event['event_summary'][:80]}...")
                
                # åˆ—å‡ºå‰3å‰‡æ–°èæ¨™é¡Œ
                news_items = sub_event.get('news_items', [])
                if news_items:
                    print(f"     åŒ…å«æ–°è:")
                    for k, news in enumerate(news_items[:3], 1):
                        title = news.get('news_title', '')[:50]
                        print(f"       {k}. {title}{'...' if len(news.get('news_title', '')) > 50 else ''}")
                    if len(news_items) > 3:
                        print(f"       ... é‚„æœ‰ {len(news_items) - 3} å‰‡æ–°è")
        
        # 6. é¡¯ç¤ºéœ€è¦åˆªé™¤çš„èˆŠåˆ†æ”¯ï¼ˆå¦‚æœæœ‰ï¼‰
        if all_branches_to_delete:
            print("\n" + "=" * 80)
            print("âš ï¸  éœ€è¦åˆªé™¤çš„èˆŠåˆ†æ”¯ IDï¼ˆå°‡åœ¨å¯«å…¥è³‡æ–™åº«æ™‚åŸ·è¡Œï¼‰")
            print("=" * 80)
            for branch_id in all_branches_to_delete:
                print(f"  - {branch_id}")
        
        # 7. å„²å­˜åˆ°è³‡æ–™åº«æˆ–åƒ…ç”Ÿæˆé è¦½
        print("\n" + "=" * 80)
        if save_to_db:
            print("âš ï¸  è³‡æ–™åº«å¯«å…¥å·²åœç”¨ï¼ˆæ ¹æ“šéœ€æ±‚å…ˆé è¦½åˆ°çµ‚ç«¯ï¼‰")
            print("=" * 80)
            print("å¦‚éœ€å¯«å…¥è³‡æ–™åº«ï¼Œè«‹ä¿®æ”¹ main() ä¸­çš„ save_to_db åƒæ•¸ç‚º True")
        else:
            print("ğŸ“‹ åƒ…é è¦½æ¨¡å¼ï¼ˆä¸æœƒå¯«å…¥è³‡æ–™åº«ï¼‰")
            print("=" * 80)
        
        # 8. æª¢æŸ¥ä¸¦é‡æ–°è™•ç†ä¸è¶³è¦æ¨¡çš„åˆ†æ”¯
        print("\n" + "=" * 80)
        print("ğŸ” æª¢æŸ¥ä¸è¶³è¦æ¨¡çš„åˆ†æ”¯ï¼ˆéæš«å­˜å€ï¼‰")
        print("=" * 80)
        
        undersized_branches = []
        for topic in all_topic_events:
            topic_id = topic['topic_id']
            for sub_event in topic['sub_events']:
                # åªæª¢æŸ¥éæš«å­˜å€çš„åˆ†æ”¯
                if not sub_event.get('is_other', False):
                    if sub_event['news_count'] < self.MIN_BRANCH_SIZE:
                        undersized_branches.append({
                            'topic_id': topic_id,
                            'topic_title': topic['topic_title'],
                            'branch': sub_event
                        })
                        print(f"âš ï¸  ä¸»é¡Œã€Œ{topic['topic_title']}ã€çš„åˆ†æ”¯ã€Œ{sub_event['event_title']}ã€")
                        print(f"    åªæœ‰ {sub_event['news_count']} å‰‡æ–°èï¼ˆä¸è¶³ {self.MIN_BRANCH_SIZE} å‰‡ï¼‰")
        
        if undersized_branches:
            print(f"\nç™¼ç¾ {len(undersized_branches)} å€‹ä¸è¶³è¦æ¨¡çš„åˆ†æ”¯ï¼Œå°‡é‡æ–°åˆ†çµ„...")
            print("=" * 80)
            
            # æŒ‰ä¸»é¡Œåˆ†çµ„ä¸è¶³è¦æ¨¡çš„åˆ†æ”¯
            undersized_by_topic = {}
            for item in undersized_branches:
                topic_id = item['topic_id']
                if topic_id not in undersized_by_topic:
                    undersized_by_topic[topic_id] = []
                undersized_by_topic[topic_id].append(item['branch'])
            
            # å°æ¯å€‹ä¸»é¡Œçš„ä¸è¶³è¦æ¨¡åˆ†æ”¯é€²è¡Œè™•ç†
            for topic_id, branches in undersized_by_topic.items():
                print(f"\nè™•ç†ä¸»é¡Œ {topic_id} çš„ä¸è¶³è¦æ¨¡åˆ†æ”¯...")
                
                # æ”¶é›†é€™äº›åˆ†æ”¯çš„æ‰€æœ‰æ–°è
                all_undersized_news = []
                branches_to_remove = []
                
                for branch in branches:
                    all_undersized_news.extend(branch['news_items'])
                    branches_to_remove.append(branch['event_id'])
                    print(f"  - æ‹†è§£åˆ†æ”¯ã€Œ{branch['event_title']}ã€({branch['news_count']} å‰‡)")
                
                print(f"\n  å…±æ”¶é›† {len(all_undersized_news)} å‰‡æ–°èï¼Œå˜—è©¦é‡æ–°åˆ†çµ„...")
                
                # æ‰¾åˆ°å°æ‡‰çš„ä¸»é¡Œä¸¦æ›´æ–°
                for topic in all_topic_events:
                    if topic['topic_id'] == topic_id:
                        # ç§»é™¤ä¸è¶³è¦æ¨¡çš„åˆ†æ”¯
                        topic['sub_events'] = [
                            sub for sub in topic['sub_events'] 
                            if sub['event_id'] not in branches_to_remove
                        ]
                        
                        # å°‹æ‰¾è©²ä¸»é¡Œçš„æš«å­˜å€åˆ†æ”¯
                        other_branch = None
                        for sub in topic['sub_events']:
                            if sub.get('is_other', False):
                                other_branch = sub
                                break
                        
                        # åˆä½µåˆ°æš«å­˜å€
                        if other_branch:
                            print(f"  â†’ å°‡ {len(all_undersized_news)} å‰‡æ–°èä½µå…¥ç¾æœ‰æš«å­˜å€")
                            other_branch['news_items'].extend(all_undersized_news)
                            other_branch['news_count'] += len(all_undersized_news)
                            other_branch['event_summary'] = f'åŒ…å« {other_branch["news_count"]} å‰‡å¾…é‡æ–°åˆ†é¡çš„æ–°è'
                            
                            # æª¢æŸ¥æ˜¯å¦é”åˆ°æœ€å°è¦æ¨¡å¯ä»¥é‡æ–°åˆ†çµ„
                            if other_branch['news_count'] >= self.MIN_BRANCH_SIZE:
                                print(f"  â˜… æš«å­˜å€å·²é” {other_branch['news_count']} å‰‡ï¼Œå˜—è©¦é‡æ–°åˆ†çµ„...")
                                
                                regrouped = self.group_news_by_events_ai_with_min_size(
                                    other_branch['news_items'],
                                    min_size=self.MIN_BRANCH_SIZE
                                )
                                
                                # ç§»é™¤èˆŠçš„æš«å­˜å€
                                topic['sub_events'] = [
                                    sub for sub in topic['sub_events']
                                    if not sub.get('is_other', False)
                                ]
                                
                                # åŠ å…¥é‡æ–°åˆ†çµ„çš„çµæœ
                                for new_branch in regrouped:
                                    new_branch['topic_id'] = topic_id
                                topic['sub_events'].extend(regrouped)
                                
                                print(f"  âœ“ é‡æ–°åˆ†çµ„å®Œæˆï¼Œç”¢ç”Ÿ {len(regrouped)} å€‹æ–°åˆ†æ”¯")
                                for i, branch in enumerate(regrouped, 1):
                                    is_other = branch.get('is_other', False)
                                    marker = "ğŸ“¦" if is_other else "ğŸ“Œ"
                                    print(f"    {marker} {branch['event_title']} ({branch['news_count']} å‰‡)")
                        else:
                            # å‰µå»ºæ–°çš„æš«å­˜å€
                            print(f"  â†’ å‰µå»ºæ–°æš«å­˜å€å®¹ç´ {len(all_undersized_news)} å‰‡æ–°è")
                            new_other = {
                                'event_id': str(uuid.uuid4()),
                                'event_title': self.OTHER_BRANCH_TITLE,
                                'event_summary': f'åŒ…å« {len(all_undersized_news)} å‰‡å¾…é‡æ–°åˆ†é¡çš„æ–°è',
                                'news_count': len(all_undersized_news),
                                'news_items': all_undersized_news,
                                'is_other': True,
                                'topic_id': topic_id
                            }
                            topic['sub_events'].append(new_other)
                        
                        # è¨˜éŒ„éœ€è¦åˆªé™¤çš„èˆŠåˆ†æ”¯
                        all_branches_to_delete.extend(branches_to_remove)
                        break
            
            print("\nâœ… ä¸è¶³è¦æ¨¡åˆ†æ”¯è™•ç†å®Œæˆ")
        else:
            print("âœ“ æ‰€æœ‰æ­£å¼åˆ†æ”¯éƒ½ç¬¦åˆæœ€å°è¦æ¨¡è¦æ±‚")
        
        # 9. è¼¸å‡ºçµ±è¨ˆè³‡è¨Š
        print("\n" + "=" * 80)
        print("ğŸ“ˆ çµ±è¨ˆæ‘˜è¦")
        print("=" * 80)
        print(f"ä¸»é¡Œæ•¸é‡: {len(topic_groups)}")
        print(f"æˆåŠŸè™•ç†çš„ä¸»é¡Œ: {len(all_topic_events)}")
        
        total_sub_events = sum(len(topic['sub_events']) for topic in all_topic_events)
        total_normal_branches = sum(
            1 for topic in all_topic_events 
            for sub in topic['sub_events'] 
            if not sub.get('is_other', False)
        )
        total_other_branches = total_sub_events - total_normal_branches
        total_news = sum(
            sum(sub_event['news_count'] for sub_event in topic['sub_events'])
            for topic in all_topic_events
        )
        
        print(f"ç¸½åˆ†æ”¯æ•¸é‡: {total_sub_events}")
        print(f"  - æ­£å¼åˆ†æ”¯: {total_normal_branches}")
        print(f"  - æš«å­˜å€åˆ†æ”¯: {total_other_branches}")
        print(f"ç¸½æ–°èæ•¸é‡: {total_news}")
        
        if all_branches_to_delete:
            print(f"\néœ€è¦åˆªé™¤çš„èˆŠåˆ†æ”¯: {len(all_branches_to_delete)} å€‹")
        
        return all_topic_events
    
    def generate_topic_title(self, news_items):
        """ç‚ºæ•´å€‹ä¸»é¡Œç”Ÿæˆæ¨™é¡Œ"""
        if not self.genai_client or not news_items:
            return f"ä¸»é¡Œäº‹ä»¶ ({len(news_items)} å‰‡æ–°è)"
        
        # å–å‰3å‰‡æ–°èçš„æ¨™é¡Œå’Œå…§å®¹ç‰‡æ®µ
        sample_news = []
        for i, news in enumerate(news_items[:3], 1):
            title = news['news_title'][:50]
            content = news['content'][:80]
            sample_news.append(f"æ–°è{i}: {title} - {content}...")
        
        prompt = f"""
åŸºæ–¼ä»¥ä¸‹ {len(news_items)} å‰‡æ–°èï¼Œç”Ÿæˆä¸€å€‹ç°¡æ½”çš„ä¸»é¡Œæ¨™é¡Œã€‚

ç¯„ä¾‹æ–°èï¼š
{chr(1000).join(sample_news)}

è«‹ç”Ÿæˆä¸€å€‹8å­—ä»¥å…§çš„ä¸»é¡Œæ¨™é¡Œï¼Œåªå›å‚³æ¨™é¡Œæ–‡å­—ï¼Œä¸è¦å…¶ä»–å…§å®¹ã€‚
"""
        
        try:
            response = self.genai_client.models.generate_content(
                model='gemini-2.5-flash',
                contents=prompt
            )
            title = response.text.strip().replace('"', '').replace("'", '')
            return title if len(title) <= 20 else title[:17] + "..."
            
        except Exception as e:
            print(f"  âœ— AI ç”Ÿæˆä¸»é¡Œæ¨™é¡Œæ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
            return f"ä¸»é¡Œäº‹ä»¶ ({len(news_items)} å‰‡æ–°è)"
    
    def generate_topic_summary(self, news_items):
        """ç‚ºä¸»é¡Œç”Ÿæˆæ¦‚è¦"""
        if not self.genai_client or not news_items:
            return f"åŒ…å« {len(news_items)} å‰‡ç›¸é—œæ–°èçš„ä¸»é¡Œäº‹ä»¶"
        
        # å–å‰3å‰‡æ–°èçš„å…§å®¹
        sample_news = []
        for i, news in enumerate(news_items[:3], 1):
            content = news['content'][:100]
            sample_news.append(f"æ–°è{i}: {content}...")
        
        prompt = f"""
åŸºæ–¼ä»¥ä¸‹æ–°èå…§å®¹ï¼Œç”Ÿæˆä¸€å€‹80å­—ä»¥å…§çš„äº‹ä»¶æ¦‚è¦ã€‚

æ–°èå…§å®¹ï¼š
{chr(1000).join(sample_news)}

è«‹ç”Ÿæˆç°¡æ½”çš„æ¦‚è¦èªªæ˜ï¼Œåªå›å‚³æ¦‚è¦æ–‡å­—ï¼Œä¸è¦å…¶ä»–å…§å®¹ã€‚
"""
        
        try:
            response = self.genai_client.models.generate_content(
                model='gemini-1.5-flash',
                contents=prompt
            )
            summary = response.text.strip()
            return summary if len(summary) <= 100 else summary[:97] + "..."
            
        except Exception as e:
            print(f"  âœ— AI ç”Ÿæˆæ¦‚è¦æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
            return f"åŒ…å« {len(news_items)} å‰‡ç›¸é—œæ–°èçš„ä¸»é¡Œäº‹ä»¶"
    
    def regroup_single_topic(self, topic_id, save_to_db=True):
        """é‡æ–°åˆ†çµ„å–®å€‹ä¸»é¡Œä¸¦æ›´æ–°åˆ°è³‡æ–™åº«
        
        Args:
            topic_id: è¦é‡æ–°åˆ†çµ„çš„ä¸»é¡Œ ID
            save_to_db: æ˜¯å¦å¯«å…¥è³‡æ–™åº«ï¼ˆTrue=å¯«å…¥, False=åƒ…é è¦½ï¼‰
        
        Returns:
            é‡æ–°åˆ†çµ„å¾Œçš„ä¸»é¡Œè³‡æ–™
        """
        print("=" * 80)
        print(f"ğŸ”„ é‡æ–°åˆ†çµ„å–®ä¸€ä¸»é¡Œ: {topic_id}")
        print("=" * 80)
        
        # 1. å¾ topic_news_map ç²å–è©²ä¸»é¡Œçš„æ‰€æœ‰æ–°è
        try:
            response = self.supabase.table('topic_news_map').select(
                'story_id'
            ).eq('topic_id', topic_id).execute()
            
            if not response.data:
                print(f"âœ— æœªæ‰¾åˆ°ä¸»é¡Œ {topic_id} çš„æ–°èæ˜ å°„")
                return None
            
            story_ids = [item['story_id'] for item in response.data]
            print(f"âœ“ æ‰¾åˆ° {len(story_ids)} å‰‡æ–°è")
            
        except Exception as e:
            print(f"âœ— ç²å–ä¸»é¡Œæ–°èæ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
            return None
        
        # 2. ç²å–æ–°èå…§å®¹
        news_items = self.fetch_news_from_supabase(story_ids)
        if not news_items:
            print("âœ— æœªç²å–åˆ°æ–°èå…§å®¹")
            return None
        
        # 3. ç”Ÿæˆä¸»é¡Œæ¨™é¡Œ
        topic_title = self.generate_topic_title(news_items)
        print(f"âœ“ ä¸»é¡Œæ¨™é¡Œ: {topic_title}")
        
        # 4. ä½¿ç”¨ AI é‡æ–°åˆ†çµ„ï¼ˆè€ƒæ…®æœ€å°è¦æ¨¡ï¼‰
        print(f"\næ­£åœ¨é‡æ–°åˆ†çµ„ {len(news_items)} å‰‡æ–°è...")
        sub_events = self.group_news_by_events_ai_with_min_size(
            news_items,
            min_size=self.MIN_BRANCH_SIZE
        )
        
        # ç‚ºæ¯å€‹å­äº‹ä»¶æ·»åŠ  topic_id
        for sub_event in sub_events:
            sub_event['topic_id'] = topic_id
        
        topic_event = {
            'topic_id': topic_id,
            'topic_title': topic_title,
            'sub_events': sub_events
        }
        
        # 5. è¼¸å‡ºé è¦½
        print("\n" + "=" * 80)
        print("ğŸ“Š é‡æ–°åˆ†çµ„çµæœé è¦½")
        print("=" * 80)
        print(f"\nã€ä¸»é¡Œã€‘{topic_title}")
        print(f"  ä¸»é¡Œ ID: {topic_id}")
        print(f"  ç¸½æ–°èæ•¸: {len(news_items)}")
        print(f"  åˆ†æ”¯æ•¸é‡: {len(sub_events)}")
        
        for i, sub_event in enumerate(sub_events, 1):
            is_other = sub_event.get('is_other', False)
            marker = "ğŸ“¦ [æš«å­˜å€]" if is_other else "ğŸ“Œ"
            
            print(f"\n  {marker} åˆ†æ”¯ {i}: {sub_event['event_title']}")
            print(f"     åˆ†æ”¯ ID: {sub_event['event_id']}")
            print(f"     æ–°èæ•¸é‡: {sub_event['news_count']} å‰‡")
            print(f"     æ‘˜è¦: {sub_event['event_summary'][:80]}...")
            
            # åˆ—å‡ºå‰3å‰‡æ–°èæ¨™é¡Œ
            news_list = sub_event.get('news_items', [])
            if news_list:
                print(f"     åŒ…å«æ–°è:")
                for j, news in enumerate(news_list[:3], 1):
                    title = news.get('news_title', '')[:50]
                    print(f"       {j}. {title}{'...' if len(news.get('news_title', '')) > 50 else ''}")
                if len(news_list) > 3:
                    print(f"       ... é‚„æœ‰ {len(news_list) - 3} å‰‡æ–°è")
        
        # 6. å¯«å…¥è³‡æ–™åº«
        if save_to_db:
            print("\n" + "=" * 80)
            print("ğŸ’¾ é–‹å§‹æ›´æ–°è³‡æ–™åº«...")
            print("=" * 80)
            
            try:
                # Step 1: åˆªé™¤è©²ä¸»é¡Œçš„èˆŠåˆ†æ”¯
                print("\n1. åˆªé™¤èˆŠåˆ†æ”¯...")
                
                # å…ˆæ‰¾å‡ºè©²ä¸»é¡Œçš„æ‰€æœ‰èˆŠåˆ†æ”¯ ID
                old_branches_response = self.supabase.table('topic_branch').select(
                    'topic_branch_id'
                ).eq('topic_id', topic_id).execute()
                
                if old_branches_response.data:
                    old_branch_ids = [b['topic_branch_id'] for b in old_branches_response.data]
                    print(f"   æ‰¾åˆ° {len(old_branch_ids)} å€‹èˆŠåˆ†æ”¯")
                    
                    # åˆªé™¤ topic_branch_news_map ä¸­çš„å°æ‡‰é—œä¿‚
                    for branch_id in old_branch_ids:
                        self.supabase.table('topic_branch_news_map').delete().eq(
                            'topic_branch_id', branch_id
                        ).execute()
                    print(f"   âœ“ å·²åˆªé™¤ topic_branch_news_map ä¸­çš„å°æ‡‰é—œä¿‚")
                    
                    # åˆªé™¤ topic_branch ä¸­çš„èˆŠåˆ†æ”¯
                    self.supabase.table('topic_branch').delete().eq(
                        'topic_id', topic_id
                    ).execute()
                    print(f"   âœ“ å·²åˆªé™¤ {len(old_branch_ids)} å€‹èˆŠåˆ†æ”¯")
                else:
                    print("   â†’ è©²ä¸»é¡Œç„¡èˆŠåˆ†æ”¯")
                
                # Step 2: å¯«å…¥æ–°åˆ†æ”¯
                print("\n2. å¯«å…¥æ–°åˆ†æ”¯...")
                
                topic_branch_data = []
                topic_branch_news_map_data = []
                
                for sub_event in sub_events:
                    branch_id = sub_event['event_id']
                    
                    # æº–å‚™ topic_branch è³‡æ–™
                    topic_branch_data.append({
                        'topic_id': topic_id,
                        'topic_branch_id': branch_id,
                        'topic_branch_title': sub_event['event_title'],
                        'topic_branch_content': sub_event['event_summary']
                    })
                    
                    # æº–å‚™ topic_branch_news_map è³‡æ–™
                    for news_item in sub_event.get('news_items', []):
                        topic_branch_news_map_data.append({
                            'topic_branch_id': branch_id,
                            'story_id': news_item['story_id']
                        })
                
                # æ‰¹æ¬¡å¯«å…¥ topic_branch
                if topic_branch_data:
                    response = self.supabase.table('topic_branch').insert(topic_branch_data).execute()
                    if response.data:
                        print(f"   âœ“ æˆåŠŸå¯«å…¥ {len(topic_branch_data)} å€‹æ–°åˆ†æ”¯")
                    else:
                        print(f"   âœ— å¯«å…¥ topic_branch å¤±æ•—")
                
                # æ‰¹æ¬¡å¯«å…¥ topic_branch_news_map
                if topic_branch_news_map_data:
                    batch_size = 100
                    success_count = 0
                    
                    for i in range(0, len(topic_branch_news_map_data), batch_size):
                        batch = topic_branch_news_map_data[i:i + batch_size]
                        response = self.supabase.table('topic_branch_news_map').insert(batch).execute()
                        if response.data:
                            success_count += len(batch)
                    
                    print(f"   âœ“ æˆåŠŸå¯«å…¥ {success_count}/{len(topic_branch_news_map_data)} ç­†æ–°èå°æ‡‰")
                
                print("\nâœ… è³‡æ–™åº«æ›´æ–°å®Œæˆï¼")
                
            except Exception as e:
                print(f"\nâœ— è³‡æ–™åº«æ›´æ–°æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
                import traceback
                traceback.print_exc()
        else:
            print("\n" + "=" * 80)
            print("ğŸ“‹ é è¦½æ¨¡å¼ï¼ˆæœªå¯«å…¥è³‡æ–™åº«ï¼‰")
            print("=" * 80)
        
        return topic_event
    
    def generate_topic_title_and_summary(self, news_items):
        """ä½¿ç”¨ AI ç‚ºä¸»é¡Œç”Ÿæˆæ¨™é¡Œå’Œæ¦‚è¦"""
        if not self.genai_client or not news_items:
            return f"ä¸»é¡Œäº‹ä»¶ ({len(news_items)} å‰‡æ–°è)", f"åŒ…å« {len(news_items)} å‰‡ç›¸é—œæ–°èçš„ä¸»é¡Œäº‹ä»¶"
        
        # æº–å‚™æ–°èæ‘˜è¦
        news_summaries = []
        for i, news in enumerate(news_items[:5], 1):  # æœ€å¤šå–å‰5å‰‡æ–°èåˆ†æ
            title = news['news_title'][:60]
            content = news['content'][:100]
            news_summaries.append(f"æ–°è{i}: {title} - {content}...")
        
        prompt = f"""
åŸºæ–¼ä»¥ä¸‹ {len(news_items)} å‰‡æ–°èï¼Œç”Ÿæˆä¸€å€‹ç°¡æ½”çš„äº‹ä»¶æ¨™é¡Œå’Œæ¦‚è¦ã€‚

æ–°èå…§å®¹ï¼š
{chr(1000).join(news_summaries)}

è«‹ä»¥ JSON æ ¼å¼å›å‚³ï¼š
{{
  "title": "ç°¡æ½”çš„äº‹ä»¶æ¨™é¡Œï¼ˆ8å­—ä»¥å…§ï¼‰",
  "summary": "äº‹ä»¶æ¦‚è¦èªªæ˜ï¼ˆ80å­—ä»¥å…§ï¼‰"
}}

åªå›å‚³ JSONï¼Œä¸è¦å…¶ä»–æ–‡å­—ã€‚
"""
        
        try:
            response = self.genai_client.models.generate_content(
                model='gemini-2.5-flash',
                contents=prompt
            )
            result_text = response.text.strip()
            
            # æ¸…ç† JSON æ ¼å¼
            if result_text.startswith('```json'):
                result_text = result_text[7:-3].strip()
            elif result_text.startswith('```'):
                result_text = result_text[3:-3].strip()
            
            result = json.loads(result_text)
            return result.get('title', 'ä¸»é¡Œäº‹ä»¶'), result.get('summary', f'åŒ…å« {len(news_items)} å‰‡ç›¸é—œæ–°è')
            
        except Exception as e:
            print(f"âœ— AI ç”Ÿæˆæ¨™é¡Œå’Œæ¦‚è¦æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
            return f"ä¸»é¡Œäº‹ä»¶ ({len(news_items)} å‰‡æ–°è)", f"åŒ…å« {len(news_items)} å‰‡ç›¸é—œæ–°èçš„ä¸»é¡Œäº‹ä»¶"
    
    def process(self, json_file_path, output_path):
        """å®Œæ•´è™•ç†æµç¨‹ï¼ˆåŸç‰ˆ - å¾JSONæª”æ¡ˆé–‹å§‹ï¼‰"""
        print("=" * 60)
        print("æ–°èäº‹ä»¶åˆ†çµ„å™¨ - é–‹å§‹è™•ç†")
        print("=" * 60)
        
        # 1. è®€å– story_id
        story_ids = self.read_story_ids_from_json(json_file_path)
        if not story_ids:
            print("æœªæ‰¾åˆ°æœ‰æ•ˆçš„ story_idï¼Œç¨‹å¼çµæŸ")
            return
        
        # 2. å¾ Supabase ç²å–æ–°è
        news_items = self.fetch_news_from_supabase(story_ids)
        if not news_items:
            print("æœªç²å–åˆ°ä»»ä½•æ–°èå…§å®¹ï¼Œç¨‹å¼çµæŸ")
            return
        
        # 3. ä½¿ç”¨ AI åˆ†çµ„
        event_groups = self.group_news_by_events_ai(news_items)
        
        # 4. å„²å­˜çµæœåˆ° JSON æª”æ¡ˆ
        self.save_to_json(event_groups, output_path)
        
        # 5. å„²å­˜çµæœåˆ°è³‡æ–™åº«
        self.save_to_database(event_groups)
        
        # 5. è¼¸å‡ºçµ±è¨ˆè³‡è¨Š
        print("\n" + "=" * 60)
        print("è™•ç†å®Œæˆ - çµ±è¨ˆè³‡è¨Š")
        print("=" * 60)
        print(f"åŸå§‹ story_id æ•¸é‡: {len(story_ids)}")
        print(f"æˆåŠŸç²å–æ–°èæ•¸é‡: {len(news_items)}")
        print(f"åˆ†çµ„å¾Œäº‹ä»¶åˆ†æ”¯æ•¸é‡: {len(event_groups)}")
        
        for i, group in enumerate(event_groups, 1):
            print(f"  åˆ†æ”¯ {i}: {group['event_title']} ({group['news_count']} å‰‡æ–°è)")


def main():
    """ä¸»ç¨‹å¼å…¥å£ - å¢é‡æ›´æ–°æ¨¡å¼"""
    print("ğŸš€ æ–°èäº‹ä»¶åˆ†çµ„å™¨ - å•Ÿå‹•ä¸­...")
    print("=" * 80)
    print("ï¿½ æ¨¡å¼ï¼šå¢é‡æ›´æ–°æ¨¡å¼ï¼ˆæœ€å°åˆ†æ”¯è¦æ¨¡: 5 å‰‡æ–°èï¼‰")
    print("=" * 80)
    print("\nåŠŸèƒ½ç‰¹é»:")
    print("  âœ“ æ¯å€‹åˆ†æ”¯è‡³å°‘éœ€è¦ 5 å‰‡æ–°è")
    print("  âœ“ ä¸è¶³ 5 å‰‡çš„æ”¾å…¥ã€Œå…¶ä»–å¾…åˆ†é¡æ–°èã€æš«å­˜å€")
    print("  âœ“ æª¢æŸ¥æ–°æ–°èæ˜¯å¦å¯åŠ å…¥ç¾æœ‰åˆ†æ”¯")
    print("  âœ“ æš«å­˜å€+æ–°æ–°èè‹¥é” 5 å‰‡ï¼Œè‡ªå‹•é‡æ–°åˆ†çµ„")
    print("  âœ“ å…ˆè¼¸å‡ºé è¦½åˆ°çµ‚ç«¯ï¼Œä¸æ›´å‹•è³‡æ–™åº«")
    print()
    
    # å‰µå»ºè™•ç†å™¨
    try:
        grouper = NewsEventGrouper()
    except Exception as e:
        print(f"âŒ åˆå§‹åŒ–å¤±æ•—: {e}")
        print("è«‹æª¢æŸ¥ç’°å¢ƒè¨­å®šå’Œç¶²è·¯é€£ç·š")
        return
    
    # è¨­å®šè¼¸å‡ºæª”æ¡ˆåç¨±ï¼ˆåŒ…å«æ™‚é–“æˆ³è¨˜ï¼‰
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    output_path = f"topic_grouped_news_incremental_{timestamp}.json"
    
    # âš ï¸ é‡è¦è¨­å®š
    save_to_db = False  # å…ˆä¸å¯«å…¥è³‡æ–™åº«ï¼Œåªè¼¸å‡ºé è¦½
    incremental_mode = True  # å•Ÿç”¨å¢é‡æ›´æ–°æ¨¡å¼
    
    print(f"ğŸ“„ çµæœå°‡å„²å­˜åˆ°: {output_path}")
    print("ï¿½ æ¨¡å¼: é è¦½æ¨¡å¼ï¼ˆä¸æœƒå¯«å…¥è³‡æ–™åº«ï¼‰")
    print()
    
    try:
        # åŸ·è¡Œä¸»è¦è™•ç†æµç¨‹
        result = grouper.process_from_topic_map(
            output_path, 
            save_to_db=save_to_db,
            incremental_mode=incremental_mode
        )
        
        if result:
            print("\n" + "=" * 80)
            print("ğŸ‰ è™•ç†å®Œæˆï¼")
            print("=" * 80)
            print(f"âœ… JSON æª”æ¡ˆ: {output_path}")
            print("âœ… è©³ç´°çµæœå·²è¼¸å‡ºåˆ°çµ‚ç«¯")
            print()
            print("ğŸ“ ä¸‹ä¸€æ­¥:")
            print("  1. æª¢æŸ¥ä¸Šæ–¹çµ‚ç«¯è¼¸å‡ºçš„åˆ†çµ„çµæœ")
            print("  2. å¦‚æœçµæœæ­£ç¢ºï¼Œä¿®æ”¹ main() ä¸­çš„ save_to_db = True")
            print("  3. é‡æ–°åŸ·è¡Œç¨‹å¼å³å¯å¯«å…¥è³‡æ–™åº«")
        else:
            print("\nâš ï¸ è™•ç†éç¨‹ä¸­é‡åˆ°å•é¡Œï¼Œè«‹æª¢æŸ¥è¼¸å‡ºè¨Šæ¯")
            
    except KeyboardInterrupt:
        print("\n\nâ¹ï¸ ä½¿ç”¨è€…ä¸­æ–·ç¨‹å¼åŸ·è¡Œ")
    except Exception as e:
        print(f"\nâŒ åŸ·è¡Œéç¨‹ä¸­ç™¼ç”ŸéŒ¯èª¤: {e}")
        import traceback
        traceback.print_exc()
        print("è«‹æª¢æŸ¥ç¶²è·¯é€£ç·šå’Œè³‡æ–™åº«è¨­å®š")
    
    print("\nç¨‹å¼çµæŸ")


if __name__ == "__main__":
    main()