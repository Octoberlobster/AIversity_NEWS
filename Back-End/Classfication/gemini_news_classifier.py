"""
Gemini æ–°èåˆ†é¡å™¨
ä½¿ç”¨ Google Gemini 2.5 Flash Lite é€²è¡Œæ™ºæ…§æ–°èåˆ†é¡

å…©éšæ®µåˆ†é¡ç­–ç•¥ï¼š
1. Topic â†’ Categoryï¼šåˆ¤æ–· topic å±¬æ–¼å“ªå€‹æ–°èé¡åˆ¥
2. News â†’ Topicï¼šå°‡è©²é¡åˆ¥çš„æ–°èåˆ†é…åˆ° topic ä¸­
"""

import os
import logging
import json
import time
from typing import List, Dict, Optional
from datetime import datetime
from supabase import create_client
from dotenv import load_dotenv
from google import genai
from pydantic import BaseModel, Field

# è¼‰å…¥ç’°å¢ƒè®Šæ•¸
load_dotenv()

# è¨­å®šæ—¥èªŒ
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)


# å®šç¾©å›æ‡‰çµæ§‹
class CategoryClassificationResult(BaseModel):
    """Topic åˆ†é¡çµæœçš„çµæ§‹ï¼ˆæ”¯æ´å¤šé¡åˆ¥ï¼‰"""
    primary_category: str
    secondary_categories: List[str]
    reason: str


class NewsClassificationResult(BaseModel):
    """æ–°èåˆ†é¡çµæœçš„çµæ§‹"""
    related_news_ids: List[int]
    reason: str


class GeminiNewsClassifier:
    """åŸºæ–¼ Gemini çš„æ–°èåˆ†é¡å™¨"""
    
    def __init__(self):
        """åˆå§‹åŒ–åˆ†é¡å™¨"""
        # åˆå§‹åŒ– Supabase å®¢æˆ¶ç«¯
        self.supabase = create_client(
            os.getenv("SUPABASE_URL"),
            os.getenv("SUPABASE_KEY")
        )
        
        # åˆå§‹åŒ– Gemini
        self.client = genai.Client(api_key=os.getenv("GEMINI_API_KEY"))
        
        # é å®šç¾©çš„æ–°èåˆ†é¡
        self.categories = [
            "Politics",
            "Taiwan News", 
            "International News",
            "Science & Technology",
            "Lifestyle & Consumer",
            "Sports",
            "Entertainment", 
            "Business & Finance",
            "Health & Wellness"
        ]
    
    # ========== è¼”åŠ©æ–¹æ³• ==========
    
    def _clean_json_response(self, response: str) -> str:
        """æ¸…ç† Gemini å›æ‡‰ä¸­çš„ markdown æ ¼å¼æ¨™è¨˜å’Œå…¶ä»–å•é¡Œ"""
        import re
        
        # ç§»é™¤ ```json å’Œ ``` æ¨™è¨˜
        response = response.strip()
        if response.startswith('```json'):
            response = response[7:]  # ç§»é™¤ ```json
        if response.startswith('```'):
            response = response[3:]   # ç§»é™¤ ```
        if response.endswith('```'):
            response = response[:-3]  # ç§»é™¤çµå°¾çš„ ```
        
        response = response.strip()
        
        # è™•ç† JSON å­—ä¸²ä¸­çš„å•é¡Œ
        try:
            # å°‹æ‰¾ JSON ç‰©ä»¶çš„é–‹å§‹å’ŒçµæŸ
            start_idx = response.find('{')
            end_idx = response.rfind('}')
            
            if start_idx != -1 and end_idx != -1 and end_idx > start_idx:
                json_part = response[start_idx:end_idx+1]
                
                # æ¸…ç†å¼•è™Ÿå•é¡Œ - å°‡æ™ºæ…§å¼•è™Ÿæ›¿æ›ç‚ºæ¨™æº–å¼•è™Ÿ
                json_part = json_part.replace('"', '"').replace('"', '"')
                json_part = json_part.replace(''', "'").replace(''', "'")
                
                # è™•ç†å¯èƒ½çš„æ›è¡Œå•é¡Œ
                json_part = re.sub(r'\n\s*', ' ', json_part)
                
                return json_part
            
        except Exception as e:
            logger.warning(f"æ¸…ç† JSON æ™‚ç™¼ç”Ÿå•é¡Œ: {e}")
        
        return response
    
    def _extract_category_from_text(self, text: str) -> str:
        """å¾æ–‡æœ¬ä¸­æå– categoryï¼Œä½œç‚º JSON è§£æå¤±æ•—æ™‚çš„å‚™ç”¨æ–¹æ³•"""
        text_lower = text.lower()
        
        # æª¢æŸ¥æ¯å€‹é¡åˆ¥æ˜¯å¦å‡ºç¾åœ¨æ–‡æœ¬ä¸­
        for category in self.categories:
            # æª¢æŸ¥å®Œæ•´çš„é¡åˆ¥åç¨±
            if category.lower() in text_lower:
                return category
            
            # æª¢æŸ¥é¡åˆ¥çš„é—œéµå­—
            category_keywords = {
                "Politics": ["politics", "political", "æ”¿æ²»"],
                "Taiwan News": ["taiwan", "å°ç£", "è‡ºç£"],
                "International News": ["international", "world", "global", "åœ‹éš›"],
                "Science & Technology": ["technology", "science", "tech", "ç§‘æŠ€", "ç§‘å­¸"],
                "Lifestyle & Consumer": ["lifestyle", "consumer", "ç”Ÿæ´»"],
                "Sports": ["sports", "sport", "é‹å‹•", "é«”è‚²"],
                "Entertainment": ["entertainment", "å¨›æ¨‚"],
                "Business & Finance": ["business", "finance", "financial", "å•†æ¥­", "é‡‘è", "ç¶“æ¿Ÿ", "è²¿æ˜“"],
                "Health & Wellness": ["health", "wellness", "é†«ç™‚", "å¥åº·"]
            }
            
            keywords = category_keywords.get(category, [])
            for keyword in keywords:
                if keyword in text_lower:
                    return category
        
        return "å…¶ä»–"
    
    # ========== ä¸»è¦åˆ†é¡æ–¹æ³• ==========
    
    def step1_classify_topic_to_category(self, topic_title: str) -> tuple[List[str], str]:
        """
        æ­¥é©Ÿ1ï¼šå°‡ topic åˆ†é¡åˆ°å¤šå€‹ category (ä½¿ç”¨ Google æœå°‹å¢å¼·åˆ†é¡æº–ç¢ºæ€§)
        
        Args:
            topic_title: topic æ¨™é¡Œ
            
        Returns:
            tuple: (åˆ†é¡çš„ categories åˆ—è¡¨, åˆ†é¡ç†ç”±)
        """
        try:
            prompt = self._build_topic_classification_prompt(topic_title, None)
            # æš«æ™‚ä¸ä½¿ç”¨çµæ§‹åŒ–è¼¸å‡ºï¼Œå…ˆç”¨æœå°‹åŠŸèƒ½ä½†è¿”å›æ™®é€šæ–‡æœ¬
            response = self._call_gemini_with_search_text(prompt)
            
            # æ¸…ç†å’Œè§£æçµæ§‹åŒ–å›æ‡‰
            try:
                cleaned_response = self._clean_json_response(response)
                result = json.loads(cleaned_response)
                
                primary_category = result.get("primary_category", result.get("category", "å…¶ä»–"))
                secondary_categories = result.get("secondary_categories", [])
                if not isinstance(secondary_categories, list):
                    secondary_categories = []
                reason = result.get("reason", "ç„¡æ³•åˆ¤æ–·")
                
                # åˆä½µä¸»è¦å’Œæ¬¡è¦é¡åˆ¥
                all_categories = [primary_category] + secondary_categories
                all_categories = list(dict.fromkeys(all_categories))  # å»é‡ä½†ä¿æŒé †åº
                
                logger.info(f"Topic '{topic_title}' åˆ†é¡ç‚º: {all_categories}, ç†ç”±: {reason}")
                return all_categories, reason
                
            except json.JSONDecodeError as e:
                logger.error(f"ç„¡æ³•è§£æ Gemini çµæ§‹åŒ–å›æ‡‰: {response}")
                logger.error(f"JSON è§£æéŒ¯èª¤: {e}")
                
                # å‚™ç”¨è§£æï¼šå˜—è©¦å¾å›æ‡‰ä¸­æå– category
                try:
                    category = self._extract_category_from_text(response)
                    if category != "å…¶ä»–":
                        logger.info(f"ä½¿ç”¨å‚™ç”¨è§£ææˆåŠŸæå– category: {category}")
                        return [category], "é€éå‚™ç”¨è§£æå–å¾—"
                except Exception as parse_error:
                    logger.error(f"å‚™ç”¨è§£æä¹Ÿå¤±æ•—: {parse_error}")
                
                # å¦‚æœéƒ½å¤±æ•—äº†ï¼Œå¼·åˆ¶åˆ†é¡åˆ°æœ€åˆé©çš„é»˜èªé¡åˆ¥
                default_categories = self._get_default_categories(topic_title)
                return default_categories, "ä½¿ç”¨é»˜èªåˆ†é¡"
                
        except Exception as e:
            logger.error(f"æ­¥é©Ÿ1åˆ†é¡å¤±æ•—: {e}")
            # å³ä½¿ç™¼ç”ŸéŒ¯èª¤ï¼Œä¹Ÿè¦å˜—è©¦åˆ†é¡åˆ°åˆé©çš„é»˜èªé¡åˆ¥
            default_categories = self._get_default_categories(topic_title)
            return default_categories, "ç™¼ç”ŸéŒ¯èª¤ï¼Œä½¿ç”¨é»˜èªåˆ†é¡"
    
    def _get_default_categories(self, topic_title: str) -> List[str]:
        """æ ¹æ“š topic æ¨™é¡Œç²å–é»˜èªåˆ†é¡ï¼Œæ”¯æ´å¤šé¡åˆ¥åˆ†é¡"""
        topic_lower = topic_title.lower()
        categories = []
        
        # åŸºæœ¬é—œéµå­—æ˜ å°„åˆ°æˆ‘å€‘çš„ 9 å€‹é¡åˆ¥
        if any(word in topic_lower for word in ['å·æ™®', 'trump', 'é¸èˆ‰', 'æ”¿æ²»', 'å…¬æŠ•', 'ç«‹é™¢', 'æ”¿åºœ']):
            categories.append("Politics")
        elif any(word in topic_lower for word in ['å°ç£', 'æŸ¯æ–‡å“²', 'è”¡è‹±æ–‡', 'éŸ“åœ‹ç‘œ', 'æœ¬åœŸ']):
            categories.append("Taiwan News")
        elif any(word in topic_lower for word in ['åœ‹éš›', 'ç¾åœ‹', 'ä¸­åœ‹', 'ä¿„çƒ', 'ä»¥è‰²åˆ—', 'ä¼Šæœ—', 'æ³°æŸ¬', 'æˆ°çˆ­', 'è¡çª']):
            categories.append("International News")
        elif any(word in topic_lower for word in ['ç§‘æŠ€', 'ç§‘å­¸', 'ai', 'äººå·¥æ™ºæ…§', 'æ™¶ç‰‡', 'åŠå°é«”']):
            categories.append("Science & Technology")
        elif any(word in topic_lower for word in ['ç”Ÿæ´»', 'æ¶ˆè²»', 'è³¼ç‰©', 'ç¾é£Ÿ', 'æ—…éŠ', 'å±•è¦½']):
            categories.append("Lifestyle & Consumer")
        elif any(word in topic_lower for word in ['é‹å‹•', 'é«”è‚²', 'çƒè³½', 'å¥§é‹', 'ä¸–ç•Œç›ƒ']):
            categories.append("Sports")
        elif any(word in topic_lower for word in ['å¨›æ¨‚', 'é›»å½±', 'éŸ³æ¨‚', 'æ˜æ˜Ÿ', 'æ¼”å“¡']):
            categories.append("Entertainment")
        elif any(word in topic_lower for word in ['ç¶“æ¿Ÿ', 'é‡‘è', 'è‚¡å¸‚', 'æŠ•è³‡', 'è²¿æ˜“', 'GDP', 'é€šè†¨']):
            categories.append("Business & Finance")
        elif any(word in topic_lower for word in ['å¥åº·', 'é†«ç™‚', 'ç–«æƒ…', 'ç—…æ¯’', 'ç–«è‹—']):
            categories.append("Health & Wellness")
        
        # å¦‚æœæ²’æœ‰åŒ¹é…åˆ°ä»»ä½•é¡åˆ¥ï¼Œè¿”å›é è¨­
        return categories if categories else ["å…¶ä»–"]
    
    def step2_classify_news_to_topic(self, categories: List[str], topic_info: Dict, topic_content: str = None) -> List[Dict]:
        """
        æ­¥é©Ÿ2ï¼šå°‡å¤šå€‹é¡åˆ¥çš„æ–°èåˆ†é…åˆ° topic
        
        Args:
            categories: æ–°èé¡åˆ¥åˆ—è¡¨
            topic_info: topic è³‡è¨Š
            topic_content: topic çš„è©³ç´°å…§å®¹/ç†ç”± (ä¾†è‡ªæ­¥é©Ÿ1çš„åˆ†é¡ç†ç”±)
            
        Returns:
            ç¬¦åˆè©² topic çš„æ–°èåˆ—è¡¨
        """
        try:
            all_classified_news = []
            
            # å°æ¯å€‹é¡åˆ¥é€²è¡Œæ–°èåˆ†é¡
            for category in categories:
                logger.info(f"è™•ç†é¡åˆ¥ '{category}' çš„æ–°è...")
                
                # 1. ç²å–è©²é¡åˆ¥çš„æ–°è
                news_list = self._get_news_by_category(category)
                
                if not news_list:
                    logger.info(f"åœ¨é¡åˆ¥ '{category}' ä¸­æ²’æœ‰æ‰¾åˆ°æ–°è")
                    continue
                
                logger.info(f"æ‰¾åˆ° {len(news_list)} å‰‡ '{category}' é¡åˆ¥çš„æ–°è")
                
                # 2. ä¸€æ¬¡è™•ç†æ‰€æœ‰æ–°è
                classified_news = self._classify_news_batch(news_list, topic_info, topic_content)
                
                if classified_news:
                    all_classified_news.extend(classified_news)
                    logger.info(f"å¾ '{category}' é¡åˆ¥åˆ†é¡ {len(classified_news)} å‰‡æ–°èåˆ° topic '{topic_info['topic_title']}'")
            
            # å»é‡ï¼ˆé¿å…åŒä¸€å‰‡æ–°èå‡ºç¾åœ¨å¤šå€‹é¡åˆ¥ä¸­ï¼‰
            unique_news = {}
            for news in all_classified_news:
                news_id = news.get('story_id')
                if news_id not in unique_news:
                    unique_news[news_id] = news
            
            final_news_list = list(unique_news.values())
            logger.info(f"ç¸½å…±æˆåŠŸåˆ†é¡ {len(final_news_list)} å‰‡æ–°èåˆ° topic '{topic_info['topic_title']}'")
            return final_news_list
            
        except Exception as e:
            logger.error(f"æ­¥é©Ÿ2åˆ†é¡å¤±æ•—: {e}")
            return []
    
    def classify_all_topics(self) -> List[Dict]:
        """å°æ‰€æœ‰ topic é€²è¡Œæ‰¹é‡åˆ†é¡"""
        try:
            # ä¸€æ¬¡æ€§ç²å–æ‰€æœ‰ topic è³‡æ–™
            logger.info("é–‹å§‹ç²å–æ‰€æœ‰ topics...")
            all_topics = self._get_all_topics()
            
            if not all_topics:
                logger.warning("æ²’æœ‰æ‰¾åˆ°ä»»ä½• topics")
                return []
                
            logger.info(f"æˆåŠŸç²å– {len(all_topics)} å€‹ topicsï¼Œé–‹å§‹é€ä¸€åˆ†é¡...")
            
            results = []
            for idx, topic in enumerate(all_topics, 1):
                logger.info(f"è™•ç†ç¬¬ {idx}/{len(all_topics)} å€‹ topic: {topic['topic_title']}")
                
                try:
                    # ç›´æ¥åœ¨é€™è£¡åŸ·è¡Œå®Œæ•´çš„åˆ†é¡æµç¨‹
                    topic_info = topic  # å·²ç¶“æœ‰å®Œæ•´è³‡è¨Šäº†
                    
                    # æ­¥é©Ÿ1ï¼šåˆ¤æ–· topic å±¬æ–¼å“ªäº› categoryï¼Œä¸¦ç²å–åˆ†é¡ç†ç”±
                    logger.info(f"é–‹å§‹æ­¥é©Ÿ1ï¼šç‚º topic '{topic_info['topic_title']}' åˆ†é¡")
                    categories, reason = self.step1_classify_topic_to_category(topic_info["topic_title"])

                    # æ­¥é©Ÿ2ï¼šå°‡å¤šå€‹ category çš„æ–°èåˆ†åˆ° topic ä¸­ï¼Œä½¿ç”¨æ­¥é©Ÿ1çš„ç†ç”±ä½œç‚º topic_content
                    categories_str = ', '.join(categories)
                    logger.info(f"é–‹å§‹æ­¥é©Ÿ2ï¼šåœ¨é¡åˆ¥ '{categories_str}' ä¸­å°‹æ‰¾ç›¸é—œæ–°è (ä½¿ç”¨ç†ç”±: {reason[:50]}...)")
                    classified_news = self.step2_classify_news_to_topic(categories, topic_info, reason)
                    
                    # å„²å­˜åˆ†é¡çµæœï¼ˆå¯é¸ï¼‰
                    if classified_news:
                        self._save_classification_results(topic["topic_id"], classified_news)
                    
                    result = {
                        "topic_id": topic_info["topic_id"],
                        "topic_title": topic_info["topic_title"], 
                        "source_story": [
                            {
                                "story_id": news["story_id"],
                                "story_title": news["news_title"]
                            }
                            for news in classified_news
                        ],
                        "success": True
                    }
                    results.append(result)
                    
                    # é¿å… API é »ç‡é™åˆ¶
                    time.sleep(1)
                    
                except Exception as e:
                    logger.error(f"è™•ç† topic {topic['topic_id']} å¤±æ•—: {e}")
                    results.append({
                        "topic_id": topic["topic_id"],
                        "topic_title": topic["topic_title"],
                        "source_story": [],
                        "success": False,
                        "error": str(e)
                    })
            
            # çµ±è¨ˆçµæœ
            success_count = sum(1 for r in results if r.get("success"))
            total_news_classified = sum(len(r.get("source_story", [])) for r in results if r.get("success"))
            
            logger.info(f"æ‰¹é‡åˆ†é¡å®Œæˆï¼æˆåŠŸ: {success_count}/{len(results)}, ç¸½å…±åˆ†é¡äº† {total_news_classified} å‰‡æ–°è")
            
            return results
            
        except Exception as e:
            logger.error(f"æ‰¹é‡åˆ†é¡å¤±æ•—: {e}")
            return []
    
    # ========== è³‡æ–™åº«æ“ä½œæ–¹æ³• ==========
    
    def _get_all_topics(self) -> List[Dict]:
        """ä¸€æ¬¡æ€§ç²å–æ‰€æœ‰ topic è³‡è¨Š"""
        try:
            response = self.supabase.table("topic").select(
                "topic_id, topic_title"
            ).execute()
            
            return response.data if response.data else []
            
        except Exception as e:
            logger.error(f"ç²å–æ‰€æœ‰ topics å¤±æ•—: {e}")
            return []
    
    def _get_news_by_category(self, category: str) -> List[Dict]:
        """ç²å–æŒ‡å®šé¡åˆ¥çš„æ–°è"""
        try:
            response = self.supabase.table("single_news").select(
                "story_id, news_title, short, category"
            ).eq("category", category).execute()
            
            return response.data if response.data else []
            
        except Exception as e:
            logger.error(f"ç²å–æ–°èè³‡æ–™å¤±æ•—: {e}")
            return []
    
    def _save_classification_results(self, topic_id: str, classified_news: List[Dict]):
        """å„²å­˜åˆ†é¡çµæœåˆ°è³‡æ–™åº«"""
        try:
            logger.info(f"å„²å­˜åˆ†é¡çµæœï¼štopic_id={topic_id}, æ–°èæ•¸é‡={len(classified_news)}")
            
            # TODO: å¯¦ç¾å„²å­˜é‚è¼¯
            # å¯ä»¥å„²å­˜åˆ° topic_branch_news_map æˆ–å…¶ä»–ç›¸é—œè¡¨æ ¼
            
        except Exception as e:
            logger.error(f"å„²å­˜åˆ†é¡çµæœå¤±æ•—: {e}")
    
    # ========== Gemini API ç›¸é—œæ–¹æ³• ==========
    
    def _call_gemini_async(self, prompt: str, response_schema=None) -> str:
        """åŒæ­¥å‘¼å« Gemini APIï¼Œæ”¯æ´çµæ§‹åŒ–è¼¸å‡º"""
        try:
            from google.genai import types
            
            if response_schema:
                # ä½¿ç”¨çµæ§‹åŒ–è¼¸å‡º
                config = types.GenerateContentConfig(
                    response_schema=response_schema,
                    response_mime_type="application/json"  # å¼·åˆ¶å›å‚³ JSON æ ¼å¼
                )
                response = self.client.models.generate_content(
                    model="gemini-2.5-flash-lite",  # çµæ§‹åŒ–è¼¸å‡ºéœ€è¦ 2.5 ç‰ˆæœ¬
                    contents=prompt,
                    config=config
                )
            else:
                # ä¸€èˆ¬æ¨¡å¼
                response = self.client.models.generate_content(
                    model="gemini-2.5-flash-lite",
                    contents=prompt
                )
            return response.text
        except Exception as e:
            logger.error(f"Gemini API å‘¼å«å¤±æ•—: {e}")
            raise
    
    def _call_gemini_with_search_text(self, prompt: str) -> str:
        """åŒæ­¥å‘¼å« Gemini API ä¸¦å•Ÿç”¨ Google æœå°‹åŠŸèƒ½ï¼Œè¿”å›ç´”æ–‡æœ¬"""
        try:
            from google.genai import types
            
            # å®šç¾© Google æœå°‹å·¥å…·
            grounding_tool = types.Tool(
                google_search=types.GoogleSearch()
            )
            # è¨­å®šç”Ÿæˆé…ç½® - åªä½¿ç”¨æœå°‹å·¥å…·
            config = types.GenerateContentConfig(
                tools=[grounding_tool]
            )
            
            response = self.client.models.generate_content(
                model="gemini-2.5-flash-lite",
                contents=prompt,
                config=config
            )
            return response.text
        except Exception as e:
            logger.error(f"Gemini API (with search text) å‘¼å«å¤±æ•—: {e}")
            # å¦‚æœæœå°‹åŠŸèƒ½å¤±æ•—ï¼Œå›é€€åˆ°ä¸€èˆ¬æ¨¡å¼
            logger.info("å›é€€åˆ°ä¸€èˆ¬æ¨¡å¼...")
            return self._call_gemini_async(prompt)

    def _call_gemini_with_search(self, prompt: str, response_schema=None) -> str:
        """åŒæ­¥å‘¼å« Gemini API ä¸¦å•Ÿç”¨ Google æœå°‹åŠŸèƒ½ï¼Œæ”¯æ´çµæ§‹åŒ–è¼¸å‡º"""
        try:
            from google.genai import types
            
            # å®šç¾© Google æœå°‹å·¥å…·
            grounding_tool = types.Tool(
                google_search=types.GoogleSearch()
            )
            # è¨­å®šç”Ÿæˆé…ç½® - æ³¨æ„ï¼šä½¿ç”¨å·¥å…·æ™‚ä¸èƒ½è¨­å®š response_mime_type
            if response_schema:
                config = types.GenerateContentConfig(
                    tools=[grounding_tool],
                    response_schema=response_schema
                    # ä¸è¨­å®š response_mime_typeï¼Œå› ç‚ºèˆ‡å·¥å…·ä¸ç›¸å®¹
                )
            else:
                config = types.GenerateContentConfig(
                    tools=[grounding_tool]
                )
            
            response = self.client.models.generate_content(
                model="gemini-2.5-flash-lite",  # ä½¿ç”¨æ”¯æ´æœå°‹å’Œçµæ§‹åŒ–è¼¸å‡ºçš„æ¨¡å‹
                contents=prompt,
                config=config
            )
            return response.text
        except Exception as e:
            logger.error(f"Gemini API (with search) å‘¼å«å¤±æ•—: {e}")
            # å¦‚æœæœå°‹åŠŸèƒ½å¤±æ•—ï¼Œå›é€€åˆ°ä¸€èˆ¬æ¨¡å¼
            logger.info("å›é€€åˆ°ä¸€èˆ¬æ¨¡å¼...")
            return self._call_gemini_async(prompt, response_schema)
    
    def _build_topic_classification_prompt(self, topic_title: str, topic_content: str = None) -> str:
        """æ§‹å»º topic åˆ†é¡çš„ promptï¼Œæ”¯æ´å¤šé¡åˆ¥åˆ†é¡"""
        prompt = f"""ä½ æ˜¯ä¸€å€‹å°ˆæ¥­çš„æ–°èåˆ†é¡å°ˆå®¶ã€‚æˆ‘éœ€è¦ä½ æ ¹æ“š topic è³‡è¨Šï¼Œåˆ¤æ–·å®ƒæœ€é©åˆæ­¸é¡åˆ°å“ªäº›æ–°èé¡åˆ¥ã€‚

è«‹å…ˆæœå°‹é—œæ–¼é€™å€‹ topic çš„æœ€æ–°è³‡è¨Šï¼Œäº†è§£å®ƒçš„èƒŒæ™¯å’Œæ€§è³ªï¼Œç„¶å¾Œé€²è¡Œåˆ†é¡ã€‚

Topic æ¨™é¡Œï¼š{topic_title}"""
        
        if topic_content:
            prompt += f"\nTopic å…§å®¹ï¼š{topic_content}"
        
        prompt += f"""

âš ï¸ **é‡è¦ï¼šä½ å¿…é ˆå¾ä»¥ä¸‹ 9 å€‹é¡åˆ¥ä¸­é¸æ“‡ï¼Œä¸å¯ä»¥ä½¿ç”¨å…¶ä»–é¡åˆ¥åç¨±**ï¼š
{', '.join(self.categories)}

è«‹åŸ·è¡Œä»¥ä¸‹æ­¥é©Ÿï¼š
1. æœå°‹é€™å€‹ topic çš„ç›¸é—œè³‡è¨Šå’Œæœ€æ–°ç™¼å±•
2. åˆ†æ topic çš„ä¸»è¦å…§å®¹å’Œæ€§è³ª
3. **é¸æ“‡ä¸€å€‹ä¸»è¦é¡åˆ¥å’Œæœ€å¤šå…©å€‹æ¬¡è¦ç›¸é—œé¡åˆ¥**
4. èªªæ˜é¸æ“‡çš„ç†ç”±

**åˆ†é¡åŸå‰‡**ï¼š
- primary_categoryï¼šæœ€ä¸»è¦ç›¸é—œçš„é¡åˆ¥ï¼ˆå¿…é ˆï¼‰
- secondary_categoriesï¼šæ¬¡è¦ç›¸é—œçš„é¡åˆ¥ï¼ˆæœ€å¤š2å€‹ï¼Œå¯ç‚ºç©ºï¼‰
- ä¸€å€‹ topic å¯èƒ½æ¶‰åŠå¤šå€‹é¡åˆ¥ï¼Œä¾‹å¦‚ã€Œå·æ™®é—œç¨…æˆ°ã€å¯èƒ½åŒæ™‚æ¶‰åŠ "International News" å’Œ "Business & Finance"
- ã€Œé¢±é¢¨æ¥ŠæŸ³ã€å¯èƒ½åŒæ™‚æ¶‰åŠ "Taiwan News" å’Œå¯èƒ½çš„å…¶ä»–å½±éŸ¿

è«‹ä»¥ JSON æ ¼å¼å›æ‡‰ï¼š
{{
    "primary_category": "å¾ä¸Šè¿°9å€‹é¡åˆ¥ä¸­é¸æ“‡çš„ä¸»è¦é¡åˆ¥åç¨±ï¼ˆå¿…é ˆå®Œå…¨ä¸€è‡´ï¼‰",
    "secondary_categories": ["å¾ä¸Šè¿°9å€‹é¡åˆ¥ä¸­é¸æ“‡çš„æ¬¡è¦é¡åˆ¥ï¼ˆå¯ç‚ºç©ºæ•¸çµ„ï¼Œæœ€å¤š2å€‹ï¼‰"],
    "reason": "é¸æ“‡ç†ç”±ï¼ŒåŒ…å«æœå°‹åˆ°çš„ç›¸é—œè³‡è¨Š"
}}"""
        
        return prompt
    
    def _build_news_classification_prompt(self, news_list_str: str, topic_info: Dict, topic_content: str = None) -> str:
        """æ§‹å»ºæ–°èåˆ†é¡çš„ promptï¼Œé…åˆçµæ§‹åŒ–è¼¸å‡º"""
        # çµ„åˆ Topic è³‡è¨Š
        topic_section = f"Topic è³‡è¨Šï¼š\næ¨™é¡Œï¼š{topic_info['topic_title']}"
        
        # å¦‚æœæœ‰ topic_contentï¼ŒåŠ å…¥æ›´è©³ç´°çš„æè¿°
        if topic_content:
            topic_section += f"\nè©³ç´°æè¿°ï¼š{topic_content}"
        
        return f"""ä½ æ˜¯ä¸€å€‹å°ˆæ¥­çš„æ–°èåˆ†æå°ˆå®¶ã€‚è«‹åˆ¤æ–·ä»¥ä¸‹æ–°èä¸­ï¼Œå“ªäº›èˆ‡çµ¦å®šçš„ Topic ç›´æ¥ç›¸é—œã€‚

{topic_section}

å¾…åˆ†æçš„æ–°èï¼š
{news_list_str}

ğŸ¯ **æ ¸å¿ƒåŸå‰‡**ï¼šåªæœ‰ç›´æ¥è¨è«–è©² Topic çš„æ–°èæ‰ç®—ç›¸é—œ

ğŸ“‹ **å…·é«”åŒ¹é…æ¨™æº–**ï¼š
1. **å­—é¢åŒ¹é…**ï¼šæ–°èæ¨™é¡Œæˆ–å…§å®¹å¿…é ˆåŒ…å« Topic çš„æ ¸å¿ƒé—œéµå­—
2. **ä¸»é¡Œä¸€è‡´**ï¼šæ–°èçš„ä¸»è¦è¨è«–å…§å®¹å¿…é ˆæ˜¯è©² Topic
3. **é¿å…è¯æƒ³**ï¼šä¸è¦å› ç‚ºé–“æ¥é—œè¯å°±èªç‚ºç›¸é—œ

âš ï¸ **åš´æ ¼é™åˆ¶**ï¼š
- ã€ŒäºŒæˆ°çµ‚æˆ°80é€±å¹´ã€â†’ åªèƒ½æ˜¯é—œæ–¼æ—¥æœ¬çµ‚æˆ°æ—¥ã€é–åœ‹ç¥ç¤¾ã€äºŒæˆ°ç´€å¿µç­‰ç›´æ¥ç›¸é—œçš„æ–°è
- ã€Œé‡å•Ÿæ ¸ä¸‰å…¬æŠ•ã€â†’ åªèƒ½æ˜¯é—œæ–¼æ ¸é›»å» ã€æ ¸ä¸‰ã€å…¬æŠ•ã€èƒ½æºæ”¿ç­–ç­‰ç›´æ¥ç›¸é—œçš„æ–°è
- ã€Œäº¬è¯åŸæ¡ˆã€â†’ åªèƒ½æ˜¯é—œæ–¼æŸ¯æ–‡å“²ã€äº¬è¯åŸã€å¸æ³•æ¡ˆä»¶ç­‰ç›´æ¥ç›¸é—œçš„æ–°è
- ã€Œé¢±é¢¨æ¥ŠæŸ³ã€â†’ åªèƒ½æ˜¯é—œæ–¼æ¥ŠæŸ³é¢±é¢¨çš„å¤©æ°£æ–°è

ğŸš« **çµ•å°æ’é™¤**ï¼š
- åƒ…æ˜¯åŒé¡åˆ¥ä½†ä¸åŒä¸»é¡Œçš„æ–°èï¼ˆå¦‚ä¸åŒé¢±é¢¨ã€ä¸åŒæ¡ˆä»¶ã€ä¸åŒæˆ°çˆ­ï¼‰
- éœ€è¦å¤šå±¤æ¨ç†æ‰èƒ½é—œè¯çš„æ–°è
- åƒ…æ˜¯èƒŒæ™¯ç›¸åŒä½†ä¸»é¡Œä¸åŒçš„æ–°è

è«‹åš´æ ¼æŒ‰ç…§å­—é¢æ„æ€é€²è¡ŒåŒ¹é…ï¼Œä¸è¦éåº¦è§£é‡‹æˆ–è¯æƒ³ã€‚

        è«‹å›æ‡‰èˆ‡ Topic ç›´æ¥ç›¸é—œçš„æ–°èç·¨è™Ÿåˆ—è¡¨å’Œç°¡æ½”ç†ç”±ã€‚"""
    
    def _classify_news_batch(self, news_batch: List[Dict], topic_info: Dict, topic_content: str = None) -> List[Dict]:
        """å°ä¸€æ‰¹æ–°èé€²è¡Œåˆ†é¡åˆ¤æ–·ï¼Œä½¿ç”¨çµæ§‹åŒ–è¼¸å‡º"""
        try:
            # æ§‹å»ºæ–°èåˆ—è¡¨å­—ä¸²
            news_list_str = ""
            for idx, news in enumerate(news_batch):
                news_title = news.get('news_title', 'ç„¡æ¨™é¡Œ')
                news_short = news.get('short', 'ç„¡å…§å®¹')[:200]
                news_list_str += f"{idx+1}. æ¨™é¡Œï¼š{news_title}\n   å…§å®¹ï¼š{news_short}...\n\n"
            
            # æ§‹å»ºä¸¦ç™¼é€ promptï¼Œä½¿ç”¨çµæ§‹åŒ–è¼¸å‡ºä¸¦å‚³å…¥ topic_content
            prompt = self._build_news_classification_prompt(news_list_str, topic_info, topic_content)
            response = self._call_gemini_async(prompt, NewsClassificationResult)
            
            # è§£æçµæ§‹åŒ–å›æ‡‰
            try:
                result = json.loads(response)
                related_news = []
                
                # è™•ç† related_news_ids åˆ—è¡¨
                related_news_ids = result.get("related_news_ids", [])
                reason = result.get("reason", "ç„¡åˆ†é¡ç†ç”±")
                
                for news_index in related_news_ids:
                    # è½‰æ›ç‚º 0-based index
                    array_index = news_index - 1
                    if 0 <= array_index < len(news_batch):
                        news_data = news_batch[array_index].copy()
                        news_data.update({
                            "reason": reason,
                            "topic_id": topic_info["topic_id"]
                        })
                        related_news.append(news_data)
                
                return related_news
                
            except json.JSONDecodeError:
                logger.error(f"ç„¡æ³•è§£æåˆ†é¡çµæ§‹åŒ–å›æ‡‰: {response}")
                return []
                
        except Exception as e:
            logger.error(f"æ‰¹æ¬¡åˆ†é¡å¤±æ•—: {e}")
            return []
    
    # ========== çµ±è¨ˆå ±å‘Šæ–¹æ³• ==========
    
    def generate_classification_report(self, results: List[Dict]) -> Dict:
        """ç”Ÿæˆåˆ†é¡çµæœçµ±è¨ˆå ±å‘Š"""
        if not results:
            return {"message": "æ²’æœ‰åˆ†é¡çµæœ"}
        
        # çµ±è¨ˆåŸºæœ¬è³‡è¨Š
        total_topics = len(results)
        successful_classifications = [r for r in results if r.get("success")]
        failed_classifications = [r for r in results if not r.get("success")]
        
        # çµ±è¨ˆç¸½æ–°èæ•¸
        total_news_classified = 0
        topics_with_news = 0
        
        for result in successful_classifications:
            news_count = len(result.get("source_story", []))
            total_news_classified += news_count
            if news_count > 0:
                topics_with_news += 1
        
        report = {
            "summary": {
                "total_topics": total_topics,
                "successful_classifications": len(successful_classifications),
                "failed_classifications": len(failed_classifications),
                "success_rate": f"{len(successful_classifications)/total_topics*100:.1f}%",
                "topics_with_news": topics_with_news,
                "topics_without_news": len(successful_classifications) - topics_with_news,
                "total_news_classified": total_news_classified,
                "average_news_per_topic": f"{total_news_classified/len(successful_classifications):.1f}" if successful_classifications else "0"
            },
            "failed_topics": [
                {
                    "topic_id": r.get("topic_id", "æœªçŸ¥"),
                    "topic_title": r.get("topic_title", "æœªçŸ¥"),
                    "error": r.get("error", "æœªçŸ¥éŒ¯èª¤")
                }
                for r in failed_classifications
            ]
        }
        
        return report

    def format_results_for_display(self, results: List[Dict]) -> List[Dict]:
        """æ ¼å¼åŒ–çµæœä»¥ä¾¿æ¸…æ¥šé¡¯ç¤º"""
        formatted_results = []
        
        for result in results:
            if result.get("success"):
                formatted_result = {
                    "topic_id": result["topic_id"],
                    "topic_title": result["topic_title"],
                    "source_story": result["source_story"]
                }
            else:
                formatted_result = {
                    "topic_id": result["topic_id"],
                    "topic_title": result["topic_title"],
                    "source_story": [],
                    "error": result.get("error", "æœªçŸ¥éŒ¯èª¤")
                }
            
            formatted_results.append(formatted_result)
        
        return formatted_results


# ========== ä¸»ç¨‹å¼ ==========

def main():
    """ä¸»å‡½æ•¸ï¼Œç”¨æ–¼æ¸¬è©¦åˆ†é¡å™¨"""
    classifier = GeminiNewsClassifier()
    
    print("=== Gemini æ–°èåˆ†é¡å™¨ ===")
    print("åˆå§‹åŒ–å®Œæˆï¼")
    print("\nä¸»è¦åŠŸèƒ½ï¼š")
    print("1. classifier.classify_all_topics() - æ‰¹é‡åˆ†é¡æ‰€æœ‰ topics")
    print("2. classifier.generate_classification_report(results) - ç”Ÿæˆçµ±è¨ˆå ±å‘Š")
    print("\nç¯„ä¾‹ç¨‹å¼ç¢¼ï¼ˆå–æ¶ˆè¨»è§£ä»¥åŸ·è¡Œï¼‰ï¼š")
    print("# æ‰¹é‡åˆ†é¡æ‰€æœ‰ topics")
    print("# results = await classifier.classify_all_topics()")
    print("# report = classifier.generate_classification_report(results)")
    print("# print(json.dumps(report, ensure_ascii=False, indent=2))")
    print("\né–‹å§‹åŸ·è¡Œæ‰¹é‡åˆ†é¡...")
    
    # ç›´æ¥åŸ·è¡Œæ‰¹é‡åˆ†é¡
    try:
        results = classifier.classify_all_topics()
        
        # æ ¼å¼åŒ–çµæœä»¥ä¾¿æ¸…æ¥šé¡¯ç¤º
        formatted_results = classifier.format_results_for_display(results)
        
        print("\n" + "="*50)
        print("åˆ†é¡çµæœï¼ˆæ¸…æ¥šæ ¼å¼ï¼‰ï¼š")
        print("="*50)
        
        # é¡¯ç¤ºå‰å¹¾å€‹çµæœä½œç‚ºç¯„ä¾‹
        for i, result in enumerate(formatted_results[:5]):  # é¡¯ç¤ºå‰5å€‹ä½œç‚ºç¯„ä¾‹
            print(f"\n--- Topic {i+1} ---")
            print(f"Topic ID: {result['topic_id']}")
            print(f"Topic Title: {result['topic_title']}")
            print(f"Source Story Count: {len(result['source_story'])}")
            
            if result['source_story']:
                print("Source Stories:")
                for j, story in enumerate(result['source_story'][:5]):  # åªé¡¯ç¤ºå‰5å‰‡æ–°è
                    print(f"  {j+1}. Story ID: {story['story_id']}")
                    print(f"     Story Title: {story['story_title']}")
            else:
                print("Source Stories: ç„¡ç›¸é—œæ–°è")
        
        if len(formatted_results) > 5:
            print(f"\n... é‚„æœ‰ {len(formatted_results) - 5} å€‹ topicsï¼ˆå®Œæ•´çµæœè«‹æŸ¥çœ‹çµ±è¨ˆå ±å‘Šï¼‰")
        
        # ç”Ÿæˆçµ±è¨ˆå ±å‘Š
        report = classifier.generate_classification_report(results)
        print("\n" + "="*50)
        print("çµ±è¨ˆå ±å‘Šï¼š")
        print("="*50)
        print(json.dumps(report, ensure_ascii=False, indent=2))
        
        # ä¿å­˜çµæœç‚º JSON æª”æ¡ˆ
        output_data = {
            "timestamp": datetime.now().isoformat(),
            "total_topics": len(results),
            "classification_results": formatted_results,
            "statistics": report
        }
        
        # è¼¸å‡ºæª”æ¡ˆåç¨±åŒ…å«æ™‚é–“æˆ³
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        output_filename = f"classification_results_{timestamp}.json"
        
        try:
            with open(output_filename, 'w', encoding='utf-8') as f:
                json.dump(output_data, f, ensure_ascii=False, indent=2)
            print(f"\nâœ… åˆ†é¡çµæœå·²ä¿å­˜è‡³: {output_filename}")
        except Exception as e:
            logger.error(f"ä¿å­˜ JSON æª”æ¡ˆå¤±æ•—: {e}")
            print(f"âŒ ä¿å­˜æª”æ¡ˆå¤±æ•—: {e}")
        
        return formatted_results
        
    except Exception as e:
        logger.error(f"åŸ·è¡Œæ‰¹é‡åˆ†é¡å¤±æ•—: {e}")
        print(f"åŸ·è¡Œå¤±æ•—: {e}")
        return []


if __name__ == "__main__":
    main()
