
from env import supabase, gemini_client
from typing import List, Dict, Any, Optional
from google.genai import types
from pydantic import BaseModel
import json
import os
from datetime import datetime

class NodeDescription(BaseModel):
    """ç¯€é»æè¿°çš„è³‡æ–™çµæ§‹"""
    id: str
    label: str
    description: str

class DetailedNodes(BaseModel):
    """è©³ç´°ç¯€é»çš„è³‡æ–™çµæ§‹"""
    who_nodes: List[NodeDescription]
    what_nodes: List[NodeDescription]
    when_nodes: List[NodeDescription]
    where_nodes: List[NodeDescription]
    why_nodes: List[NodeDescription]
    how_nodes: List[NodeDescription]

class Analysis5W1H(BaseModel):
    """5W1Håˆ†æçµæœçš„å®Œæ•´è³‡æ–™çµæ§‹"""
    center_node: NodeDescription
    main_nodes: List[NodeDescription]
    detailed_nodes: DetailedNodes

class NewsAnalyzer:
    """æ–°èåˆ†æå™¨é¡åˆ¥"""
    
    def __init__(self):
        self.knowledge_base_dict = {
            "5W1H_Analysis": None,
            "search": None
        }
    
    def search_topic_by_keyword(self, keyword: str) -> Optional[Dict[str, Any]]:
        """
        æ ¹æ“šé—œéµå­—æœå°‹topicï¼Œå–å¾—topic_idå’Œç›¸é—œè³‡è¨Š
        
        Args:
            keyword: æœå°‹é—œéµå­—
            
        Returns:
            topicè³‡è¨Šå­—å…¸ï¼ŒåŒ…å«topic_id, topic_titleç­‰
        """
        try:
            # å–å¾—æ‰€æœ‰topicè³‡æ–™
            response = supabase.table("topic").select("*").execute()
            
            if response.data:
                # åœ¨æ‰€æœ‰topicä¸­æœå°‹é—œéµå­—
                for topic in response.data:
                    if keyword.lower() in topic.get("topic_title", "").lower():
                        return topic  # è¿”å›ç¬¬ä¸€å€‹åŒ¹é…çš„topic
                
                print(f"æœªæ‰¾åˆ°åŒ…å«é—œéµå­— '{keyword}' çš„topic")
                return None
            else:
                print("ç„¡æ³•å–å¾—topicè³‡æ–™")
                return None
                
        except Exception as e:
            print(f"æœå°‹topicæ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
            return None
    
    def get_story_ids_by_topic(self, topic_id: str) -> List[str]:
        """
        æ ¹æ“štopic_idå¾topic_news_mapè¡¨ä¸­å–å¾—æ‰€æœ‰ç›¸é—œçš„story_id
        
        Args:
            topic_id: topicçš„ID
            
        Returns:
            story_idåˆ—è¡¨
        """
        try:
            response = supabase.table("topic_news_map").select("story_id").eq("topic_id", topic_id).execute()
            return [item["story_id"] for item in response.data]
            
        except Exception as e:
            print(f"å–å¾—story_idsæ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
            return []
    
    def get_news_data_by_story_ids(self, story_ids: List[str]) -> List[Dict[str, Any]]:
        """
        æ ¹æ“šstory_idåˆ—è¡¨å¾single_newsè¡¨ä¸­å–å¾—æ–°èè³‡æ–™
        
        Args:
            story_ids: story_idåˆ—è¡¨
            
        Returns:
            æ–°èè³‡æ–™åˆ—è¡¨
        """
        try:
            response = supabase.table("single_news").select(
                "news_title,short,category,generated_date,story_id"
            ).in_("story_id", story_ids).execute()
            
            return response.data
            
        except Exception as e:
            print(f"å–å¾—æ–°èè³‡æ–™æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
            return []
    
    def get_topic_branches(self, topic_id: str) -> List[Dict[str, Any]]:
        """
        æ ¹æ“štopic_idå¾topic_branchè¡¨ä¸­å–å¾—topic_branch_title
        
        Args:
            topic_id: topicçš„ID
            
        Returns:
            topic_branchè³‡æ–™åˆ—è¡¨
        """
        try:
            response = supabase.table("topic_branch").select("*").eq("topic_id", topic_id).execute()
            return response.data
            
        except Exception as e:
            print(f"å–å¾—topic_branchæ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
            return []
    
    def format_news_data(self, news_list: List[Dict[str, Any]]) -> str:
        """
        å°‡æ–°èè³‡æ–™æ ¼å¼åŒ–ç‚ºæ–‡å­—
        
        Args:
            news_list: æ–°èè³‡æ–™åˆ—è¡¨
            
        Returns:
            æ ¼å¼åŒ–å¾Œçš„æ–°èæ–‡å­—
        """
        if not news_list:
            return "ç›®å‰æ²’æœ‰ç›¸é—œæ–°èè³‡æ–™ã€‚"
        
        news_text = "ç›¸é—œæ–°èè³‡æ–™ï¼š\n\n"
        for i, news in enumerate(news_list, 1):
            news_text += f"æ–°è {i}ï¼š\n"
            news_text += f"æ¨™é¡Œï¼š{news.get('news_title', 'N/A')}\n"
            news_text += f"æ‘˜è¦ï¼š{news.get('short', 'N/A')}\n"
            news_text += f"åˆ†é¡ï¼š{news.get('category', 'N/A')}\n"
            news_text += f"æ—¥æœŸï¼š{news.get('generated_date', 'N/A')}\n"
            news_text += f"æ•…äº‹IDï¼š{news.get('story_id', 'N/A')}\n"
            news_text += "\n" + "-"*50 + "\n\n"
        
        return news_text
    
    def format_topic_branches(self, branches: List[Dict[str, Any]]) -> str:
        """
        å°‡topic_branchesæ ¼å¼åŒ–ç‚ºæ–‡å­—
        
        Args:
            branches: topic_branchè³‡æ–™åˆ—è¡¨
            
        Returns:
            æ ¼å¼åŒ–å¾Œçš„branchesæ–‡å­—
        """
        if not branches:
            return ""
        
        branches_text = "\n\nç›¸é—œä¸»é¡Œåˆ†æ”¯ï¼š\n"
        for branch in branches:
            branches_text += f"- {branch.get('topic_branch_title', 'N/A')}\n"
        
        return branches_text
    
    def set_knowledge_base_by_keyword(self, keyword: str, category: str = "5W1H_Analysis"):
        """
        æ ¹æ“šé—œéµå­—è¨­å®šçŸ¥è­˜åº«
        
        Args:
            keyword: æœå°‹é—œéµå­—
            category: åˆ†æé¡å‹
        """
        # 1. æœå°‹topic
        topic_info = self.search_topic_by_keyword(keyword)
        if not topic_info:
            print(f"ç„¡æ³•æ‰¾åˆ°é—œéµå­— '{keyword}' ç›¸é—œçš„topic")
            return False, None, None
        
        topic_id = topic_info["topic_id"]
        topic_title = topic_info["topic_title"]
        
        # 2. å–å¾—story_ids
        story_ids = self.get_story_ids_by_topic(topic_id)
        if not story_ids:
            print(f"topic_id '{topic_id}' æ²’æœ‰ç›¸é—œçš„story")
            return False, None, None
        
        # 3. å–å¾—æ–°èè³‡æ–™
        news_data = self.get_news_data_by_story_ids(story_ids)
        
        # 4. å–å¾—topic_branches
        topic_branches = self.get_topic_branches(topic_id)
        
        # 5. æ ¼å¼åŒ–è³‡æ–™
        news_text = self.format_news_data(news_data)
        branches_text = self.format_topic_branches(topic_branches)
        
        # 6. è¨­å®šçŸ¥è­˜åº«
        if category == "search":
            self.knowledge_base_dict["search"] = f"""ä½ æ˜¯ä¸€å€‹å°ˆæ¥­çš„æ–°èèˆ‡å°ˆé¡Œ AI åŠ©æ‰‹ï¼Œä½ ç›®å‰çš„çŸ¥è­˜åº«æ˜¯ï¼š
ä¸»é¡Œï¼š{topic_title}
{news_text}{branches_text}
éœ€è¦æ™‚åƒè€ƒé€™äº›è³‡æ–™ä¾†å›ç­”å•é¡Œã€‚"""
        else:
            # æ ¹æ“šå…·é«”éœ€æ±‚å„ªåŒ–ç³»çµ±æŒ‡ä»¤
            self.knowledge_base_dict["5W1H_Analysis"] = f"""ä½ æ˜¯ä¸€å€‹å°ˆæ¥­çš„æ–°èèˆ‡å°ˆé¡Œ AI åŠ©æ‰‹ï¼Œå°ˆé–€æä¾›æŸä¸€äº‹ä»¶æˆ–è­°é¡Œçš„5W1Håˆ†æã€‚

è«‹æ ¹æ“šä»¥ä¸‹çŸ¥è­˜åº«å…§å®¹é€²è¡Œåˆ†æï¼š

ä¸»é¡Œï¼š{topic_title}
{news_text}{branches_text}

åˆ†æè¦æ±‚ï¼š
1. **Whatï¼ˆä»€éº¼ï¼‰**ï¼štopic_branch_titleçš„å…§å®¹ï¼Œæ¨™é¡Œ + 80å­—å·¦å³æ•˜è¿°
2. **Whereï¼ˆå“ªè£¡ï¼‰**ï¼štopic_branch_titleæåŠçš„åœ°é»ï¼Œæ¨™é¡Œ + 80å­—å·¦å³æ•˜è¿°
3. **Whyï¼ˆç‚ºä»€éº¼ï¼‰**ï¼šç‚ºä»€éº¼æœƒç”¢ç”Ÿé€™å€‹topicï¼Œ100å­—æ•˜è¿°
4. **Whoï¼ˆèª°ï¼‰**ï¼šèˆ‡topicæœ‰é—œçš„äººåŠå…¶é‡è¦é—œä¿‚ï¼Œæ¨™é¡Œ + 80å­—å·¦å³æ•˜è¿°
5. **Whenï¼ˆä½•æ™‚ï¼‰**ï¼šç•¶è¦å»ºç«‹when_nodesæ™‚ï¼Œå¿…é ˆä½¿ç”¨topic_branch_titleä½œç‚ºdescriptionå…§å®¹ï¼Œè€Œlabelå‰‡ä½¿ç”¨ç›¸é—œçš„æ™‚é–“è³‡è¨Šï¼Œéœ€è¦å…·é«”æ™‚é–“
6. **Howï¼ˆå¦‚ä½•ï¼‰**ï¼šwhoä¸­æåŠçš„äººåšäº†ä»€éº¼äº‹ï¼Œæ¨™é¡Œ + 80å­—å·¦å³æ•˜è¿°

ç‰¹åˆ¥æ³¨æ„ï¼š
- å›ºå®š "center_node": "id": "center"
- detailed_nodes ä¸­ what_nodes çš„ label å¿…é ˆä½¿ç”¨åŸå§‹çš„ topic_branch_titleï¼Œä¸è¦ä¿®æ”¹
- detailed_nodes ä¸­ when_nodes çš„ description å¿…é ˆä½¿ç”¨åŸå§‹çš„ topic_branch_title ä½œç‚ºå…§å®¹
- æ¯å€‹ç¯€é»çš„æè¿°è¦å…·é«”ä¸”å®Œæ•´
- å…§å®¹å¿…é ˆåŸºæ–¼æä¾›çš„çŸ¥è­˜åº«è³‡æ–™
- è¼¸å‡ºæ ¼å¼å¿…é ˆæ˜¯æœ‰æ•ˆçš„JSONæ ¼å¼

åˆ†æçµæœéœ€è¦åŒ…å«ä¸‰å€‹å±¤æ¬¡ï¼š
1. ä¸­å¿ƒç¯€é»ï¼šä¸»é¡Œçš„ç°¡ç•¥æ¦‚è¿°
2. 5W1Hä¸»ç¯€é»ï¼šå…­å€‹ä¸»è¦åˆ†æç¶­åº¦çš„ç°¡ç•¥æè¿°  
3. è©³ç´°ç¯€é»ï¼šæ¯å€‹5W1Hç¶­åº¦ä¸‹çš„å…·é«”å­é …ç›®"""
        
        return True, topic_branches, news_data
    
    def get_knowledge_base(self, category: str = "5W1H_Analysis") -> str:
        """
        å–å¾—çŸ¥è­˜åº«å…§å®¹
        
        Args:
            category: åˆ†æé¡å‹
            
        Returns:
            çŸ¥è­˜åº«çš„ç³»çµ±æç¤ºå…§å®¹
        """
        if category in self.knowledge_base_dict and self.knowledge_base_dict[category]:
            return self.knowledge_base_dict[category]
        else:
            raise ValueError(f"Unknown category or empty knowledge base: {category}")
    
    def analyze_5W1H(self, keyword: str) -> Dict[str, Any]:
        """
        åŸ·è¡Œ5W1Håˆ†æçš„ä¸»è¦å‡½æ•¸
        
        Args:
            keyword: è¦åˆ†æçš„é—œéµå­—ï¼ˆä¾‹å¦‚ï¼š"å¤§ç½·å…"ï¼‰
            
        Returns:
            5W1Håˆ†æçµæœçš„å­—å…¸
        """
        # æ ¹æ“šé—œéµå­—è¨­å®šçŸ¥è­˜åº«
        success, topic_branches, news_data = self.set_knowledge_base_by_keyword(keyword, "5W1H_Analysis")
        if not success:
            return {"error": f"ç„¡æ³•ç‚ºé—œéµå­— '{keyword}' è¨­å®šçŸ¥è­˜åº«"}
        
        try:
            # å–å¾—ç³»çµ±æç¤º
            system_instruction = self.get_knowledge_base("5W1H_Analysis")
            
            # æ§‹å»ºæ›´è©³ç´°çš„ç”¨æˆ¶æç¤º
            user_prompt = f"""è«‹å°é—œéµå­— '{keyword}' ç›¸é—œçš„ä¸»é¡Œé€²è¡Œ5W1Håˆ†æã€‚

åˆ†ææ™‚è«‹ç‰¹åˆ¥æ³¨æ„ï¼š
1. Whatç¯€é»ï¼šä½¿ç”¨æ‰€æœ‰çš„topic_branch_titleä½œç‚ºæ¨™é¡Œï¼Œä¸¦æä¾›80å­—å·¦å³çš„æ•˜è¿°
2. Whereç¯€é»ï¼šå¾topic_branch_titleä¸­è­˜åˆ¥åœ°é»ï¼Œæä¾›æ¨™é¡Œå’Œ80å­—æ•˜è¿°
3. Whyç¯€é»ï¼šåˆ†æç‚ºä»€éº¼æœƒç”¢ç”Ÿé€™å€‹topicï¼Œæä¾›100å­—æ•˜è¿°
4. Whoç¯€é»ï¼šè­˜åˆ¥èˆ‡topicç›¸é—œçš„é‡è¦äººç‰©ï¼Œèªªæ˜å…¶é—œä¿‚ï¼Œæä¾›æ¨™é¡Œå’Œ80å­—æ•˜è¿°
5. Whenç¯€é»ï¼šä½¿ç”¨topic_branch_titleä½œç‚ºdescriptionå…§å®¹ï¼Œlabelä½¿ç”¨ç›¸é—œçš„æ™‚é–“è³‡è¨Šï¼Œéœ€è¦å…·é«”æ™‚é–“
6. Howç¯€é»ï¼šåˆ†æwhoä¸­æåŠçš„äººåšäº†ä»€éº¼äº‹ï¼Œæä¾›æ¨™é¡Œå’Œ80å­—æ•˜è¿°

è«‹ç¢ºä¿ï¼š
- å›ºå®š "center_node": "id": "center"
- detailed_nodesä¸­what_nodesçš„labelç›´æ¥ä½¿ç”¨åŸå§‹çš„topic_branch_title
- detailed_nodesä¸­when_nodesçš„descriptionç›´æ¥ä½¿ç”¨åŸå§‹çš„topic_branch_title"""
            
            # è®“AIé€²è¡Œ5W1Håˆ†æ
            response = gemini_client.models.generate_content(
                model="gemini-2.5-flash-lite",
                contents=user_prompt,
                config=types.GenerateContentConfig(
                    system_instruction=system_instruction,
                    response_mime_type="application/json",
                    response_schema=Analysis5W1H,
                )
            )
            
            # è§£æçµæœ
            analysis_result = response.parsed
            result_dict = {
                "center_node": {
                    "id": analysis_result.center_node.id,
                    "label": analysis_result.center_node.label,
                    "description": analysis_result.center_node.description
                },
                "main_nodes": [
                    {
                        "id": node.id,
                        "label": node.label, 
                        "description": node.description
                    } for node in analysis_result.main_nodes
                ],
                "detailed_nodes": {
                    "who_nodes": [
                        {
                            "id": node.id,
                            "label": node.label,
                            "description": node.description
                        } for node in analysis_result.detailed_nodes.who_nodes
                    ],
                    "what_nodes": [
                        {
                            "id": node.id,
                            "label": node.label,
                            "description": node.description
                        } for node in analysis_result.detailed_nodes.what_nodes
                    ],
                    "when_nodes": [
                        {
                            "id": node.id,
                            "label": node.label,
                            "description": node.description
                        } for node in analysis_result.detailed_nodes.when_nodes
                    ],
                    "where_nodes": [
                        {
                            "id": node.id,
                            "label": node.label,
                            "description": node.description
                        } for node in analysis_result.detailed_nodes.where_nodes
                    ],
                    "why_nodes": [
                        {
                            "id": node.id,
                            "label": node.label,
                            "description": node.description
                        } for node in analysis_result.detailed_nodes.why_nodes
                    ],
                    "how_nodes": [
                        {
                            "id": node.id,
                            "label": node.label,
                            "description": node.description
                        } for node in analysis_result.detailed_nodes.how_nodes
                    ]
                },
                # æ·»åŠ åŸå§‹è³‡æ–™ä»¥ä¾›åƒè€ƒ
                # "metadata": {
                #     "topic_branches": topic_branches,
                #     "news_count": len(news_data) if news_data else 0,
                #     "analysis_date": datetime.now().isoformat()
                # }
            }
            
            # å„²å­˜åˆ°JSONæª”æ¡ˆ
            self.save_analysis_result(keyword, result_dict)
            
            return result_dict
            
        except Exception as e:
            print(f"5W1Håˆ†ææ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
            return {"error": str(e)}
    
    def save_analysis_result(self, keyword: str, result: Dict[str, Any]):
        """
        å„²å­˜åˆ†æçµæœåˆ°JSONæª”æ¡ˆ
        
        Args:
            keyword: é—œéµå­—
            result: åˆ†æçµæœ
        """
        try:
            output_folder = "json/5W1H"
            os.makedirs(output_folder, exist_ok=True)
            
            # ä½¿ç”¨æ™‚é–“æˆ³è¨˜é¿å…æª”åè¡çª
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            safe_keyword = keyword.replace(' ', '_').replace('/', '_')
            filename = f"{output_folder}/{safe_keyword}_5W1H_{timestamp}.json"
            
            with open(filename, 'w', encoding='utf-8') as f:
                json.dump(result, f, ensure_ascii=False, indent=2)
            
            print(f"5W1Håˆ†æçµæœå·²å„²å­˜è‡³: {filename}")
            
        except Exception as e:
            print(f"å„²å­˜æª”æ¡ˆæ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
    
    def upload_mind_map_to_supabase(self, topic_id: str, mind_map_data: Dict[str, Any]) -> bool:
        """
        å°‡å¿ƒæ™ºåœ–è³‡æ–™ä¸Šå‚³åˆ°Supabaseçš„topicè¡¨ä¸­çš„mind_map_detailæ¬„ä½
        
        Args:
            topic_id: topicçš„ID
            mind_map_data: 5W1Håˆ†æçµæœçš„å­—å…¸
            
        Returns:
            ä¸Šå‚³æ˜¯å¦æˆåŠŸ
        """
        try:
            # æº–å‚™è¦æ›´æ–°çš„è³‡æ–™
            update_data = {
                "mind_map_detail": mind_map_data
            }
            
            # æ›´æ–°topicè¡¨ä¸­çš„mind_map_detailæ¬„ä½
            response = supabase.table("topic").update(update_data).eq("topic_id", topic_id).execute()
            
            if response.data:
                print(f"æˆåŠŸä¸Šå‚³å¿ƒæ™ºåœ–è³‡æ–™åˆ°topic_id: {topic_id}")
                return True
            else:
                print(f"ä¸Šå‚³å¿ƒæ™ºåœ–è³‡æ–™å¤±æ•—ï¼Œæ²’æœ‰æ‰¾åˆ°topic_id: {topic_id}")
                return False
                
        except Exception as e:
            print(f"ä¸Šå‚³å¿ƒæ™ºåœ–è³‡æ–™åˆ°Supabaseæ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
            return False

# ä½¿ç”¨ç¯„ä¾‹å’Œæ¸¬è©¦å‡½æ•¸
def validate_analysis_result(result: Dict[str, Any]) -> bool:
    """
    é©—è­‰åˆ†æçµæœæ˜¯å¦ç¬¦åˆè¦æ±‚
    
    Args:
        result: åˆ†æçµæœ
        
    Returns:
        æ˜¯å¦ç¬¦åˆè¦æ±‚
    """
    try:
        # æª¢æŸ¥åŸºæœ¬çµæ§‹
        required_keys = ["center_node", "main_nodes", "detailed_nodes"]
        for key in required_keys:
            if key not in result:
                print(f"ç¼ºå°‘å¿…è¦æ¬„ä½: {key}")
                return False
        
        # æª¢æŸ¥detailed_nodesçµæ§‹
        detailed_keys = ["who_nodes", "what_nodes", "when_nodes", "where_nodes", "why_nodes", "how_nodes"]
        for key in detailed_keys:
            if key not in result["detailed_nodes"]:
                print(f"ç¼ºå°‘detailed_nodesæ¬„ä½: {key}")
                return False
        
        # æª¢æŸ¥what_nodesæ˜¯å¦åŒ…å«topic_branch_title
        what_nodes = result["detailed_nodes"]["what_nodes"]
        if not what_nodes:
            print("what_nodesç‚ºç©º")
            return False
        
        # æª¢æŸ¥when_nodesæ˜¯å¦ä½¿ç”¨topic_branch_titleä½œç‚ºdescription
        when_nodes = result["detailed_nodes"]["when_nodes"]
        if not when_nodes:
            print("when_nodesç‚ºç©º")
            return False
        
        print("åˆ†æçµæœé©—è­‰é€šé")
        return True
        
    except Exception as e:
        print(f"é©—è­‰åˆ†æçµæœæ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
        return False

def demo_with_custom_requirements():
    """
    æŒ‰ç…§å…·é«”éœ€æ±‚é€²è¡Œæ¼”ç¤ºçš„å‡½æ•¸ï¼Œä¸¦ä¸Šå‚³åˆ°Supabase
    """
    analyzer = NewsAnalyzer()
    keyword = "éæ´²è±¬ç˜Ÿ"  # ä½ å¯ä»¥æ”¹æˆå…¶ä»–é—œéµå­—
    
    print(f"é–‹å§‹æŒ‰ç…§è‡ªå®šç¾©éœ€æ±‚åˆ†æé—œéµå­—: {keyword}")
    
    # 1. é¦–å…ˆæœå°‹topicè³‡è¨Š
    topic_info = analyzer.search_topic_by_keyword(keyword)
    if not topic_info:
        print(f"ç„¡æ³•æ‰¾åˆ°é—œéµå­— '{keyword}' ç›¸é—œçš„topic")
        return
    
    topic_id = topic_info["topic_id"]
    print(f"æ‰¾åˆ°Topic ID: {topic_id}")
    
    # 2. è¨­å®šçŸ¥è­˜åº«
    success, topic_branches, news_data = analyzer.set_knowledge_base_by_keyword(keyword)
    if not success:
        print(f"ç„¡æ³•è¨­å®šçŸ¥è­˜åº«")
        return
    
    print(f"æ‰¾åˆ° {len(topic_branches)} å€‹ä¸»é¡Œåˆ†æ”¯")
    print(f"æ‰¾åˆ° {len(news_data)} æ¢ç›¸é—œæ–°è")
    
    # 3. åŸ·è¡Œåˆ†æ
    analysis_result = analyzer.analyze_5W1H(keyword)
    
    if "error" not in analysis_result:
        print("\n=== åˆ†ææˆåŠŸ ===")
        
        # é¡¯ç¤ºWhatç¯€é»ï¼ˆæ‡‰è©²åŒ…å«æ‰€æœ‰topic_branch_titleï¼‰
        print("\n=== Whatç¯€é»ï¼ˆTopic Branch Titlesï¼‰ ===")
        for node in analysis_result['detailed_nodes']['what_nodes']:
            print(f"æ¨™é¡Œ: {node['label']}")
            print(f"æè¿°: {node['description']}")
            print("-" * 40)
        
        # é¡¯ç¤ºWhenç¯€é»ï¼ˆdescriptionæ‡‰è©²æ˜¯topic_branch_titleï¼‰
        print("\n=== Whenç¯€é»ï¼ˆTopic Branch Titles as Descriptionï¼‰ ===")
        for node in analysis_result['detailed_nodes']['when_nodes']:
            print(f"æ™‚é–“æ¨™ç±¤: {node['label']}")
            print(f"æè¿°å…§å®¹: {node['description']}")  # é€™è£¡æ‡‰è©²æ˜¯topic_branch_title
            print("-" * 40)
        
        # é¡¯ç¤ºå…¶ä»–é‡è¦ç¯€é»
        print("\n=== Whyç¯€é»ï¼ˆ100å­—æ•˜è¿°ï¼‰ ===")
        for node in analysis_result['detailed_nodes']['why_nodes']:
            print(f"æè¿°: {node['description']}")
        
        # â˜…â˜…â˜… æ–°å¢ï¼šä¸Šå‚³åˆ°Supabase â˜…â˜…â˜…
        print("\n=== ä¸Šå‚³åˆ°Supabase ===")
        upload_success = analyzer.upload_mind_map_to_supabase(topic_id, analysis_result)
        
        if upload_success:
            print("âœ… å¿ƒæ™ºåœ–è³‡æ–™å·²æˆåŠŸä¸Šå‚³åˆ°Supabaseçš„topicè¡¨")
            
            # é©—è­‰ä¸Šå‚³çµæœ
            try:
                verify_response = supabase.table("topic").select("mind_map_detail").eq("topic_id", topic_id).execute()
                if verify_response.data and verify_response.data[0].get("mind_map_detail"):
                    print("âœ… é©—è­‰ä¸Šå‚³æˆåŠŸï¼šmind_map_detailæ¬„ä½å·²æ›´æ–°")
                else:
                    print("âŒ é©—è­‰å¤±æ•—ï¼šmind_map_detailæ¬„ä½ç‚ºç©º")
            except Exception as e:
                print(f"é©—è­‰ä¸Šå‚³çµæœæ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
        else:
            print("âŒ å¿ƒæ™ºåœ–è³‡æ–™ä¸Šå‚³å¤±æ•—")
            
    else:
        print(f"åˆ†æå¤±æ•—: {analysis_result['error']}")

def demo_with_custom_requirements_and_return_topic_id(keyword: str = "å¤§ç½·å…") -> Optional[str]:
    """
    åŸ·è¡Œåˆ†æä¸¦ä¸Šå‚³åˆ°Supabaseï¼Œè¿”å›topic_idä»¥ä¾›å¾ŒçºŒä½¿ç”¨
    
    Args:
        keyword: è¦åˆ†æçš„é—œéµå­—
        
    Returns:
        æˆåŠŸæ™‚è¿”å›topic_idï¼Œå¤±æ•—æ™‚è¿”å›None
    """
    analyzer = NewsAnalyzer()
    
    print(f"é–‹å§‹åˆ†æä¸¦ä¸Šå‚³é—œéµå­—: {keyword}")
    
    # 1. é¦–å…ˆæœå°‹topicè³‡è¨Š
    topic_info = analyzer.search_topic_by_keyword(keyword)
    if not topic_info:
        print(f"ç„¡æ³•æ‰¾åˆ°é—œéµå­— '{keyword}' ç›¸é—œçš„topic")
        return None
    
    topic_id = topic_info["topic_id"]
    print(f"æ‰¾åˆ°Topic ID: {topic_id}")
    
    # 2. è¨­å®šçŸ¥è­˜åº«ä¸¦åŸ·è¡Œåˆ†æ
    success, topic_branches, news_data = analyzer.set_knowledge_base_by_keyword(keyword)
    if not success:
        print(f"ç„¡æ³•è¨­å®šçŸ¥è­˜åº«")
        return None
    
    # 3. åŸ·è¡Œåˆ†æ
    analysis_result = analyzer.analyze_5W1H(keyword)
    
    if "error" not in analysis_result:
        # 4. ä¸Šå‚³åˆ°Supabase
        upload_success = analyzer.upload_mind_map_to_supabase(topic_id, analysis_result)
        
        if upload_success:
            print(f"âœ… é—œéµå­— '{keyword}' çš„å¿ƒæ™ºåœ–è³‡æ–™å·²æˆåŠŸä¸Šå‚³")
            return topic_id
        else:
            print(f"âŒ é—œéµå­— '{keyword}' çš„å¿ƒæ™ºåœ–è³‡æ–™ä¸Šå‚³å¤±æ•—")
            return None
    else:
        print(f"åˆ†æå¤±æ•—: {analysis_result['error']}")
        return None

def batch_analyze_and_upload(keywords: List[str]) -> Dict[str, Optional[str]]:
    """
    æ‰¹æ¬¡åˆ†æå¤šå€‹é—œéµå­—ä¸¦ä¸Šå‚³åˆ°Supabase
    
    Args:
        keywords: é—œéµå­—åˆ—è¡¨
        
    Returns:
        æ¯å€‹é—œéµå­—å°æ‡‰çš„topic_idå­—å…¸ï¼ˆæˆåŠŸæ™‚ç‚ºtopic_idï¼Œå¤±æ•—æ™‚ç‚ºNoneï¼‰
    """
    results = {}
    
    for keyword in keywords:
        print(f"\nè™•ç†é—œéµå­—: {keyword}")
        print("=" * 50)
        topic_id = demo_with_custom_requirements_and_return_topic_id(keyword)
        results[keyword] = topic_id
    
    # é¡¯ç¤ºç¸½çµ
    print("\n" + "=" * 80)
    print("æ‰¹æ¬¡è™•ç†ç¸½çµ:")
    for keyword, topic_id in results.items():
        if topic_id:
            print(f"âœ… {keyword}: æˆåŠŸä¸Šå‚³ (Topic ID: {topic_id})")
        else:
            print(f"âŒ {keyword}: ä¸Šå‚³å¤±æ•—")
    
    return results

def get_all_topics() -> List[Dict[str, Any]]:
    """
    å–å¾—æ‰€æœ‰topicè³‡æ–™
    
    Returns:
        æ‰€æœ‰topicçš„åˆ—è¡¨
    """
    try:
        response = supabase.table("topic").select("*").execute()
        if response.data:
            print(f"æˆåŠŸå–å¾— {len(response.data)} å€‹topics")
            return response.data
        else:
            print("æœªæ‰¾åˆ°ä»»ä½•topicè³‡æ–™")
            return []
    except Exception as e:
        print(f"å–å¾—topicsæ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
        return []

def process_single_topic(topic_info: Dict[str, Any]) -> Optional[str]:
    """
    è™•ç†å–®ä¸€topicçš„5W1Håˆ†æä¸¦ä¸Šå‚³
    
    Args:
        topic_info: topicè³‡è¨Šå­—å…¸
        
    Returns:
        æˆåŠŸæ™‚è¿”å›topic_idï¼Œå¤±æ•—æ™‚è¿”å›None
    """
    analyzer = NewsAnalyzer()
    
    topic_id = topic_info["topic_id"]
    topic_title = topic_info["topic_title"]
    
    print(f"\né–‹å§‹è™•ç†Topic: {topic_title}")
    print(f"Topic ID: {topic_id}")
    
    # 1. å–å¾—story_ids
    story_ids = analyzer.get_story_ids_by_topic(topic_id)
    if not story_ids:
        print(f"âš ï¸ Topic '{topic_title}' æ²’æœ‰ç›¸é—œçš„storyï¼Œè·³é")
        return None
    
    # 2. å–å¾—æ–°èè³‡æ–™
    news_data = analyzer.get_news_data_by_story_ids(story_ids)
    
    # 3. å–å¾—topic_branches
    topic_branches = analyzer.get_topic_branches(topic_id)
    
    if not topic_branches:
        print(f"âš ï¸ Topic '{topic_title}' æ²’æœ‰topic_branchesï¼Œè·³é")
        return None
    
    # 4. æ ¼å¼åŒ–è³‡æ–™ä¸¦è¨­å®šçŸ¥è­˜åº«
    news_text = analyzer.format_news_data(news_data)
    branches_text = analyzer.format_topic_branches(topic_branches)
    
    analyzer.knowledge_base_dict["5W1H_Analysis"] = f"""ä½ æ˜¯ä¸€å€‹å°ˆæ¥­çš„æ–°èèˆ‡å°ˆé¡Œ AI åŠ©æ‰‹ï¼Œå°ˆé–€æä¾›æŸä¸€äº‹ä»¶æˆ–è­°é¡Œçš„5W1Håˆ†æã€‚

    è«‹æ ¹æ“šä»¥ä¸‹çŸ¥è­˜åº«å…§å®¹é€²è¡Œåˆ†æï¼š

    ä¸»é¡Œï¼š{topic_title}
    {news_text}{branches_text}

    åˆ†æè¦æ±‚ï¼š
    1. **Whatï¼ˆä»€éº¼ï¼‰**ï¼štopic_branch_titleçš„å…§å®¹ï¼Œæ¨™é¡Œ + 80å­—å·¦å³æ•˜è¿°
    2. **Whereï¼ˆå“ªè£¡ï¼‰**ï¼štopic_branch_titleæåŠçš„åœ°é»ï¼Œæ¨™é¡Œ + 80å­—å·¦å³æ•˜è¿°
    3. **Whyï¼ˆç‚ºä»€éº¼ï¼‰**ï¼šç‚ºä»€éº¼æœƒç”¢ç”Ÿé€™å€‹topicï¼Œ100å­—æ•˜è¿°
    4. **Whoï¼ˆèª°ï¼‰**ï¼šèˆ‡topicæœ‰é—œçš„äººåŠå…¶é‡è¦é—œä¿‚ï¼Œæ¨™é¡Œ + 80å­—å·¦å³æ•˜è¿°
    5. **Whenï¼ˆä½•æ™‚ï¼‰**ï¼šç•¶è¦å»ºç«‹when_nodesæ™‚ï¼Œå¿…é ˆä½¿ç”¨topic_branch_titleä½œç‚ºdescriptionå…§å®¹ï¼Œè€Œlabelå‰‡ä½¿ç”¨ç›¸é—œçš„æ™‚é–“è³‡è¨Šï¼Œéœ€è¦å…·é«”æ™‚é–“
    6. **Howï¼ˆå¦‚ä½•ï¼‰**ï¼šwhoä¸­æåŠçš„äººåšäº†ä»€éº¼äº‹ï¼Œæ¨™é¡Œ + 80å­—å·¦å³æ•˜è¿°

    ç‰¹åˆ¥æ³¨æ„ï¼š
    - å›ºå®š "center_node": "id": "center"
    - detailed_nodes ä¸­ what_nodes çš„ label å¿…é ˆä½¿ç”¨åŸå§‹çš„ topic_branch_titleï¼Œä¸è¦ä¿®æ”¹
    - detailed_nodes ä¸­ when_nodes çš„ description å¿…é ˆä½¿ç”¨åŸå§‹çš„ topic_branch_title ä½œç‚ºå…§å®¹
    - æ¯å€‹ç¯€é»çš„æè¿°è¦å…·é«”ä¸”å®Œæ•´
    - å…§å®¹å¿…é ˆåŸºæ–¼æä¾›çš„çŸ¥è­˜åº«è³‡æ–™
    - è¼¸å‡ºæ ¼å¼å¿…é ˆæ˜¯æœ‰æ•ˆçš„JSONæ ¼å¼

    åˆ†æçµæœéœ€è¦åŒ…å«ä¸‰å€‹å±¤æ¬¡ï¼š
    1. ä¸­å¿ƒç¯€é»ï¼šä¸»é¡Œçš„ç°¡ç•¥æ¦‚è¿°
    2. 5W1Hä¸»ç¯€é»ï¼šå…­å€‹ä¸»è¦åˆ†æç¶­åº¦çš„ç°¡ç•¥æè¿°  
    3. è©³ç´°ç¯€é»ï¼šæ¯å€‹5W1Hç¶­åº¦ä¸‹çš„å…·é«”å­é …ç›®"""
    
    # 5. åŸ·è¡Œåˆ†æ
    try:
        system_instruction = analyzer.knowledge_base_dict["5W1H_Analysis"]
        
        user_prompt = f"""è«‹å°ä¸»é¡Œ '{topic_title}' é€²è¡Œ5W1Håˆ†æã€‚

        åˆ†ææ™‚è«‹ç‰¹åˆ¥æ³¨æ„ï¼š
        1. Whatç¯€é»ï¼šä½¿ç”¨æ‰€æœ‰çš„topic_branch_titleä½œç‚ºæ¨™é¡Œï¼Œä¸¦æä¾›80å­—å·¦å³çš„æ•˜è¿°
        2. Whereç¯€é»ï¼šå¾topic_branch_titleä¸­è­˜åˆ¥åœ°é»ï¼Œæä¾›æ¨™é¡Œå’Œ80å­—æ•˜è¿°
        3. Whyç¯€é»ï¼šåˆ†æç‚ºä»€éº¼æœƒç”¢ç”Ÿé€™å€‹topicï¼Œæä¾›100å­—æ•˜è¿°
        4. Whoç¯€é»ï¼šè­˜åˆ¥èˆ‡topicç›¸é—œçš„é‡è¦äººç‰©ï¼Œèªªæ˜å…¶é—œä¿‚ï¼Œæä¾›æ¨™é¡Œå’Œ80å­—æ•˜è¿°
        5. Whenç¯€é»ï¼šä½¿ç”¨topic_branch_titleä½œç‚ºdescriptionå…§å®¹ï¼Œlabelä½¿ç”¨ç›¸é—œçš„æ™‚é–“è³‡è¨Šï¼Œéœ€è¦å…·é«”æ™‚é–“
        6. Howç¯€é»ï¼šåˆ†æwhoä¸­æåŠçš„äººåšäº†ä»€éº¼äº‹ï¼Œæä¾›æ¨™é¡Œå’Œ80å­—æ•˜è¿°

        è«‹ç¢ºä¿ï¼š
        - å›ºå®š "center_node": "id": "center"
        - detailed_nodesä¸­what_nodesçš„labelç›´æ¥ä½¿ç”¨åŸå§‹çš„topic_branch_title
        - detailed_nodesä¸­when_nodesçš„descriptionç›´æ¥ä½¿ç”¨åŸå§‹çš„topic_branch_title"""
        
        response = gemini_client.models.generate_content(
            model="gemini-2.0-flash",
            contents=user_prompt,
            config=types.GenerateContentConfig(
                system_instruction=system_instruction,
                response_mime_type="application/json",
                response_schema=Analysis5W1H,
            )
        )
        
        analysis_result = response.parsed
        result_dict = {
            "center_node": {
                "id": analysis_result.center_node.id,
                "label": analysis_result.center_node.label,
                "description": analysis_result.center_node.description
            },
            "main_nodes": [
                {
                    "id": node.id,
                    "label": node.label, 
                    "description": node.description
                } for node in analysis_result.main_nodes
            ],
            "detailed_nodes": {
                "who_nodes": [
                    {
                        "id": node.id,
                        "label": node.label,
                        "description": node.description
                    } for node in analysis_result.detailed_nodes.who_nodes
                ],
                "what_nodes": [
                    {
                        "id": node.id,
                        "label": node.label,
                        "description": node.description
                    } for node in analysis_result.detailed_nodes.what_nodes
                ],
                "when_nodes": [
                    {
                        "id": node.id,
                        "label": node.label,
                        "description": node.description
                    } for node in analysis_result.detailed_nodes.when_nodes
                ],
                "where_nodes": [
                    {
                        "id": node.id,
                        "label": node.label,
                        "description": node.description
                    } for node in analysis_result.detailed_nodes.where_nodes
                ],
                "why_nodes": [
                    {
                        "id": node.id,
                        "label": node.label,
                        "description": node.description
                    } for node in analysis_result.detailed_nodes.why_nodes
                ],
                "how_nodes": [
                    {
                        "id": node.id,
                        "label": node.label,
                        "description": node.description
                    } for node in analysis_result.detailed_nodes.how_nodes
                ]
            }
        }
        
        # 6. ä¸Šå‚³åˆ°Supabase
        upload_success = analyzer.upload_mind_map_to_supabase(topic_id, result_dict)
        
        if upload_success:
            print(f"âœ… Topic '{topic_title}' çš„å¿ƒæ™ºåœ–è³‡æ–™å·²æˆåŠŸä¸Šå‚³")
            return topic_id
        else:
            print(f"âŒ Topic '{topic_title}' çš„å¿ƒæ™ºåœ–è³‡æ–™ä¸Šå‚³å¤±æ•—")
            return None
            
    except Exception as e:
        print(f"âŒ è™•ç†Topic '{topic_title}' æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
        return None

def process_all_topics():
    """
    è™•ç†æ‰€æœ‰topicsçš„5W1Håˆ†æä¸¦ä¸Šå‚³åˆ°Supabase
    """
    print("=" * 80)
    print("é–‹å§‹è™•ç†æ‰€æœ‰Topicsçš„5W1Håˆ†æ")
    print("=" * 80)
    
    # 1. å–å¾—æ‰€æœ‰topics
    all_topics = get_all_topics()
    
    if not all_topics:
        print("âŒ æ²’æœ‰æ‰¾åˆ°ä»»ä½•topicè³‡æ–™")
        return
    
    # 2. è™•ç†æ¯å€‹topic
    success_count = 0
    skip_count = 0
    fail_count = 0
    
    for i, topic in enumerate(all_topics, 1):
        print(f"\n{'='*80}")
        print(f"é€²åº¦: {i}/{len(all_topics)}")
        
        result = process_single_topic(topic)
        
        if result:
            success_count += 1
        elif result is None and "æ²’æœ‰ç›¸é—œçš„story" in str(result):
            skip_count += 1
        else:
            fail_count += 1
    
    # 3. é¡¯ç¤ºç¸½çµ
    print("\n" + "=" * 80)
    print("æ‰¹æ¬¡è™•ç†å®Œæˆï¼")
    print("=" * 80)
    print(f"ğŸ“Š è™•ç†çµ±è¨ˆ:")
    print(f"   - ç¸½å…±è™•ç†: {len(all_topics)} å€‹topics")
    print(f"   - âœ… æˆåŠŸä¸Šå‚³: {success_count} å€‹")
    print(f"   - âš ï¸ è·³é: {skip_count} å€‹ï¼ˆç„¡è³‡æ–™ï¼‰")
    print(f"   - âŒ å¤±æ•—: {fail_count} å€‹")
    print("=" * 80)

if __name__ == "__main__":
    # è™•ç†æ‰€æœ‰topics
    process_all_topics()
    
    # å¦‚æœåªæƒ³è™•ç†å–®ä¸€é—œéµå­—ï¼Œå¯ä»¥ä½¿ç”¨ï¼š
    # demo_with_custom_requirements()